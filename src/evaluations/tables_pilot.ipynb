{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from typing import Set, Tuple, NamedTuple, List, Dict, Counter, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from decomposer import AdversarialDecomposer, AdversarialConfig\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Embedding():\n",
    "    \n",
    "    def __init__(self, path: str, source: Optional[str] = None):\n",
    "        if source is None or source == 'adversarial':\n",
    "            self.init_from_adversarial(path)\n",
    "        elif source == 'skip_gram':\n",
    "            self.init_from_skip_gram(path)\n",
    "        elif source == 'plain_text':\n",
    "            self.init_from_plain_text(path)\n",
    "        else:\n",
    "            raise ValueError('Unknown embedding source.')\n",
    "            \n",
    "    def init_from_adversarial(self, path: str, device=torch.device('cpu')):\n",
    "        payload = torch.load(path, map_location=device)\n",
    "        model = payload['model']\n",
    "        self.word_to_id = model.word_to_id\n",
    "        self.id_to_word = model.id_to_word \n",
    "        self.Dem_frequency: Counter[str] = model.Dem_frequency\n",
    "        self.GOP_frequency: Counter[str] = model.GOP_frequency\n",
    "        \n",
    "        # encoded layer\n",
    "        self.embedding = model.export_encoded_embedding(device=device)\n",
    "#         self.embedding = model.export_decomposed_embedding(device=device)\n",
    "\n",
    "#         # manually choose which layer to export\n",
    "#         all_vocab_ids = torch.arange(\n",
    "#             len(self.word_to_id), dtype=torch.long, device=device)\n",
    "#         with torch.no_grad():\n",
    "#             embed = model.embedding(all_vocab_ids)\n",
    "#             encoded = model.encoder(embed)\n",
    "#             self.cono_logits = model.cono_decoder(encoded)\n",
    "            \n",
    "#     def init_from_adversarial(self, path: str):        \n",
    "#         config = DenotationEncoderConfig()\n",
    "#         config.input_dir = '../../data/processed/adversarial/44_Obama_1e-5'\n",
    "#         data = AdversarialDataset(config)\n",
    "#         model = DenotationEncoder(config, data)\n",
    "#         model.load_state_dict(torch.load(path))\n",
    "#         self.embedding = model.export_decomposed_embedding().to('cpu')\n",
    "#         self.word_to_id = model.word_to_id\n",
    "#         self.id_to_word = model.id_to_word\n",
    "\n",
    "    def init_from_skip_gram(self, paths: Tuple[str, str]) -> None:\n",
    "        \"\"\"Directly extract the weights of a single layer.\"\"\"\n",
    "        model_path, vocab_path = paths\n",
    "        with open(model_path, 'rb') as model_file:\n",
    "            state_dict = torch.load(model_file, map_location='cpu')\n",
    "    #     print(state_dict.keys())\n",
    "        self.embedding = state_dict['center_embedding.weight'].numpy()\n",
    "        with open(vocab_path, 'rb') as vocab_file:\n",
    "            self.word_to_id, self.id_to_word, _ = pickle.load(vocab_file)\n",
    "\n",
    "    def init_from_plain_text(self, path: str) -> Tuple[np.array, Dict[str, int]]:\n",
    "        id_generator = 0\n",
    "        word_to_id: Dict[str, int] = {}\n",
    "        embeddings: List[float] = []\n",
    "        embedding_file = open(path)\n",
    "        vocab_size, num_dimensions = map(int, embedding_file.readline().split())\n",
    "        print(f'vocab_size = {vocab_size:,}, num_dimensions = {num_dimensions}')\n",
    "        print(f'Loading embeddings from {path}', flush=True)\n",
    "        for line in embedding_file:\n",
    "            line: List[str] = line.split()  # type: ignore\n",
    "            word = line[0]\n",
    "            vector = np.array(line[-num_dimensions:], dtype=np.float64)\n",
    "            embeddings.append(vector)\n",
    "            word_to_id[word] = id_generator\n",
    "            id_generator += 1\n",
    "        embedding_file.close()\n",
    "        print('Done')\n",
    "        self.id_to_word = {val: key for key, val in word_to_id.items()}\n",
    "        self.word_to_id = word_to_id\n",
    "        self.embedding = np.array(embeddings)\n",
    "        \n",
    "    def write_to_tensorboard_projector(self, tb_dir: str) -> None:\n",
    "        from torch.utils import tensorboard\n",
    "        tb = tensorboard.SummaryWriter(log_dir=tb_dir)\n",
    "        all_vocab_ids = range(len(self.word_to_id))\n",
    "        embedding_labels = [\n",
    "            self.id_to_word[word_id]\n",
    "            for word_id in all_vocab_ids]\n",
    "        tb.add_embedding(\n",
    "            self.embedding[:9999], \n",
    "            embedding_labels[:9999], \n",
    "            global_step=0)\n",
    "        \n",
    "    def export_web_projector(self, out_dir: str) -> None:\n",
    "        random_indices = np.random.randint(len(self.embedding), size=10000)\n",
    "        subset_embedding = self.embedding[random_indices].tolist()\n",
    "        \n",
    "        vector_path = os.path.join(out_dir, 'tensorboard.tsv')\n",
    "        with open(vector_path, 'w') as vector_file:\n",
    "            for vector in subset_embedding:\n",
    "                vector_file.write('\\t'.join(map(str, vector)) + '\\n')\n",
    "\n",
    "        label_path = os.path.join(out_dir, 'tensorboard_labels.tsv')\n",
    "        with open(label_path, 'w') as label_file:\n",
    "            for index in random_indices:\n",
    "                label_file.write(self.id_to_word[index] + '\\n')\n",
    "\n",
    "    def cosine_similarity(self, query1: str, query2: str) -> float:\n",
    "        try:\n",
    "            query1_id = self.word_to_id[query1]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query1}')\n",
    "            raise error\n",
    "        try:\n",
    "            query2_id = self.word_to_id[query2]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query2}')\n",
    "            raise error\n",
    "        vectors = self.embedding[(query1_id, query2_id), :]\n",
    "        similarity = 1 - distance.cosine(vectors[0], vectors[1])\n",
    "        return similarity\n",
    "\n",
    "    def nearest_neighbor(self, query: str, top_k: int = 10):\n",
    "        try:\n",
    "            query_id = self.word_to_id[query]\n",
    "        except KeyError:\n",
    "            raise KeyError(f'{query} is out of vocabulary. Sorry!')    \n",
    "        query_vec = self.embedding[query_id]\n",
    "        \n",
    "        distances = [distance.cosine(query_vec, vec) \n",
    "                     for vec in self.embedding]\n",
    "        neighbors = np.argsort(distances)\n",
    "        print(f\"{query}'s neareset neighbors:\")\n",
    "        for ranking in range(1, top_k + 1):\n",
    "            word_id = neighbors[ranking]\n",
    "            word = self.id_to_word[word_id]\n",
    "            cosine_similarity = 1 - distances[word_id]\n",
    "            print(f'{cosine_similarity:.4f}\\t{word}')\n",
    "        print()\n",
    "        \n",
    "\n",
    "class PhrasePair(NamedTuple):\n",
    "    query: str\n",
    "    neighbor: str\n",
    "    deno_sim: float\n",
    "    cono_sim: float\n",
    "        \n",
    "\n",
    "def load_cherry(path, exclude_hard_examples=True):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['semantic_similarity'] and row['cono_similarity']:\n",
    "                if (exclude_hard_examples and \n",
    "                        'hard example' in row['comment'].lower()):\n",
    "                    continue\n",
    "                data.append(PhrasePair(\n",
    "                    row['query'], \n",
    "                    row['neighbor'], \n",
    "#                     row['query_words'], \n",
    "#                     row['neighbor_words'], \n",
    "                    float(row['semantic_similarity']), \n",
    "                    float(row['cono_similarity'])))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_MTurk_results(path):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['median_deno'] and row['median_query_cono']:\n",
    "                \n",
    "                cono_sim = 5 - abs(\n",
    "                    float(row['median_query_cono']) - \n",
    "                    float(row['median_neighbor_cono']))\n",
    "                \n",
    "                data.append(PhrasePair( \n",
    "                    row['query_words'], \n",
    "                    row['neighbor_words'], \n",
    "                    float(row['median_deno']), \n",
    "                    cono_sim))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def correlate_sim_deltas(model, ref_model, phrase_pairs, verbose=False):\n",
    "    label_deltas = []\n",
    "    model_deltas = []\n",
    "    if verbose:\n",
    "        print(f'deno_sim\\tcono_sim\\tref_sim\\tmodel_sim')\n",
    "    \n",
    "    for pair in phrase_pairs:\n",
    "        try:\n",
    "            sim = model.cosine_similarity(pair.query, pair.neighbor)\n",
    "            ref_sim = ref_model.cosine_similarity(pair.query, pair.neighbor)\n",
    "        except KeyError:\n",
    "            continue \n",
    "        model_delta = sim - ref_sim\n",
    "        model_deltas.append(model_delta)\n",
    "        label_deltas.append(pair.deno_sim - pair.cono_sim)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'{pair.deno_sim}  {pair.cono_sim}  {ref_sim:.2%}  {sim:.2%}  '\n",
    "                  f'{pair.query}  {pair.neighbor}')\n",
    "\n",
    "    median = np.median(model_deltas)\n",
    "    mean = np.mean(model_deltas)\n",
    "    stddev = np.std(model_deltas)\n",
    "    rho, _ = spearmanr(model_deltas, label_deltas)\n",
    "    return rho, median, mean, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cherry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Dem_pairs = load_cherry(    \n",
    "    '../../data/evaluation/cherries/labeled_Dem_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "GOP_pairs = load_cherry(\n",
    "    '../../data/evaluation/cherries/labeled_GOP_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "test_data = Dem_pairs + GOP_pairs\n",
    "\n",
    "# Same entity denotation, different party connotation.\n",
    "euphemism = [pair for pair in test_data\n",
    "             if pair.deno_sim > pair.cono_sim]\n",
    "\n",
    "# Different entity denotation, same party connotation.\n",
    "party_platform = [pair for pair in test_data\n",
    "                  if pair.deno_sim < pair.cono_sim]\n",
    "party_platform += load_cherry(\n",
    "    '../../data/evaluation/cherries/remove_deno.tsv',\n",
    "    exclude_hard_examples=False)\n",
    "\n",
    "print(f'{len(euphemism)} euphemism (deno_sim > cono_sim)')\n",
    "print(f'{len(party_platform)} party platform (deno_sim < cono_sim)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 370 labeled entries at ../../data/evaluation/combined_result.csv\n",
      "14 euphemism (deno_sim > cono_sim)\n",
      "325 party platform (deno_sim < cono_sim)\n"
     ]
    }
   ],
   "source": [
    "# test_data = load_MTurk_results('../../data/evaluation/qualification_30.csv')\n",
    "test_data = load_MTurk_results('../../data/evaluation/combined_result.csv')\n",
    "\n",
    "# Same entity denotation, different party connotation.\n",
    "euphemism = [pair for pair in test_data\n",
    "             if pair.deno_sim > pair.cono_sim]\n",
    "\n",
    "# Different entity denotation, same party connotation.\n",
    "party_platform = [pair for pair in test_data\n",
    "                  if pair.deno_sim < pair.cono_sim]\n",
    "\n",
    "print(f'{len(euphemism)} euphemism (deno_sim > cono_sim)')\n",
    "print(f'{len(party_platform)} party platform (deno_sim < cono_sim)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\t2.0\tswapo\tsovietbacked\n",
      "2.5\t2.0\thanoi\tnorth_vietnam\n",
      "4.5\t4.0\tlaidoff_workers\tdisplaced_workers\n",
      "3.0\t2.0\tclass_sizes\treducing_class_size\n",
      "5.0\t1.0\tdeath_tax\testate_taxes\n",
      "4.0\t3.0\tgovernment_option\tgovernment_health_care\n",
      "2.0\t1.0\tnational_energy_tax\tcarbon_pollution\n",
      "2.5\t2.0\tlivable_wage\tper_child_tax\n",
      "4.0\t3.0\tliving_wage\tminimum_wage\n",
      "4.0\t2.0\toccupation_of_haiti\tinvasion_of_haiti\n",
      "5.0\t1.0\tprivate_accounts\tpersonal_accounts\n",
      "3.0\t2.0\tlibyan_oil\tlibyan\n",
      "2.0\t1.0\telitists\tfar_right\n",
      "3.0\t2.0\tgenocide_convention\tconvention\n"
     ]
    }
   ],
   "source": [
    "# preview\n",
    "for stuff in euphemism:\n",
    "    q, n, d, c = stuff\n",
    "    print(d, c, q, n, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 111,387, num_dimensions = 300\n",
      "Loading embeddings from ../../data/pretrained_word2vec/for_real.txt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pretrained = Embedding('../../data/pretrained_word2vec/for_real.txt', 'plain_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "similarity should increase for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.016\t0.011\t0.025\t-0.112\n",
      "1d -1c/epoch4.pt\t0.012\t0.006\t0.027\t-0.228\n",
      "1d -1c/epoch6.pt\t0.009\t0.002\t0.024\t0.045\n",
      "1d -1c/epoch8.pt\t0.002\t-0.001\t0.021\t-0.045\n",
      "1d -1c/epoch10.pt\t0.005\t0.000\t0.025\t-0.052\n",
      "1d -1c/epoch12.pt\t0.004\t-0.001\t0.022\t-0.228\n",
      "1d -1c/epoch14.pt\t-0.007\t-0.003\t0.027\t-0.131\n",
      "1d -1c/epoch16.pt\t0.004\t0.000\t0.030\t-0.228\n",
      "1d -1c/epoch20.pt\t0.004\t-0.004\t0.032\t-0.262\n",
      "1d -1c/epoch24.pt\t-0.001\t-0.006\t0.036\t-0.183\n",
      "1d -1c/epoch28.pt\t0.009\t-0.001\t0.032\t-0.281\n",
      "1d -1c/epoch30.pt\t0.011\t0.002\t0.029\t-0.228\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.020\t0.019\t0.031\t0.150\n",
      "1d -2c/epoch4.pt\t0.017\t0.009\t0.035\t0.060\n",
      "1d -2c/epoch6.pt\t0.007\t-0.005\t0.036\t0.105\n",
      "1d -2c/epoch8.pt\t0.014\t-0.007\t0.039\t0.045\n",
      "1d -2c/epoch10.pt\t0.001\t-0.009\t0.037\t-0.098\n",
      "1d -2c/epoch12.pt\t0.003\t-0.008\t0.036\t-0.052\n",
      "1d -2c/epoch14.pt\t0.004\t-0.007\t0.037\t-0.295\n",
      "1d -2c/epoch16.pt\t-0.009\t-0.012\t0.030\t-0.190\n",
      "1d -2c/epoch20.pt\t-0.005\t-0.010\t0.033\t0.071\n",
      "1d -2c/epoch24.pt\t-0.008\t-0.012\t0.035\t-0.105\n",
      "1d -2c/epoch28.pt\t-0.013\t-0.015\t0.035\t0.052\n",
      "1d -2c/epoch30.pt\t0.006\t-0.011\t0.040\t-0.124\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.038\t0.035\t0.041\t-0.283\n",
      "1d -4c/epoch4.pt\t0.020\t0.021\t0.036\t-0.131\n",
      "1d -4c/epoch6.pt\t0.033\t0.029\t0.033\t-0.202\n",
      "1d -4c/epoch8.pt\t0.038\t0.023\t0.039\t-0.359\n",
      "1d -4c/epoch10.pt\t0.023\t0.021\t0.030\t-0.726\n",
      "1d -4c/epoch12.pt\t0.016\t0.015\t0.033\t-0.621\n",
      "1d -4c/epoch14.pt\t0.034\t0.022\t0.040\t-0.621\n",
      "1d -4c/epoch16.pt\t0.011\t0.009\t0.032\t-0.464\n",
      "1d -4c/epoch20.pt\t-0.010\t-0.009\t0.038\t-0.071\n",
      "1d -4c/epoch24.pt\t-0.009\t-0.007\t0.036\t-0.098\n",
      "1d -4c/epoch28.pt\t-0.001\t-0.008\t0.045\t0.026\n",
      "1d -4c/epoch30.pt\t0.006\t-0.009\t0.052\t0.195\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.079\t0.084\t0.045\t-0.086\n",
      "1d -8c/epoch4.pt\t0.060\t0.058\t0.051\t-0.100\n",
      "1d -8c/epoch6.pt\t0.063\t0.057\t0.062\t-0.283\n",
      "1d -8c/epoch8.pt\t0.044\t0.038\t0.051\t-0.048\n",
      "1d -8c/epoch10.pt\t0.056\t0.052\t0.061\t-0.219\n",
      "1d -8c/epoch12.pt\t0.059\t0.061\t0.064\t-0.336\n",
      "1d -8c/epoch14.pt\t0.053\t0.043\t0.071\t-0.250\n",
      "1d -8c/epoch16.pt\t0.056\t0.042\t0.068\t-0.050\n",
      "1d -8c/epoch20.pt\t0.052\t0.046\t0.068\t-0.148\n",
      "1d -8c/epoch24.pt\t0.049\t0.041\t0.058\t-0.481\n",
      "1d -8c/epoch28.pt\t0.027\t0.025\t0.062\t-0.559\n",
      "1d -8c/epoch30.pt\t0.043\t0.024\t0.056\t-0.495\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.084\t0.106\t0.061\t-0.212\n",
      "1d -10c/epoch4.pt\t0.095\t0.108\t0.062\t-0.062\n",
      "1d -10c/epoch6.pt\t0.097\t0.120\t0.071\t-0.200\n",
      "1d -10c/epoch8.pt\t0.098\t0.110\t0.065\t-0.409\n",
      "1d -10c/epoch10.pt\t0.120\t0.100\t0.089\t-0.585\n",
      "1d -10c/epoch12.pt\t0.113\t0.091\t0.101\t-0.455\n",
      "1d -10c/epoch14.pt\t0.122\t0.100\t0.099\t-0.481\n",
      "1d -10c/epoch16.pt\t0.122\t0.095\t0.111\t-0.507\n",
      "1d -10c/epoch20.pt\t0.141\t0.101\t0.137\t-0.455\n",
      "1d -10c/epoch24.pt\t0.151\t0.099\t0.132\t-0.428\n",
      "1d -10c/epoch28.pt\t0.149\t0.095\t0.147\t-0.417\n",
      "1d -10c/epoch30.pt\t0.154\t0.089\t0.143\t-0.383\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/' \n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.005\t0.006\t0.016\t-0.355\n",
      "1d -1c/epoch4.pt\t0.015\t0.013\t0.015\t-0.478\n",
      "1d -1c/epoch6.pt\t0.006\t0.010\t0.010\t-0.359\n",
      "1d -1c/epoch8.pt\t0.010\t0.011\t0.013\t-0.445\n",
      "1d -1c/epoch10.pt\t0.007\t0.010\t0.020\t-0.228\n",
      "1d -1c/epoch12.pt\t0.006\t0.008\t0.017\t-0.478\n",
      "1d -1c/epoch14.pt\t0.007\t0.008\t0.015\t-0.426\n",
      "1d -1c/epoch16.pt\t0.012\t0.010\t0.021\t-0.367\n",
      "1d -1c/epoch20.pt\t0.011\t0.009\t0.019\t-0.433\n",
      "1d -1c/epoch24.pt\t0.009\t0.008\t0.020\t-0.262\n",
      "1d -1c/epoch28.pt\t0.021\t0.016\t0.023\t-0.359\n",
      "1d -1c/epoch30.pt\t0.018\t0.019\t0.020\t-0.516\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.016\t0.014\t0.017\t-0.060\n",
      "1d -2c/epoch4.pt\t0.017\t0.015\t0.024\t-0.150\n",
      "1d -2c/epoch6.pt\t0.011\t0.004\t0.024\t-0.052\n",
      "1d -2c/epoch8.pt\t0.009\t0.004\t0.021\t-0.262\n",
      "1d -2c/epoch10.pt\t0.001\t0.001\t0.020\t-0.367\n",
      "1d -2c/epoch12.pt\t0.007\t0.001\t0.029\t-0.243\n",
      "1d -2c/epoch14.pt\t0.008\t0.004\t0.021\t-0.452\n",
      "1d -2c/epoch16.pt\t-0.012\t-0.003\t0.025\t-0.219\n",
      "1d -2c/epoch20.pt\t0.001\t0.002\t0.029\t-0.024\n",
      "1d -2c/epoch24.pt\t0.003\t0.002\t0.029\t-0.419\n",
      "1d -2c/epoch28.pt\t0.001\t0.003\t0.029\t-0.255\n",
      "1d -2c/epoch30.pt\t0.012\t0.006\t0.030\t-0.347\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.024\t0.030\t0.033\t-0.326\n",
      "1d -4c/epoch4.pt\t0.023\t0.028\t0.030\t-0.290\n",
      "1d -4c/epoch6.pt\t0.034\t0.038\t0.036\t-0.471\n",
      "1d -4c/epoch8.pt\t0.038\t0.034\t0.037\t-0.550\n",
      "1d -4c/epoch10.pt\t0.028\t0.031\t0.034\t-0.812\n",
      "1d -4c/epoch12.pt\t0.018\t0.024\t0.031\t-0.674\n",
      "1d -4c/epoch14.pt\t0.036\t0.032\t0.040\t-0.516\n",
      "1d -4c/epoch16.pt\t0.020\t0.019\t0.038\t-0.386\n",
      "1d -4c/epoch20.pt\t0.022\t0.004\t0.040\t-0.060\n",
      "1d -4c/epoch24.pt\t0.017\t0.006\t0.038\t-0.105\n",
      "1d -4c/epoch28.pt\t0.010\t0.010\t0.052\t-0.007\n",
      "1d -4c/epoch30.pt\t0.009\t0.008\t0.058\t0.136\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.065\t0.079\t0.048\t-0.181\n",
      "1d -8c/epoch4.pt\t0.066\t0.065\t0.049\t-0.267\n",
      "1d -8c/epoch6.pt\t0.070\t0.065\t0.066\t-0.312\n",
      "1d -8c/epoch8.pt\t0.052\t0.050\t0.050\t-0.312\n",
      "1d -8c/epoch10.pt\t0.058\t0.062\t0.066\t-0.300\n",
      "1d -8c/epoch12.pt\t0.069\t0.069\t0.066\t-0.324\n",
      "1d -8c/epoch14.pt\t0.059\t0.053\t0.071\t-0.245\n",
      "1d -8c/epoch16.pt\t0.047\t0.051\t0.067\t-0.202\n",
      "1d -8c/epoch20.pt\t0.054\t0.058\t0.058\t-0.124\n",
      "1d -8c/epoch24.pt\t0.053\t0.055\t0.056\t-0.319\n",
      "1d -8c/epoch28.pt\t0.038\t0.043\t0.061\t-0.502\n",
      "1d -8c/epoch30.pt\t0.047\t0.041\t0.067\t-0.405\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.074\t0.102\t0.067\t-0.188\n",
      "1d -10c/epoch4.pt\t0.099\t0.114\t0.073\t-0.102\n",
      "1d -10c/epoch6.pt\t0.119\t0.129\t0.077\t-0.259\n",
      "1d -10c/epoch8.pt\t0.099\t0.122\t0.078\t-0.390\n",
      "1d -10c/epoch10.pt\t0.116\t0.110\t0.102\t-0.469\n",
      "1d -10c/epoch12.pt\t0.117\t0.100\t0.114\t-0.378\n",
      "1d -10c/epoch14.pt\t0.130\t0.110\t0.110\t-0.462\n",
      "1d -10c/epoch16.pt\t0.120\t0.105\t0.119\t-0.469\n",
      "1d -10c/epoch20.pt\t0.145\t0.113\t0.144\t-0.462\n",
      "1d -10c/epoch24.pt\t0.151\t0.113\t0.139\t-0.383\n",
      "1d -10c/epoch28.pt\t0.150\t0.112\t0.148\t-0.364\n",
      "1d -10c/epoch30.pt\t0.145\t0.106\t0.146\t-0.286\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "Similarity should decrease for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.017\t0.016\t0.033\t-0.076\n",
      "1d -1c/epoch4.pt\t0.008\t0.005\t0.035\t-0.022\n",
      "1d -1c/epoch6.pt\t-0.002\t-0.003\t0.037\t0.007\n",
      "1d -1c/epoch8.pt\t-0.006\t-0.005\t0.037\t0.010\n",
      "1d -1c/epoch10.pt\t-0.004\t-0.006\t0.040\t0.050\n",
      "1d -1c/epoch12.pt\t-0.007\t-0.008\t0.037\t0.009\n",
      "1d -1c/epoch14.pt\t-0.004\t-0.006\t0.039\t0.045\n",
      "1d -1c/epoch16.pt\t-0.004\t-0.008\t0.040\t0.077\n",
      "1d -1c/epoch20.pt\t-0.009\t-0.009\t0.041\t0.073\n",
      "1d -1c/epoch24.pt\t-0.009\t-0.009\t0.044\t0.088\n",
      "1d -1c/epoch28.pt\t-0.006\t-0.010\t0.045\t0.072\n",
      "1d -1c/epoch30.pt\t-0.008\t-0.010\t0.044\t0.048\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.027\t0.027\t0.035\t-0.010\n",
      "1d -2c/epoch4.pt\t0.015\t0.015\t0.035\t-0.027\n",
      "1d -2c/epoch6.pt\t0.006\t0.005\t0.036\t-0.027\n",
      "1d -2c/epoch8.pt\t-0.000\t-0.002\t0.039\t-0.001\n",
      "1d -2c/epoch10.pt\t-0.000\t-0.006\t0.038\t-0.048\n",
      "1d -2c/epoch12.pt\t-0.002\t-0.007\t0.039\t0.001\n",
      "1d -2c/epoch14.pt\t-0.007\t-0.009\t0.040\t-0.033\n",
      "1d -2c/epoch16.pt\t-0.004\t-0.011\t0.039\t-0.005\n",
      "1d -2c/epoch20.pt\t-0.010\t-0.010\t0.040\t-0.002\n",
      "1d -2c/epoch24.pt\t-0.007\t-0.012\t0.042\t-0.044\n",
      "1d -2c/epoch28.pt\t-0.009\t-0.014\t0.042\t-0.030\n",
      "1d -2c/epoch30.pt\t-0.007\t-0.011\t0.042\t-0.025\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.047\t0.047\t0.043\t-0.038\n",
      "1d -4c/epoch4.pt\t0.031\t0.033\t0.042\t-0.060\n",
      "1d -4c/epoch6.pt\t0.031\t0.032\t0.045\t-0.075\n",
      "1d -4c/epoch8.pt\t0.025\t0.022\t0.047\t-0.047\n",
      "1d -4c/epoch10.pt\t0.024\t0.021\t0.046\t-0.112\n",
      "1d -4c/epoch12.pt\t0.020\t0.017\t0.045\t-0.091\n",
      "1d -4c/epoch14.pt\t0.018\t0.017\t0.049\t-0.085\n",
      "1d -4c/epoch16.pt\t0.011\t0.011\t0.050\t-0.070\n",
      "1d -4c/epoch20.pt\t0.010\t0.008\t0.050\t-0.065\n",
      "1d -4c/epoch24.pt\t0.008\t0.006\t0.053\t-0.060\n",
      "1d -4c/epoch28.pt\t0.004\t0.000\t0.053\t-0.076\n",
      "1d -4c/epoch30.pt\t0.005\t0.001\t0.051\t-0.090\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.077\t0.081\t0.061\t-0.110\n",
      "1d -8c/epoch4.pt\t0.061\t0.065\t0.063\t-0.083\n",
      "1d -8c/epoch6.pt\t0.056\t0.059\t0.062\t-0.134\n",
      "1d -8c/epoch8.pt\t0.047\t0.050\t0.060\t-0.112\n",
      "1d -8c/epoch10.pt\t0.043\t0.042\t0.060\t-0.094\n",
      "1d -8c/epoch12.pt\t0.054\t0.054\t0.065\t-0.097\n",
      "1d -8c/epoch14.pt\t0.046\t0.047\t0.064\t-0.154\n",
      "1d -8c/epoch16.pt\t0.041\t0.044\t0.062\t-0.090\n",
      "1d -8c/epoch20.pt\t0.050\t0.047\t0.067\t-0.060\n",
      "1d -8c/epoch24.pt\t0.040\t0.043\t0.064\t-0.113\n",
      "1d -8c/epoch28.pt\t0.033\t0.034\t0.062\t-0.131\n",
      "1d -8c/epoch30.pt\t0.034\t0.033\t0.060\t-0.113\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.092\t0.095\t0.080\t-0.093\n",
      "1d -10c/epoch4.pt\t0.090\t0.095\t0.091\t-0.106\n",
      "1d -10c/epoch6.pt\t0.101\t0.104\t0.095\t-0.094\n",
      "1d -10c/epoch8.pt\t0.102\t0.106\t0.106\t-0.074\n",
      "1d -10c/epoch10.pt\t0.095\t0.092\t0.128\t-0.087\n",
      "1d -10c/epoch12.pt\t0.098\t0.097\t0.131\t-0.079\n",
      "1d -10c/epoch14.pt\t0.092\t0.096\t0.136\t-0.102\n",
      "1d -10c/epoch16.pt\t0.089\t0.092\t0.137\t-0.113\n",
      "1d -10c/epoch20.pt\t0.097\t0.092\t0.135\t-0.079\n",
      "1d -10c/epoch24.pt\t0.095\t0.094\t0.139\t-0.097\n",
      "1d -10c/epoch28.pt\t0.092\t0.090\t0.144\t-0.064\n",
      "1d -10c/epoch30.pt\t0.101\t0.091\t0.146\t-0.091\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.008\t0.010\t0.020\t-0.017\n",
      "1d -1c/epoch4.pt\t0.009\t0.011\t0.022\t0.001\n",
      "1d -1c/epoch6.pt\t0.009\t0.009\t0.023\t0.027\n",
      "1d -1c/epoch8.pt\t0.008\t0.009\t0.024\t0.031\n",
      "1d -1c/epoch10.pt\t0.008\t0.009\t0.026\t0.047\n",
      "1d -1c/epoch12.pt\t0.008\t0.009\t0.025\t-0.035\n",
      "1d -1c/epoch14.pt\t0.012\t0.012\t0.029\t0.016\n",
      "1d -1c/epoch16.pt\t0.010\t0.010\t0.028\t0.028\n",
      "1d -1c/epoch20.pt\t0.009\t0.010\t0.031\t0.012\n",
      "1d -1c/epoch24.pt\t0.009\t0.011\t0.035\t0.042\n",
      "1d -1c/epoch28.pt\t0.007\t0.010\t0.033\t0.027\n",
      "1d -1c/epoch30.pt\t0.009\t0.010\t0.034\t0.001\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.018\t0.021\t0.027\t0.035\n",
      "1d -2c/epoch4.pt\t0.019\t0.020\t0.028\t-0.006\n",
      "1d -2c/epoch6.pt\t0.015\t0.016\t0.029\t-0.008\n",
      "1d -2c/epoch8.pt\t0.011\t0.012\t0.029\t-0.002\n",
      "1d -2c/epoch10.pt\t0.009\t0.009\t0.028\t-0.059\n",
      "1d -2c/epoch12.pt\t0.009\t0.010\t0.032\t-0.050\n",
      "1d -2c/epoch14.pt\t0.006\t0.009\t0.033\t-0.049\n",
      "1d -2c/epoch16.pt\t0.006\t0.007\t0.033\t-0.074\n",
      "1d -2c/epoch20.pt\t0.008\t0.009\t0.036\t-0.059\n",
      "1d -2c/epoch24.pt\t0.007\t0.008\t0.036\t-0.094\n",
      "1d -2c/epoch28.pt\t0.007\t0.007\t0.037\t-0.104\n",
      "1d -2c/epoch30.pt\t0.010\t0.009\t0.039\t-0.082\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.037\t0.040\t0.043\t-0.014\n",
      "1d -4c/epoch4.pt\t0.035\t0.038\t0.041\t-0.053\n",
      "1d -4c/epoch6.pt\t0.038\t0.043\t0.049\t-0.092\n",
      "1d -4c/epoch8.pt\t0.030\t0.035\t0.051\t-0.057\n",
      "1d -4c/epoch10.pt\t0.032\t0.036\t0.052\t-0.140\n",
      "1d -4c/epoch12.pt\t0.031\t0.035\t0.052\t-0.115\n",
      "1d -4c/epoch14.pt\t0.031\t0.035\t0.054\t-0.110\n",
      "1d -4c/epoch16.pt\t0.027\t0.029\t0.056\t-0.095\n",
      "1d -4c/epoch20.pt\t0.023\t0.027\t0.059\t-0.113\n",
      "1d -4c/epoch24.pt\t0.027\t0.026\t0.061\t-0.100\n",
      "1d -4c/epoch28.pt\t0.017\t0.020\t0.059\t-0.099\n",
      "1d -4c/epoch30.pt\t0.023\t0.022\t0.058\t-0.113\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.066\t0.074\t0.069\t-0.089\n",
      "1d -8c/epoch4.pt\t0.067\t0.070\t0.071\t-0.074\n",
      "1d -8c/epoch6.pt\t0.067\t0.071\t0.070\t-0.110\n",
      "1d -8c/epoch8.pt\t0.058\t0.064\t0.068\t-0.092\n",
      "1d -8c/epoch10.pt\t0.059\t0.057\t0.070\t-0.099\n",
      "1d -8c/epoch12.pt\t0.063\t0.071\t0.076\t-0.111\n",
      "1d -8c/epoch14.pt\t0.062\t0.065\t0.076\t-0.143\n",
      "1d -8c/epoch16.pt\t0.053\t0.062\t0.078\t-0.106\n",
      "1d -8c/epoch20.pt\t0.058\t0.066\t0.082\t-0.093\n",
      "1d -8c/epoch24.pt\t0.055\t0.063\t0.080\t-0.128\n",
      "1d -8c/epoch28.pt\t0.050\t0.054\t0.076\t-0.139\n",
      "1d -8c/epoch30.pt\t0.042\t0.053\t0.075\t-0.122\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.082\t0.088\t0.088\t-0.059\n",
      "1d -10c/epoch4.pt\t0.093\t0.100\t0.103\t-0.080\n",
      "1d -10c/epoch6.pt\t0.106\t0.116\t0.111\t-0.086\n",
      "1d -10c/epoch8.pt\t0.116\t0.119\t0.122\t-0.074\n",
      "1d -10c/epoch10.pt\t0.103\t0.107\t0.143\t-0.084\n",
      "1d -10c/epoch12.pt\t0.112\t0.114\t0.147\t-0.077\n",
      "1d -10c/epoch14.pt\t0.113\t0.114\t0.153\t-0.093\n",
      "1d -10c/epoch16.pt\t0.107\t0.110\t0.154\t-0.104\n",
      "1d -10c/epoch20.pt\t0.109\t0.111\t0.152\t-0.073\n",
      "1d -10c/epoch24.pt\t0.116\t0.114\t0.154\t-0.085\n",
      "1d -10c/epoch28.pt\t0.118\t0.110\t0.158\t-0.069\n",
      "1d -10c/epoch30.pt\t0.115\t0.111\t0.161\t-0.091\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotaion -d +c models \n",
    "similarity should decrease for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-7.94%\t-7.94%\t12.94%\t-31.18%\n",
      "-0.005d 1c/epoch4.pt\t-4.34%\t-7.42%\t8.94%\t-21.42%\n",
      "-0.005d 1c/epoch6.pt\t-5.97%\t-8.99%\t9.78%\t15.23%\n",
      "-0.005d 1c/epoch8.pt\t-4.40%\t-6.75%\t9.00%\t-24.51%\n",
      "-0.005d 1c/epoch10.pt\t-6.71%\t-9.34%\t11.85%\t-2.38%\n",
      "-0.005d 1c/epoch12.pt\t-7.95%\t-11.25%\t11.01%\t-8.33%\n",
      "-0.005d 1c/epoch14.pt\t-9.84%\t-10.04%\t9.88%\t-8.09%\n",
      "-0.005d 1c/epoch16.pt\t-11.01%\t-9.72%\t7.20%\t-10.23%\n",
      "-0.005d 1c/epoch20.pt\t-10.03%\t-10.45%\t6.26%\t-25.94%\n",
      "-0.005d 1c/epoch24.pt\t-13.80%\t-12.54%\t8.22%\t-7.62%\n",
      "-0.005d 1c/epoch28.pt\t-13.17%\t-10.69%\t7.87%\t-4.76%\n",
      "-0.005d 1c/epoch30.pt\t-12.88%\t-13.20%\t9.90%\t11.42%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t21.40%\t25.12%\t10.16%\t-39.51%\n",
      "-0.05d 1c/epoch4.pt\t21.42%\t25.63%\t10.47%\t-36.18%\n",
      "-0.05d 1c/epoch6.pt\t15.67%\t16.75%\t8.61%\t-39.51%\n",
      "-0.05d 1c/epoch8.pt\t13.77%\t14.92%\t8.86%\t-42.13%\n",
      "-0.05d 1c/epoch10.pt\t11.09%\t11.61%\t8.85%\t-33.80%\n",
      "-0.05d 1c/epoch12.pt\t10.56%\t11.13%\t9.15%\t-29.27%\n",
      "-0.05d 1c/epoch14.pt\t10.82%\t10.45%\t9.23%\t-38.32%\n",
      "-0.05d 1c/epoch16.pt\t16.75%\t19.53%\t9.27%\t-42.84%\n",
      "-0.05d 1c/epoch20.pt\t9.31%\t10.72%\t8.05%\t-29.27%\n",
      "-0.05d 1c/epoch24.pt\t5.60%\t6.77%\t8.21%\t-12.38%\n",
      "-0.05d 1c/epoch28.pt\t5.84%\t5.79%\t8.03%\t-7.14%\n",
      "-0.05d 1c/epoch30.pt\t4.76%\t4.71%\t7.95%\t-9.04%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-7.80%\t-8.05%\t10.86%\t-36.41%\n",
      "-0.01d 1c/epoch4.pt\t-8.26%\t-7.61%\t8.01%\t-27.13%\n",
      "-0.01d 1c/epoch6.pt\t-4.85%\t-9.63%\t9.15%\t5.47%\n",
      "-0.01d 1c/epoch8.pt\t-8.65%\t-8.91%\t8.01%\t-14.76%\n",
      "-0.01d 1c/epoch10.pt\t-9.65%\t-11.25%\t9.44%\t-10.71%\n",
      "-0.01d 1c/epoch12.pt\t-11.84%\t-13.02%\t9.56%\t-10.23%\n",
      "-0.01d 1c/epoch14.pt\t-12.34%\t-12.95%\t9.01%\t-6.19%\n",
      "-0.01d 1c/epoch16.pt\t-13.03%\t-12.13%\t6.60%\t-5.00%\n",
      "-0.01d 1c/epoch20.pt\t-13.66%\t-12.84%\t8.00%\t-2.38%\n",
      "-0.01d 1c/epoch24.pt\t-15.82%\t-14.63%\t8.08%\t1.67%\n",
      "-0.01d 1c/epoch28.pt\t-15.85%\t-13.63%\t7.46%\t-5.00%\n",
      "-0.01d 1c/epoch30.pt\t-15.81%\t-15.47%\t9.70%\t5.47%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t23.96%\t29.22%\t11.83%\t-27.61%\n",
      "-0.1d 1c/epoch4.pt\t24.22%\t29.92%\t12.20%\t-30.23%\n",
      "-0.1d 1c/epoch6.pt\t24.28%\t30.06%\t12.21%\t-30.23%\n",
      "-0.1d 1c/epoch8.pt\t24.25%\t30.07%\t12.23%\t-30.23%\n",
      "-0.1d 1c/epoch10.pt\t24.23%\t30.03%\t12.20%\t-30.23%\n",
      "-0.1d 1c/epoch12.pt\t24.20%\t30.01%\t12.21%\t-30.23%\n",
      "-0.1d 1c/epoch14.pt\t24.09%\t29.90%\t12.18%\t-30.23%\n",
      "-0.1d 1c/epoch16.pt\t23.99%\t29.75%\t12.12%\t-30.23%\n",
      "-0.1d 1c/epoch20.pt\t23.72%\t29.34%\t11.88%\t-35.46%\n",
      "-0.1d 1c/epoch24.pt\t23.19%\t28.54%\t11.51%\t-38.79%\n",
      "-0.1d 1c/epoch28.pt\t22.53%\t27.76%\t11.21%\t-38.79%\n",
      "-0.1d 1c/epoch30.pt\t22.09%\t27.31%\t11.09%\t-36.89%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t24.11%\t29.68%\t11.80%\t-24.99%\n",
      "-0.2d 1c/epoch4.pt\t24.57%\t30.41%\t12.24%\t-24.99%\n",
      "-0.2d 1c/epoch6.pt\t24.74%\t30.56%\t12.29%\t-24.99%\n",
      "-0.2d 1c/epoch8.pt\t24.79%\t30.63%\t12.32%\t-24.99%\n",
      "-0.2d 1c/epoch10.pt\t24.84%\t30.67%\t12.34%\t-24.99%\n",
      "-0.2d 1c/epoch12.pt\t24.86%\t30.71%\t12.36%\t-24.99%\n",
      "-0.2d 1c/epoch14.pt\t24.86%\t30.72%\t12.37%\t-24.99%\n",
      "-0.2d 1c/epoch16.pt\t24.86%\t30.75%\t12.38%\t-24.99%\n",
      "-0.2d 1c/epoch20.pt\t24.90%\t30.76%\t12.38%\t-24.99%\n",
      "-0.2d 1c/epoch24.pt\t24.93%\t30.79%\t12.39%\t-24.99%\n",
      "-0.2d 1c/epoch28.pt\t24.93%\t30.80%\t12.41%\t-24.99%\n",
      "-0.2d 1c/epoch30.pt\t24.94%\t30.81%\t12.41%\t-24.99%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t24.28%\t30.04%\t12.11%\t-24.99%\n",
      "-0.4d 1c/epoch4.pt\t24.69%\t30.58%\t12.32%\t-24.99%\n",
      "-0.4d 1c/epoch6.pt\t24.84%\t30.71%\t12.37%\t-24.99%\n",
      "-0.4d 1c/epoch8.pt\t24.91%\t30.77%\t12.39%\t-24.99%\n",
      "-0.4d 1c/epoch10.pt\t24.95%\t30.82%\t12.41%\t-24.99%\n",
      "-0.4d 1c/epoch12.pt\t24.97%\t30.84%\t12.42%\t-24.99%\n",
      "-0.4d 1c/epoch14.pt\t24.99%\t30.86%\t12.43%\t-24.99%\n",
      "-0.4d 1c/epoch16.pt\t25.00%\t30.88%\t12.44%\t-24.99%\n",
      "-0.4d 1c/epoch20.pt\t25.02%\t30.90%\t12.45%\t-24.99%\n",
      "-0.4d 1c/epoch24.pt\t25.03%\t30.91%\t12.46%\t-24.99%\n",
      "-0.4d 1c/epoch28.pt\t25.04%\t30.92%\t12.46%\t-24.99%\n",
      "-0.4d 1c/epoch30.pt\t25.05%\t30.92%\t12.46%\t-24.99%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t24.42%\t30.23%\t12.19%\t-24.99%\n",
      "-0.8d 1c/epoch4.pt\t24.83%\t30.68%\t12.38%\t-24.99%\n",
      "-0.8d 1c/epoch6.pt\t24.92%\t30.79%\t12.42%\t-24.99%\n",
      "-0.8d 1c/epoch8.pt\t24.96%\t30.83%\t12.43%\t-24.99%\n",
      "-0.8d 1c/epoch10.pt\t24.97%\t30.85%\t12.43%\t-24.99%\n",
      "-0.8d 1c/epoch12.pt\t24.99%\t30.87%\t12.44%\t-24.99%\n",
      "-0.8d 1c/epoch14.pt\t25.01%\t30.87%\t12.45%\t-24.99%\n",
      "-0.8d 1c/epoch16.pt\t25.02%\t30.85%\t12.44%\t-24.99%\n",
      "-0.8d 1c/epoch20.pt\t25.03%\t30.87%\t12.44%\t-24.99%\n",
      "-0.8d 1c/epoch24.pt\t25.04%\t30.89%\t12.45%\t-24.99%\n",
      "-0.8d 1c/epoch28.pt\t25.05%\t30.91%\t12.45%\t-24.99%\n",
      "-0.8d 1c/epoch30.pt\t25.05%\t30.91%\t12.46%\t-24.99%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.31%\t-1.72%\t3.72%\t-0.24%\n",
      "-0.005d 1c/epoch4.pt\t-3.02%\t-2.98%\t3.74%\t39.03%\n",
      "-0.005d 1c/epoch6.pt\t-3.14%\t-2.34%\t2.23%\t41.17%\n",
      "-0.005d 1c/epoch8.pt\t-3.41%\t-4.03%\t4.02%\t36.65%\n",
      "-0.005d 1c/epoch10.pt\t-2.72%\t-3.94%\t4.09%\t28.08%\n",
      "-0.005d 1c/epoch12.pt\t-4.18%\t-3.69%\t4.67%\t5.47%\n",
      "-0.005d 1c/epoch14.pt\t-1.16%\t-2.46%\t3.52%\t0.95%\n",
      "-0.005d 1c/epoch16.pt\t-2.28%\t-3.73%\t5.34%\t-3.33%\n",
      "-0.005d 1c/epoch20.pt\t-2.46%\t-2.66%\t3.68%\t-8.57%\n",
      "-0.005d 1c/epoch24.pt\t-4.92%\t-4.60%\t4.29%\t-34.51%\n",
      "-0.005d 1c/epoch28.pt\t-4.78%\t-5.49%\t5.42%\t-25.70%\n",
      "-0.005d 1c/epoch30.pt\t-4.24%\t-4.82%\t7.51%\t-4.76%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t24.30%\t31.34%\t20.04%\t10.95%\n",
      "-0.05d 1c/epoch4.pt\t29.49%\t30.07%\t15.27%\t11.66%\n",
      "-0.05d 1c/epoch6.pt\t19.78%\t23.40%\t13.32%\t-10.71%\n",
      "-0.05d 1c/epoch8.pt\t16.70%\t17.65%\t10.27%\t5.47%\n",
      "-0.05d 1c/epoch10.pt\t13.02%\t17.02%\t13.15%\t-20.71%\n",
      "-0.05d 1c/epoch12.pt\t14.81%\t18.70%\t14.83%\t-19.28%\n",
      "-0.05d 1c/epoch14.pt\t14.31%\t18.03%\t12.83%\t-15.47%\n",
      "-0.05d 1c/epoch16.pt\t22.14%\t25.52%\t11.39%\t-10.95%\n",
      "-0.05d 1c/epoch20.pt\t15.53%\t18.52%\t10.96%\t7.38%\n",
      "-0.05d 1c/epoch24.pt\t9.97%\t14.72%\t10.35%\t-5.00%\n",
      "-0.05d 1c/epoch28.pt\t9.78%\t10.99%\t9.85%\t-13.57%\n",
      "-0.05d 1c/epoch30.pt\t10.47%\t13.10%\t12.12%\t-12.85%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-2.38%\t-1.83%\t4.60%\t10.23%\n",
      "-0.01d 1c/epoch4.pt\t-2.48%\t-3.16%\t5.86%\t35.94%\n",
      "-0.01d 1c/epoch6.pt\t-2.11%\t-2.98%\t3.36%\t11.90%\n",
      "-0.01d 1c/epoch8.pt\t-6.24%\t-6.19%\t4.08%\t42.60%\n",
      "-0.01d 1c/epoch10.pt\t-5.49%\t-5.84%\t3.46%\t-16.90%\n",
      "-0.01d 1c/epoch12.pt\t-5.93%\t-5.45%\t4.05%\t-23.56%\n",
      "-0.01d 1c/epoch14.pt\t-3.78%\t-5.36%\t4.68%\t23.80%\n",
      "-0.01d 1c/epoch16.pt\t-5.59%\t-6.13%\t3.86%\t14.99%\n",
      "-0.01d 1c/epoch20.pt\t-5.27%\t-5.05%\t4.67%\t20.94%\n",
      "-0.01d 1c/epoch24.pt\t-6.95%\t-6.69%\t4.87%\t-30.94%\n",
      "-0.01d 1c/epoch28.pt\t-7.98%\t-8.42%\t3.72%\t-26.42%\n",
      "-0.01d 1c/epoch30.pt\t-6.08%\t-7.09%\t5.08%\t-7.38%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t27.35%\t35.44%\t22.09%\t10.95%\n",
      "-0.1d 1c/epoch4.pt\t33.32%\t34.36%\t17.16%\t11.66%\n",
      "-0.1d 1c/epoch6.pt\t33.12%\t36.71%\t17.97%\t-15.23%\n",
      "-0.1d 1c/epoch8.pt\t30.84%\t32.79%\t14.90%\t5.00%\n",
      "-0.1d 1c/epoch10.pt\t27.91%\t35.44%\t18.40%\t-12.14%\n",
      "-0.1d 1c/epoch12.pt\t31.14%\t37.58%\t19.97%\t-11.90%\n",
      "-0.1d 1c/epoch14.pt\t33.24%\t37.48%\t18.19%\t-14.04%\n",
      "-0.1d 1c/epoch16.pt\t33.03%\t35.75%\t14.18%\t-8.81%\n",
      "-0.1d 1c/epoch20.pt\t32.05%\t37.13%\t16.45%\t-6.19%\n",
      "-0.1d 1c/epoch24.pt\t27.22%\t36.49%\t16.21%\t-4.28%\n",
      "-0.1d 1c/epoch28.pt\t28.88%\t32.97%\t15.69%\t-8.09%\n",
      "-0.1d 1c/epoch30.pt\t29.17%\t35.69%\t17.52%\t-23.09%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t27.92%\t35.90%\t22.20%\t16.18%\n",
      "-0.2d 1c/epoch4.pt\t33.72%\t34.85%\t17.28%\t11.66%\n",
      "-0.2d 1c/epoch6.pt\t33.90%\t37.21%\t18.11%\t-15.23%\n",
      "-0.2d 1c/epoch8.pt\t31.69%\t33.35%\t15.03%\t5.00%\n",
      "-0.2d 1c/epoch10.pt\t28.57%\t36.08%\t18.56%\t-11.42%\n",
      "-0.2d 1c/epoch12.pt\t31.64%\t38.28%\t20.17%\t-11.90%\n",
      "-0.2d 1c/epoch14.pt\t33.87%\t38.31%\t18.41%\t-14.04%\n",
      "-0.2d 1c/epoch16.pt\t33.80%\t36.74%\t14.48%\t-3.57%\n",
      "-0.2d 1c/epoch20.pt\t33.35%\t38.56%\t17.06%\t-6.19%\n",
      "-0.2d 1c/epoch24.pt\t29.48%\t38.73%\t17.25%\t-0.24%\n",
      "-0.2d 1c/epoch28.pt\t31.66%\t36.00%\t17.05%\t-5.47%\n",
      "-0.2d 1c/epoch30.pt\t32.80%\t39.20%\t18.92%\t-15.23%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t27.95%\t36.26%\t22.52%\t16.18%\n",
      "-0.4d 1c/epoch4.pt\t33.87%\t35.02%\t17.36%\t11.66%\n",
      "-0.4d 1c/epoch6.pt\t34.03%\t37.36%\t18.20%\t-15.23%\n",
      "-0.4d 1c/epoch8.pt\t31.82%\t33.50%\t15.10%\t5.00%\n",
      "-0.4d 1c/epoch10.pt\t28.68%\t36.23%\t18.63%\t-11.42%\n",
      "-0.4d 1c/epoch12.pt\t31.82%\t38.41%\t20.23%\t-11.90%\n",
      "-0.4d 1c/epoch14.pt\t34.03%\t38.44%\t18.49%\t-14.04%\n",
      "-0.4d 1c/epoch16.pt\t33.94%\t36.87%\t14.54%\t-3.57%\n",
      "-0.4d 1c/epoch20.pt\t33.48%\t38.69%\t17.15%\t-6.19%\n",
      "-0.4d 1c/epoch24.pt\t29.66%\t38.85%\t17.33%\t-0.24%\n",
      "-0.4d 1c/epoch28.pt\t31.78%\t36.12%\t17.11%\t-5.47%\n",
      "-0.4d 1c/epoch30.pt\t32.91%\t39.31%\t18.97%\t-15.23%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t28.19%\t36.45%\t22.60%\t16.18%\n",
      "-0.8d 1c/epoch4.pt\t33.93%\t35.12%\t17.43%\t11.66%\n",
      "-0.8d 1c/epoch6.pt\t34.11%\t37.44%\t18.25%\t-15.23%\n",
      "-0.8d 1c/epoch8.pt\t31.88%\t33.56%\t15.16%\t5.00%\n",
      "-0.8d 1c/epoch10.pt\t28.70%\t36.26%\t18.66%\t-11.42%\n",
      "-0.8d 1c/epoch12.pt\t31.84%\t38.44%\t20.25%\t-11.90%\n",
      "-0.8d 1c/epoch14.pt\t34.02%\t38.46%\t18.51%\t-14.04%\n",
      "-0.8d 1c/epoch16.pt\t33.93%\t36.84%\t14.55%\t-3.57%\n",
      "-0.8d 1c/epoch20.pt\t33.48%\t38.66%\t17.15%\t-6.19%\n",
      "-0.8d 1c/epoch24.pt\t29.67%\t38.84%\t17.33%\t-0.24%\n",
      "-0.8d 1c/epoch28.pt\t31.78%\t36.11%\t17.11%\t-5.47%\n",
      "-0.8d 1c/epoch30.pt\t32.91%\t39.30%\t18.97%\t-15.23%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotation -d +c models \n",
    "similarity should increase for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.22%\t-4.62%\t14.51%\t9.38%\n",
      "-0.005d 1c/epoch4.pt\t-3.01%\t-5.28%\t11.75%\t5.70%\n",
      "-0.005d 1c/epoch6.pt\t-4.90%\t-7.31%\t10.50%\t10.38%\n",
      "-0.005d 1c/epoch8.pt\t-6.16%\t-7.83%\t9.71%\t5.10%\n",
      "-0.005d 1c/epoch10.pt\t-6.68%\t-7.85%\t8.16%\t8.27%\n",
      "-0.005d 1c/epoch12.pt\t-7.15%\t-9.04%\t9.08%\t12.39%\n",
      "-0.005d 1c/epoch14.pt\t-8.33%\t-9.75%\t8.97%\t4.32%\n",
      "-0.005d 1c/epoch16.pt\t-9.40%\t-10.57%\t9.23%\t2.73%\n",
      "-0.005d 1c/epoch20.pt\t-10.65%\t-11.34%\t9.20%\t4.75%\n",
      "-0.005d 1c/epoch24.pt\t-11.45%\t-11.77%\t9.12%\t7.39%\n",
      "-0.005d 1c/epoch28.pt\t-10.98%\t-12.43%\t9.55%\t3.08%\n",
      "-0.005d 1c/epoch30.pt\t-10.99%\t-12.53%\t9.22%\t11.09%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t27.94%\t29.01%\t10.94%\t-18.71%\n",
      "-0.05d 1c/epoch4.pt\t28.23%\t29.25%\t11.49%\t-16.78%\n",
      "-0.05d 1c/epoch6.pt\t18.18%\t19.83%\t9.63%\t-15.77%\n",
      "-0.05d 1c/epoch8.pt\t16.18%\t17.22%\t9.20%\t-12.64%\n",
      "-0.05d 1c/epoch10.pt\t12.81%\t13.94%\t9.23%\t-12.63%\n",
      "-0.05d 1c/epoch12.pt\t11.89%\t12.78%\t9.19%\t-12.67%\n",
      "-0.05d 1c/epoch14.pt\t10.89%\t11.93%\t9.16%\t-11.72%\n",
      "-0.05d 1c/epoch16.pt\t20.97%\t21.71%\t9.41%\t-16.65%\n",
      "-0.05d 1c/epoch20.pt\t10.87%\t11.83%\t8.66%\t-11.12%\n",
      "-0.05d 1c/epoch24.pt\t7.36%\t7.85%\t8.81%\t-11.52%\n",
      "-0.05d 1c/epoch28.pt\t6.21%\t6.80%\t8.80%\t-11.08%\n",
      "-0.05d 1c/epoch30.pt\t4.99%\t6.04%\t9.01%\t-11.19%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-3.47%\t-6.28%\t14.31%\t8.35%\n",
      "-0.01d 1c/epoch4.pt\t-6.33%\t-7.67%\t11.39%\t4.64%\n",
      "-0.01d 1c/epoch6.pt\t-7.96%\t-9.77%\t10.12%\t8.43%\n",
      "-0.01d 1c/epoch8.pt\t-8.27%\t-9.90%\t9.17%\t3.90%\n",
      "-0.01d 1c/epoch10.pt\t-9.07%\t-10.74%\t8.96%\t11.81%\n",
      "-0.01d 1c/epoch12.pt\t-10.18%\t-12.26%\t9.89%\t13.30%\n",
      "-0.01d 1c/epoch14.pt\t-11.42%\t-12.62%\t10.14%\t8.94%\n",
      "-0.01d 1c/epoch16.pt\t-12.56%\t-14.04%\t10.20%\t3.95%\n",
      "-0.01d 1c/epoch20.pt\t-12.56%\t-14.44%\t9.93%\t6.94%\n",
      "-0.01d 1c/epoch24.pt\t-13.62%\t-15.20%\t10.05%\t11.57%\n",
      "-0.01d 1c/epoch28.pt\t-14.28%\t-15.30%\t10.29%\t5.20%\n",
      "-0.01d 1c/epoch30.pt\t-14.68%\t-15.45%\t9.83%\t9.95%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t31.39%\t33.34%\t12.38%\t-16.46%\n",
      "-0.1d 1c/epoch4.pt\t32.22%\t34.19%\t12.67%\t-16.14%\n",
      "-0.1d 1c/epoch6.pt\t32.63%\t34.37%\t12.72%\t-16.18%\n",
      "-0.1d 1c/epoch8.pt\t32.64%\t34.36%\t12.69%\t-16.37%\n",
      "-0.1d 1c/epoch10.pt\t32.60%\t34.31%\t12.68%\t-16.21%\n",
      "-0.1d 1c/epoch12.pt\t32.45%\t34.27%\t12.69%\t-16.19%\n",
      "-0.1d 1c/epoch14.pt\t32.34%\t34.14%\t12.65%\t-16.17%\n",
      "-0.1d 1c/epoch16.pt\t32.22%\t33.99%\t12.62%\t-15.92%\n",
      "-0.1d 1c/epoch20.pt\t31.89%\t33.51%\t12.51%\t-15.63%\n",
      "-0.1d 1c/epoch24.pt\t31.21%\t32.62%\t12.34%\t-15.87%\n",
      "-0.1d 1c/epoch28.pt\t30.57%\t31.65%\t12.11%\t-15.95%\n",
      "-0.1d 1c/epoch30.pt\t30.11%\t31.20%\t12.04%\t-16.10%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t32.23%\t34.02%\t12.45%\t-17.08%\n",
      "-0.2d 1c/epoch4.pt\t33.19%\t34.86%\t12.80%\t-16.65%\n",
      "-0.2d 1c/epoch6.pt\t33.38%\t35.12%\t12.94%\t-16.45%\n",
      "-0.2d 1c/epoch8.pt\t33.69%\t35.23%\t12.99%\t-16.41%\n",
      "-0.2d 1c/epoch10.pt\t33.72%\t35.28%\t13.03%\t-16.46%\n",
      "-0.2d 1c/epoch12.pt\t33.73%\t35.32%\t13.05%\t-16.40%\n",
      "-0.2d 1c/epoch14.pt\t33.74%\t35.35%\t13.07%\t-16.44%\n",
      "-0.2d 1c/epoch16.pt\t33.74%\t35.37%\t13.09%\t-16.44%\n",
      "-0.2d 1c/epoch20.pt\t33.76%\t35.41%\t13.11%\t-16.45%\n",
      "-0.2d 1c/epoch24.pt\t33.79%\t35.44%\t13.13%\t-16.43%\n",
      "-0.2d 1c/epoch28.pt\t33.78%\t35.44%\t13.13%\t-16.45%\n",
      "-0.2d 1c/epoch30.pt\t33.80%\t35.46%\t13.14%\t-16.47%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t32.44%\t34.33%\t12.60%\t-16.57%\n",
      "-0.4d 1c/epoch4.pt\t33.61%\t35.10%\t12.91%\t-16.50%\n",
      "-0.4d 1c/epoch6.pt\t33.72%\t35.29%\t13.01%\t-16.42%\n",
      "-0.4d 1c/epoch8.pt\t33.77%\t35.38%\t13.05%\t-16.42%\n",
      "-0.4d 1c/epoch10.pt\t33.80%\t35.43%\t13.09%\t-16.41%\n",
      "-0.4d 1c/epoch12.pt\t33.80%\t35.45%\t13.11%\t-16.43%\n",
      "-0.4d 1c/epoch14.pt\t33.79%\t35.49%\t13.13%\t-16.42%\n",
      "-0.4d 1c/epoch16.pt\t33.81%\t35.51%\t13.15%\t-16.40%\n",
      "-0.4d 1c/epoch20.pt\t33.83%\t35.51%\t13.14%\t-16.46%\n",
      "-0.4d 1c/epoch24.pt\t33.85%\t35.52%\t13.15%\t-16.47%\n",
      "-0.4d 1c/epoch28.pt\t33.86%\t35.52%\t13.15%\t-16.46%\n",
      "-0.4d 1c/epoch30.pt\t33.86%\t35.53%\t13.15%\t-16.45%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t32.71%\t34.45%\t12.58%\t-16.77%\n",
      "-0.8d 1c/epoch4.pt\t33.51%\t35.13%\t12.85%\t-16.62%\n",
      "-0.8d 1c/epoch6.pt\t33.74%\t35.33%\t12.99%\t-16.47%\n",
      "-0.8d 1c/epoch8.pt\t33.79%\t35.42%\t13.06%\t-16.41%\n",
      "-0.8d 1c/epoch10.pt\t33.79%\t35.45%\t13.08%\t-16.43%\n",
      "-0.8d 1c/epoch12.pt\t33.78%\t35.46%\t13.09%\t-16.43%\n",
      "-0.8d 1c/epoch14.pt\t33.62%\t35.41%\t13.07%\t-16.47%\n",
      "-0.8d 1c/epoch16.pt\t33.61%\t35.37%\t13.05%\t-16.48%\n",
      "-0.8d 1c/epoch20.pt\t33.63%\t35.41%\t13.08%\t-16.46%\n",
      "-0.8d 1c/epoch24.pt\t33.64%\t35.42%\t13.09%\t-16.44%\n",
      "-0.8d 1c/epoch28.pt\t33.64%\t35.44%\t13.11%\t-16.42%\n",
      "-0.8d 1c/epoch30.pt\t33.64%\t35.45%\t13.11%\t-16.42%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-2.12%\t-2.15%\t3.41%\t4.94%\n",
      "-0.005d 1c/epoch4.pt\t-1.97%\t-2.53%\t3.92%\t8.06%\n",
      "-0.005d 1c/epoch6.pt\t-3.34%\t-3.51%\t3.94%\t3.09%\n",
      "-0.005d 1c/epoch8.pt\t-3.53%\t-4.14%\t4.18%\t7.01%\n",
      "-0.005d 1c/epoch10.pt\t-4.16%\t-4.23%\t3.87%\t12.60%\n",
      "-0.005d 1c/epoch12.pt\t-4.32%\t-4.44%\t4.18%\t7.39%\n",
      "-0.005d 1c/epoch14.pt\t-4.11%\t-4.58%\t4.42%\t11.72%\n",
      "-0.005d 1c/epoch16.pt\t-4.16%\t-4.29%\t4.52%\t-1.37%\n",
      "-0.005d 1c/epoch20.pt\t-5.08%\t-5.03%\t5.11%\t9.61%\n",
      "-0.005d 1c/epoch24.pt\t-4.43%\t-4.88%\t5.18%\t8.11%\n",
      "-0.005d 1c/epoch28.pt\t-5.47%\t-5.76%\t5.71%\t3.62%\n",
      "-0.005d 1c/epoch30.pt\t-5.02%\t-5.33%\t6.37%\t8.62%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t28.41%\t31.48%\t19.46%\t-17.91%\n",
      "-0.05d 1c/epoch4.pt\t29.19%\t32.00%\t17.93%\t-11.98%\n",
      "-0.05d 1c/epoch6.pt\t21.19%\t23.63%\t14.54%\t-15.03%\n",
      "-0.05d 1c/epoch8.pt\t18.81%\t20.90%\t13.29%\t-8.84%\n",
      "-0.05d 1c/epoch10.pt\t16.56%\t17.56%\t11.96%\t-9.34%\n",
      "-0.05d 1c/epoch12.pt\t15.53%\t17.38%\t12.79%\t-14.15%\n",
      "-0.05d 1c/epoch14.pt\t15.23%\t17.10%\t12.81%\t-6.89%\n",
      "-0.05d 1c/epoch16.pt\t26.59%\t27.99%\t14.58%\t-13.57%\n",
      "-0.05d 1c/epoch20.pt\t17.31%\t18.14%\t12.78%\t-7.24%\n",
      "-0.05d 1c/epoch24.pt\t13.79%\t14.73%\t11.87%\t-9.24%\n",
      "-0.05d 1c/epoch28.pt\t12.42%\t13.46%\t12.14%\t-8.89%\n",
      "-0.05d 1c/epoch30.pt\t11.23%\t13.24%\t12.31%\t-9.50%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-3.71%\t-3.81%\t4.74%\t0.59%\n",
      "-0.01d 1c/epoch4.pt\t-4.65%\t-4.92%\t5.11%\t7.99%\n",
      "-0.01d 1c/epoch6.pt\t-5.78%\t-5.97%\t4.95%\t-1.16%\n",
      "-0.01d 1c/epoch8.pt\t-5.82%\t-6.22%\t5.37%\t3.79%\n",
      "-0.01d 1c/epoch10.pt\t-7.05%\t-7.12%\t5.57%\t18.18%\n",
      "-0.01d 1c/epoch12.pt\t-7.25%\t-7.66%\t5.84%\t6.22%\n",
      "-0.01d 1c/epoch14.pt\t-7.10%\t-7.46%\t5.84%\t15.14%\n",
      "-0.01d 1c/epoch16.pt\t-7.45%\t-7.77%\t5.97%\t-1.56%\n",
      "-0.01d 1c/epoch20.pt\t-7.70%\t-8.13%\t6.46%\t11.70%\n",
      "-0.01d 1c/epoch24.pt\t-7.82%\t-8.32%\t7.09%\t13.02%\n",
      "-0.01d 1c/epoch28.pt\t-7.54%\t-8.63%\t7.65%\t6.68%\n",
      "-0.01d 1c/epoch30.pt\t-7.51%\t-8.24%\t7.78%\t7.36%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t32.74%\t35.81%\t20.84%\t-16.95%\n",
      "-0.1d 1c/epoch4.pt\t34.09%\t36.94%\t19.11%\t-12.20%\n",
      "-0.1d 1c/epoch6.pt\t35.70%\t38.17%\t18.12%\t-16.67%\n",
      "-0.1d 1c/epoch8.pt\t35.17%\t38.04%\t17.41%\t-14.00%\n",
      "-0.1d 1c/epoch10.pt\t35.99%\t37.93%\t16.28%\t-13.48%\n",
      "-0.1d 1c/epoch12.pt\t36.93%\t38.87%\t17.11%\t-16.98%\n",
      "-0.1d 1c/epoch14.pt\t37.02%\t39.31%\t17.19%\t-12.83%\n",
      "-0.1d 1c/epoch16.pt\t37.53%\t40.27%\t17.33%\t-14.39%\n",
      "-0.1d 1c/epoch20.pt\t38.80%\t39.82%\t16.70%\t-11.90%\n",
      "-0.1d 1c/epoch24.pt\t38.04%\t39.51%\t16.58%\t-14.58%\n",
      "-0.1d 1c/epoch28.pt\t36.51%\t38.32%\t16.64%\t-13.12%\n",
      "-0.1d 1c/epoch30.pt\t36.17%\t38.40%\t16.47%\t-15.49%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t33.14%\t36.49%\t20.99%\t-17.51%\n",
      "-0.2d 1c/epoch4.pt\t34.73%\t37.61%\t19.26%\t-12.45%\n",
      "-0.2d 1c/epoch6.pt\t36.34%\t38.92%\t18.26%\t-16.68%\n",
      "-0.2d 1c/epoch8.pt\t35.90%\t38.91%\t17.60%\t-13.97%\n",
      "-0.2d 1c/epoch10.pt\t36.87%\t38.90%\t16.54%\t-13.68%\n",
      "-0.2d 1c/epoch12.pt\t37.94%\t39.92%\t17.32%\t-16.75%\n",
      "-0.2d 1c/epoch14.pt\t37.92%\t40.51%\t17.42%\t-12.69%\n",
      "-0.2d 1c/epoch16.pt\t38.65%\t41.65%\t17.52%\t-14.13%\n",
      "-0.2d 1c/epoch20.pt\t41.02%\t41.72%\t16.99%\t-11.97%\n",
      "-0.2d 1c/epoch24.pt\t40.96%\t42.33%\t17.02%\t-15.07%\n",
      "-0.2d 1c/epoch28.pt\t39.86%\t42.11%\t17.19%\t-13.58%\n",
      "-0.2d 1c/epoch30.pt\t40.52%\t42.67%\t17.09%\t-15.93%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t33.19%\t36.80%\t21.05%\t-16.75%\n",
      "-0.4d 1c/epoch4.pt\t35.05%\t37.85%\t19.31%\t-12.33%\n",
      "-0.4d 1c/epoch6.pt\t36.70%\t39.10%\t18.30%\t-16.54%\n",
      "-0.4d 1c/epoch8.pt\t36.04%\t39.06%\t17.64%\t-13.99%\n",
      "-0.4d 1c/epoch10.pt\t36.96%\t39.05%\t16.60%\t-13.65%\n",
      "-0.4d 1c/epoch12.pt\t38.33%\t40.06%\t17.37%\t-16.73%\n",
      "-0.4d 1c/epoch14.pt\t38.03%\t40.65%\t17.47%\t-12.66%\n",
      "-0.4d 1c/epoch16.pt\t38.81%\t41.79%\t17.56%\t-14.15%\n",
      "-0.4d 1c/epoch20.pt\t41.12%\t41.81%\t17.03%\t-11.87%\n",
      "-0.4d 1c/epoch24.pt\t41.04%\t42.41%\t17.05%\t-14.99%\n",
      "-0.4d 1c/epoch28.pt\t40.23%\t42.19%\t17.22%\t-13.52%\n",
      "-0.4d 1c/epoch30.pt\t40.62%\t42.73%\t17.10%\t-15.90%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t33.75%\t36.92%\t21.11%\t-17.17%\n",
      "-0.8d 1c/epoch4.pt\t35.09%\t37.88%\t19.31%\t-12.55%\n",
      "-0.8d 1c/epoch6.pt\t36.56%\t39.14%\t18.31%\t-16.66%\n",
      "-0.8d 1c/epoch8.pt\t36.09%\t39.11%\t17.66%\t-13.99%\n",
      "-0.8d 1c/epoch10.pt\t37.01%\t39.07%\t16.59%\t-13.66%\n",
      "-0.8d 1c/epoch12.pt\t38.13%\t40.06%\t17.37%\t-16.78%\n",
      "-0.8d 1c/epoch14.pt\t38.05%\t40.57%\t17.44%\t-12.66%\n",
      "-0.8d 1c/epoch16.pt\t38.58%\t41.65%\t17.52%\t-14.21%\n",
      "-0.8d 1c/epoch20.pt\t41.02%\t41.72%\t16.99%\t-12.03%\n",
      "-0.8d 1c/epoch24.pt\t41.01%\t42.31%\t17.02%\t-15.02%\n",
      "-0.8d 1c/epoch28.pt\t40.14%\t42.11%\t17.20%\t-13.53%\n",
      "-0.8d 1c/epoch30.pt\t40.62%\t42.65%\t17.08%\t-15.88%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
