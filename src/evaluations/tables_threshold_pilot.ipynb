{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from typing import Set, Tuple, NamedTuple, List, Dict, Counter, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from decomposer import AdversarialDecomposer, AdversarialConfig\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Embedding():\n",
    "    \n",
    "    def __init__(self, path: str, source: Optional[str] = None):\n",
    "        if source is None or source == 'adversarial':\n",
    "            self.init_from_adversarial(path)\n",
    "        elif source == 'skip_gram':\n",
    "            self.init_from_skip_gram(path)\n",
    "        elif source == 'plain_text':\n",
    "            self.init_from_plain_text(path)\n",
    "        else:\n",
    "            raise ValueError('Unknown embedding source.')\n",
    "            \n",
    "    def init_from_adversarial(self, path: str, device=torch.device('cpu')):\n",
    "        payload = torch.load(path, map_location=device)\n",
    "        model = payload['model']\n",
    "        self.word_to_id = model.word_to_id\n",
    "        self.id_to_word = model.id_to_word \n",
    "        self.Dem_frequency: Counter[str] = model.Dem_frequency\n",
    "        self.GOP_frequency: Counter[str] = model.GOP_frequency\n",
    "        \n",
    "        # encoded layer\n",
    "        self.embedding = model.export_encoded_embedding(device=device)\n",
    "#         self.embedding = model.export_decomposed_embedding(device=device)\n",
    "\n",
    "#         # manually choose which layer to export\n",
    "#         all_vocab_ids = torch.arange(\n",
    "#             len(self.word_to_id), dtype=torch.long, device=device)\n",
    "#         with torch.no_grad():\n",
    "#             embed = model.embedding(all_vocab_ids)\n",
    "#             encoded = model.encoder(embed)\n",
    "#             self.cono_logits = model.cono_decoder(encoded)\n",
    "            \n",
    "#     def init_from_adversarial(self, path: str):        \n",
    "#         config = DenotationEncoderConfig()\n",
    "#         config.input_dir = '../../data/processed/adversarial/44_Obama_1e-5'\n",
    "#         data = AdversarialDataset(config)\n",
    "#         model = DenotationEncoder(config, data)\n",
    "#         model.load_state_dict(torch.load(path))\n",
    "#         self.embedding = model.export_decomposed_embedding().to('cpu')\n",
    "#         self.word_to_id = model.word_to_id\n",
    "#         self.id_to_word = model.id_to_word\n",
    "\n",
    "    def init_from_skip_gram(self, paths: Tuple[str, str]) -> None:\n",
    "        \"\"\"Directly extract the weights of a single layer.\"\"\"\n",
    "        model_path, vocab_path = paths\n",
    "        with open(model_path, 'rb') as model_file:\n",
    "            state_dict = torch.load(model_file, map_location='cpu')\n",
    "    #     print(state_dict.keys())\n",
    "        self.embedding = state_dict['center_embedding.weight'].numpy()\n",
    "        with open(vocab_path, 'rb') as vocab_file:\n",
    "            self.word_to_id, self.id_to_word, _ = pickle.load(vocab_file)\n",
    "\n",
    "    def init_from_plain_text(self, path: str) -> Tuple[np.array, Dict[str, int]]:\n",
    "        id_generator = 0\n",
    "        word_to_id: Dict[str, int] = {}\n",
    "        embeddings: List[float] = []\n",
    "        embedding_file = open(path)\n",
    "        vocab_size, num_dimensions = map(int, embedding_file.readline().split())\n",
    "        print(f'vocab_size = {vocab_size:,}, num_dimensions = {num_dimensions}')\n",
    "        print(f'Loading embeddings from {path}', flush=True)\n",
    "        for line in embedding_file:\n",
    "            line: List[str] = line.split()  # type: ignore\n",
    "            word = line[0]\n",
    "            vector = np.array(line[-num_dimensions:], dtype=np.float64)\n",
    "            embeddings.append(vector)\n",
    "            word_to_id[word] = id_generator\n",
    "            id_generator += 1\n",
    "        embedding_file.close()\n",
    "        print('Done')\n",
    "        self.id_to_word = {val: key for key, val in word_to_id.items()}\n",
    "        self.word_to_id = word_to_id\n",
    "        self.embedding = np.array(embeddings)\n",
    "        \n",
    "    def write_to_tensorboard_projector(self, tb_dir: str) -> None:\n",
    "        from torch.utils import tensorboard\n",
    "        tb = tensorboard.SummaryWriter(log_dir=tb_dir)\n",
    "        all_vocab_ids = range(len(self.word_to_id))\n",
    "        embedding_labels = [\n",
    "            self.id_to_word[word_id]\n",
    "            for word_id in all_vocab_ids]\n",
    "        tb.add_embedding(\n",
    "            self.embedding[:9999], \n",
    "            embedding_labels[:9999], \n",
    "            global_step=0)\n",
    "        \n",
    "    def export_web_projector(self, out_dir: str) -> None:\n",
    "        random_indices = np.random.randint(len(self.embedding), size=10000)\n",
    "        subset_embedding = self.embedding[random_indices].tolist()\n",
    "        \n",
    "        vector_path = os.path.join(out_dir, 'tensorboard.tsv')\n",
    "        with open(vector_path, 'w') as vector_file:\n",
    "            for vector in subset_embedding:\n",
    "                vector_file.write('\\t'.join(map(str, vector)) + '\\n')\n",
    "\n",
    "        label_path = os.path.join(out_dir, 'tensorboard_labels.tsv')\n",
    "        with open(label_path, 'w') as label_file:\n",
    "            for index in random_indices:\n",
    "                label_file.write(self.id_to_word[index] + '\\n')\n",
    "\n",
    "    def cosine_similarity(self, query1: str, query2: str) -> float:\n",
    "        try:\n",
    "            query1_id = self.word_to_id[query1]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query1}')\n",
    "            raise error\n",
    "        try:\n",
    "            query2_id = self.word_to_id[query2]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query2}')\n",
    "            raise error\n",
    "        vectors = self.embedding[(query1_id, query2_id), :]\n",
    "        similarity = 1 - distance.cosine(vectors[0], vectors[1])\n",
    "        return similarity\n",
    "\n",
    "    def nearest_neighbor(self, query: str, top_k: int = 10):\n",
    "        try:\n",
    "            query_id = self.word_to_id[query]\n",
    "        except KeyError:\n",
    "            raise KeyError(f'{query} is out of vocabulary. Sorry!')    \n",
    "        query_vec = self.embedding[query_id]\n",
    "        \n",
    "        distances = [distance.cosine(query_vec, vec) \n",
    "                     for vec in self.embedding]\n",
    "        neighbors = np.argsort(distances)\n",
    "        print(f\"{query}'s neareset neighbors:\")\n",
    "        for ranking in range(1, top_k + 1):\n",
    "            word_id = neighbors[ranking]\n",
    "            word = self.id_to_word[word_id]\n",
    "            cosine_similarity = 1 - distances[word_id]\n",
    "            print(f'{cosine_similarity:.4f}\\t{word}')\n",
    "        print()\n",
    "        \n",
    "\n",
    "class PhrasePair(NamedTuple):\n",
    "    query: str\n",
    "    neighbor: str\n",
    "    deno_sim: float\n",
    "    cono_sim: float\n",
    "    \n",
    "\n",
    "def load_cherry(path, exclude_hard_examples=True):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['semantic_similarity'] and row['cono_similarity']:\n",
    "                if (exclude_hard_examples and \n",
    "                        'hard example' in row['comment'].lower()):\n",
    "                    continue\n",
    "                data.append(PhrasePair(\n",
    "                    row['query'], \n",
    "                    row['neighbor'], \n",
    "#                     row['query_words'], \n",
    "#                     row['neighbor_words'], \n",
    "                    float(row['semantic_similarity']), \n",
    "                    float(row['cono_similarity'])))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_MTurk_results(path):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            qc = row['median_query_cono']\n",
    "            nc = row['median_neighbor_cono']\n",
    "            if qc and nc:  # nonempty string\n",
    "                qc = float(qc)\n",
    "                nc = float(nc)\n",
    "                if qc == 0 or nc == 0:  # unable to judge\n",
    "                    continue\n",
    "                \n",
    "#                 cono_sim = 5 - abs(qc - nc)\n",
    "            \n",
    "                if ((qc > 3 and nc > 3) \n",
    "                        or (qc < 3 and nc < 3) \n",
    "                        or (qc == 3 and nc == 3)):\n",
    "                    cono_sim = 5\n",
    "                else:\n",
    "                    cono_sim = 1\n",
    "    \n",
    "                data.append(PhrasePair( \n",
    "                    row['query_words'], \n",
    "                    row['neighbor_words'], \n",
    "                    float(row['median_deno']), \n",
    "                    cono_sim))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def correlate_sim_deltas(model, ref_model, phrase_pairs, verbose=False):\n",
    "    label_deltas = []\n",
    "    model_deltas = []\n",
    "    if verbose:\n",
    "        print(f'deno_sim\\tcono_sim\\tref_sim\\tmodel_sim')\n",
    "    \n",
    "    for pair in phrase_pairs:\n",
    "        try:\n",
    "            sim = model.cosine_similarity(pair.query, pair.neighbor)\n",
    "            ref_sim = ref_model.cosine_similarity(pair.query, pair.neighbor)\n",
    "        except KeyError:\n",
    "            continue \n",
    "        model_delta = sim - ref_sim\n",
    "        model_deltas.append(model_delta)\n",
    "        label_deltas.append(pair.deno_sim - pair.cono_sim)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'{pair.deno_sim}  {pair.cono_sim}  {ref_sim:.2%}  {sim:.2%}  '\n",
    "                  f'{pair.query}  {pair.neighbor}')\n",
    "\n",
    "    median = np.median(model_deltas)\n",
    "    mean = np.mean(model_deltas)\n",
    "    stddev = np.std(model_deltas)\n",
    "    rho, _ = spearmanr(model_deltas, label_deltas)\n",
    "    return rho, median, mean, stddev\n",
    "\n",
    "\n",
    "def preview(things):\n",
    "    for stuff in things:\n",
    "        q, n, d, c = stuff\n",
    "        print(d, c, q, n, sep='\\t')\n",
    "\n",
    "\n",
    "def same_deno(pair):\n",
    "    return pair.deno_sim >= 3\n",
    "\n",
    "\n",
    "def same_cono(pair):\n",
    "    return pair.cono_sim >= 3\n",
    "        \n",
    "        \n",
    "def is_euphemism(pair) -> bool:\n",
    "    return same_deno(pair) and not same_cono(pair)\n",
    "\n",
    "\n",
    "def is_party_platform(pair) -> bool:\n",
    "    return not same_deno(pair) and same_cono(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cherry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Dem_pairs = load_cherry(    \n",
    "    '../../data/evaluation/cherries/labeled_Dem_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "GOP_pairs = load_cherry(\n",
    "    '../../data/evaluation/cherries/labeled_GOP_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "val_data = Dem_pairs + GOP_pairs\n",
    "\n",
    "euphemism = list(filter(is_euphemism, val_data))\n",
    "party_platform = list(filter(is_party_platform, val_data))\n",
    "party_platform += load_cherry(\n",
    "    '../../data/evaluation/cherries/remove_deno.tsv',\n",
    "    exclude_hard_examples=False)\n",
    "\n",
    "print(f'{len(euphemism)} euphemism')\n",
    "preview(euphemism)\n",
    "print(f'\\n{len(party_platform)} party platform')\n",
    "preview(party_platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualification Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_cherry(\n",
    "    '../../data/evaluation/qualification_30.csv', \n",
    "    exclude_hard_examples=False)\n",
    "\n",
    "euphemism = list(filter(is_euphemism, test_data))\n",
    "party_platform = list(filter(is_party_platform, test_data))\n",
    "\n",
    "print(f'{len(euphemism)} euphemism')\n",
    "print(f'{len(party_platform)} party platform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 318 labeled entries at ../../data/evaluation/combined_result.csv\n",
      "37 euphemism\n",
      "3.0\t1\tobamacare\thealth_care_law\n",
      "3.0\t1\tbilingual_ballots\tvoting_systems\n",
      "3.0\t1\tmedical_liability_insurance\tmedical_liability_crisis\n",
      "3.0\t1\tthe_distinguished_acting_republican_leader\tdistinguished_minority_leader\n",
      "3.0\t1\ttrillion_debt\tnational_debt\n",
      "4.0\t1\trecovery_and_reinvestment\tstimulus\n",
      "4.5\t1\tlaidoff_workers\tdisplaced_workers\n",
      "3.0\t1\ttrillion_in_debt\ttrillion\n",
      "3.0\t1\trepublican_congressman\tthencongressman\n",
      "3.0\t1\tthe_classroom_act\tsmaller_class_size\n",
      "3.0\t1\tincrease_supply\tdrill_our_way\n",
      "3.0\t1\tlilly_ledbetter\tequal_employment_opportunity_commission\n",
      "3.0\t1\tmegabanks\tbanks\n",
      "3.0\t1\tconstitutional_option\tchange_the_rules\n",
      "3.0\t1\tballistic_missile_attack\tlaunchonwarning\n",
      "5.0\t1\tprivate_accounts\tpersonal_accounts\n",
      "3.5\t1\tdrill_our_way\tenergy_independent\n",
      "5.0\t1\tdeath_tax\testate_taxes\n",
      "3.0\t1\tgun_dealers\tgun\n",
      "3.0\t1\tarctic_wildlife_refuge\tnorth_slope\n",
      "4.0\t1\tgovernment_option\tgovernment_health_care\n",
      "3.0\t1\ttax_penalty\tmarriage_penalty_relief\n",
      "3.0\t1\tthe_disclose_act\treal_campaign_finance\n",
      "3.0\t1\tenmons\tsupreme_court_decision\n",
      "3.0\t1\tcedaw\tconvention\n",
      "3.0\t1\tbigspending\tliberals\n",
      "3.0\t1\tnegroes\tnonwhite\n",
      "4.0\t1\tliving_wage\tminimum_wage\n",
      "3.0\t1\tright_to_overtime\tovertime_pay\n",
      "3.0\t1\tbig_banks\taig\n",
      "3.0\t1\tgrowth_rate\tpercent_per_year\n",
      "3.0\t1\tantihunger\tfood_banks\n",
      "3.0\t1\tgun_lobby\tgun_laws\n",
      "3.0\t1\tthe_tax_limitation_amendment\tlower_taxes\n",
      "3.0\t1\ttargeted_tax\tmarriage_penalty_relief\n",
      "3.0\t1\tkilled_by_gunfire\tdied\n",
      "3.0\t1\tmerrill_lynch\twall_street_banks\n",
      "\n",
      "111 party platform\n",
      "2.0\t5\tasian_pacific_americans\thispanicamericans\n",
      "2.0\t5\tgun_safety\tmandatory_minimum_sentencing\n",
      "2.0\t5\teskimos\tarctic_refuge\n",
      "2.0\t5\tasianamerican\thispanicamerican\n",
      "2.0\t5\ttaxes_too_much\tdebt_tax\n",
      "2.0\t5\tlabor_laws\tinternational_labor_organization\n",
      "2.0\t5\tteaching_hospitals\tmedicaid_patients\n",
      "2.0\t5\tpottawatomis\tcherokees\n",
      "2.0\t5\thuman_resources_committee\tthe_family_support_act\n",
      "2.0\t5\tkansai\tfsx_deal\n",
      "2.0\t5\tdrill_our_way\tarctic_wildlife_refuge\n",
      "2.5\t5\twar_against_iraq\tgo_to_war\n",
      "2.5\t5\tmilitary_solution\tpolitical_solution\n",
      "2.0\t5\tdebasement\thigh_interest_rate\n",
      "2.0\t5\tdisabled_veterans_tax\tretirees\n",
      "2.0\t5\tcollege_more_affordable\tperchild_tax_credit\n",
      "2.0\t5\tasianamerican\tsubgroup\n",
      "2.0\t5\tolder_people\tsnowewyden\n",
      "2.0\t5\tlulac\tcongressional_hispanic_caucus\n",
      "2.0\t5\tcost_jobs\tnew_taxes\n",
      "2.0\t5\tclintonmitchell\tnational_health_insurance\n",
      "2.0\t5\tletelier\taugusto\n",
      "2.0\t5\tparamilitaries\tchiapas\n",
      "2.0\t5\thatchleahy\tthe_omnibus_crime_bill\n",
      "2.0\t5\tvenereal\thepatitis_b\n",
      "2.0\t5\tbillion_a_month\tnew_debt\n",
      "2.0\t5\toverthrow_the_government\tnicaragua\n",
      "2.0\t5\tbrief_period\textend_beyond\n",
      "2.0\t5\trove\tpress_secretary\n",
      "2.0\t5\tconkling\twhig\n",
      "2.5\t5\tmaytag\tgalesburg\n",
      "2.0\t5\tnuclear_secrets\tcia_agent\n",
      "2.0\t5\tperchlorate\tradium\n",
      "2.0\t5\tlifetime_appointment\tsecond_highest_court\n",
      "2.0\t5\tkarl_rove\twhite_house\n",
      "2.0\t5\tbreckinridge\thenry_clay\n",
      "2.5\t5\tnasp\taeronautical\n",
      "2.0\t5\tgreenaway\tdistrict_court_judge\n",
      "2.0\t5\tsnowewyden\tmedicare_bill\n",
      "2.0\t5\tconablehance\tlast_years_tax\n",
      "2.0\t5\tlargest_tax_increase\tborrowandspend\n",
      "2.0\t5\tpeople_of_indiana\teighth_district_of\n",
      "2.0\t5\ttaxpayer_funding\tthe_disclose_act\n",
      "2.0\t5\tovervalued_dollar\ttrade_imbalance\n",
      "2.0\t5\thepatitis_b\tvenereal\n",
      "2.0\t5\tearly_grades\treducing_class_size\n",
      "2.0\t5\thealth_care_law\tsecond_opinion\n",
      "2.0\t5\tsave_their_homes\thousing_market\n",
      "2.0\t5\tthe_american_energy_act\tincrease_the_supply\n",
      "1.0\t5\tgun_safety_legislation\tthe_juvenile_justice_bill\n",
      "2.0\t5\tmonterey\tsonoma\n",
      "2.0\t5\tblue_dogs\tfiscal_responsibility\n",
      "2.0\t5\tcredit_authority\tbudget_authority\n",
      "2.0\t5\tnonhispanic\tafrican_americans\n",
      "2.0\t5\trepublican_congressman\tfreshman_class\n",
      "2.0\t5\tpercent_of_social\textend_the_solvency\n",
      "2.0\t5\texxonmobil\tchevron\n",
      "2.0\t5\tbuild_america_bonds\tcreates_jobs\n",
      "2.0\t5\ttax_freedom_day\tcost_of_government\n",
      "2.0\t5\tquickening\twomans_life\n",
      "2.0\t5\tgifted_and_talented\tbasic_skills\n",
      "2.5\t5\tcredit_authority\ttax_expenditures\n",
      "2.0\t5\tnuclear_arms_race\tsuperpowers\n",
      "2.0\t5\teducation_savings_account\tperchild_tax_credit\n",
      "2.0\t5\tfire_safety\tcampus\n",
      "2.0\t5\trecovery_act\tjumpstarting\n",
      "2.0\t5\toctober_surprise\tken_starr\n",
      "2.5\t5\tkagen\tkanjorski\n",
      "2.0\t5\tam_on_tuesday\tam_on_wednesday\n",
      "2.0\t5\textend_the_solvency\tsocial_security_money\n",
      "2.0\t5\tpaydown\ttrillion\n",
      "2.0\t5\tschool_facilities\tthe_teacher_empowerment_act\n",
      "2.5\t5\tmonterey\tmorro\n",
      "2.0\t5\tiraqi_leaders\tpolitical_reconciliation\n",
      "2.0\t5\teliminate_the_marriage\tmarriage_penalty_relief\n",
      "2.0\t5\tearl_warren\tchief_justice_rehnquist\n",
      "2.0\t5\ttraditional_interpretation\tnarrow_interpretation\n",
      "2.0\t5\tmedical_liability\tpass_health_care\n",
      "2.0\t5\trepublican_leaderships\tmajoritys\n",
      "2.0\t5\trepublican_bill\tthe_democratic_bill\n",
      "2.0\t5\tsenators_can_expect\trollcall_votes_today\n",
      "2.0\t5\tpedophile\texploitive\n",
      "2.0\t5\tprogressive_message\tprogressive_caucus\n",
      "2.0\t5\treconsider_laid_upon\tbill_be_considered\n",
      "2.0\t5\tmedgar\tdorothy_height\n",
      "2.0\t5\tredeploy\tforces_in_iraq\n",
      "2.0\t5\tlasater\thillary_rodham_clinton\n",
      "2.0\t5\tcurrent_hate_crimes\thate_crimes_legislation\n",
      "2.0\t5\tmedgar\twiley\n",
      "2.0\t5\ttraumatic_brain\tamputations\n",
      "2.0\t5\tmerkley\tjack_reed\n",
      "2.5\t5\tprovides_for_consideration\tlead_sponsor\n",
      "2.5\t5\tnuclear_weapons_testing\tcomprehensive_test_ban\n",
      "2.5\t5\tfannie_lou_hamer\trosa_parks\n",
      "2.5\t5\tketchikan\tpulp\n",
      "2.0\t5\temployer_mandates\tnational_health_insurance\n",
      "2.0\t5\tlifetime_appointment\tjohn_roberts\n",
      "2.0\t5\tthe_republican_bill\tthe_democrat_bill\n",
      "2.0\t5\tdistrict_of_california\trobert_dornan\n",
      "2.0\t5\thead_start_teachers\tthe_classroom_act\n",
      "2.0\t5\tnational_debt_repayment_act\tsocial_security_trust_fund\n",
      "2.0\t5\tcourts_of_appeals\tmajority_support\n",
      "2.0\t5\tseaport_security\tair_cargo\n",
      "2.0\t5\tmedical_wastes\tsludge\n",
      "2.0\t5\texport_subsidies\tovervalued_dollar\n",
      "2.0\t5\tkaktovik\ttundra\n",
      "2.0\t5\tagrifactories\tfamily_farm\n",
      "2.0\t5\tamniotic_fluid\tstem_cells\n",
      "2.0\t5\tmegaton\tdetonating\n",
      "2.0\t5\tallowed_to_speak\tminutes_in_length\n",
      "2.0\t5\tstate_of_indiana\teighth_congressional_district\n"
     ]
    }
   ],
   "source": [
    "# test_data = load_MTurk_results('../../data/evaluation/qualification_30.csv')\n",
    "test_data = load_MTurk_results('../../data/evaluation/combined_result.csv')\n",
    "\n",
    "euphemism = list(filter(is_euphemism, test_data))\n",
    "party_platform = list(filter(is_party_platform, test_data))\n",
    "\n",
    "print(f'{len(euphemism)} euphemism')\n",
    "preview(euphemism)\n",
    "print(f'\\n{len(party_platform)} party platform')\n",
    "preview(party_platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 111,387, num_dimensions = 300\n",
      "Loading embeddings from ../../data/pretrained_word2vec/for_real.txt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pretrained = Embedding('../../data/pretrained_word2vec/for_real.txt', 'plain_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "similarity should increase for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.020\t0.018\t0.035\t0.039\n",
      "1d -1c/epoch4.pt\t0.015\t0.008\t0.039\t0.160\n",
      "1d -1c/epoch6.pt\t0.002\t-0.001\t0.039\t0.218\n",
      "1d -1c/epoch8.pt\t0.006\t0.001\t0.037\t0.113\n",
      "1d -1c/epoch10.pt\t0.003\t-0.002\t0.043\t0.146\n",
      "1d -1c/epoch12.pt\t0.004\t-0.005\t0.041\t0.166\n",
      "1d -1c/epoch14.pt\t-0.000\t-0.005\t0.040\t0.257\n",
      "1d -1c/epoch16.pt\t-0.001\t-0.007\t0.041\t0.230\n",
      "1d -1c/epoch20.pt\t0.004\t-0.007\t0.045\t0.219\n",
      "1d -1c/epoch24.pt\t-0.000\t-0.009\t0.049\t0.198\n",
      "1d -1c/epoch28.pt\t-0.007\t-0.011\t0.048\t0.297\n",
      "1d -1c/epoch30.pt\t-0.007\t-0.016\t0.048\t0.365\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.039\t0.029\t0.038\t0.218\n",
      "1d -2c/epoch4.pt\t0.022\t0.016\t0.037\t0.231\n",
      "1d -2c/epoch6.pt\t0.006\t0.006\t0.036\t0.361\n",
      "1d -2c/epoch8.pt\t0.009\t0.001\t0.037\t0.360\n",
      "1d -2c/epoch10.pt\t-0.002\t-0.008\t0.037\t0.343\n",
      "1d -2c/epoch12.pt\t0.001\t-0.005\t0.033\t0.336\n",
      "1d -2c/epoch14.pt\t-0.004\t-0.011\t0.040\t0.393\n",
      "1d -2c/epoch16.pt\t-0.005\t-0.011\t0.038\t0.268\n",
      "1d -2c/epoch20.pt\t-0.007\t-0.010\t0.043\t0.342\n",
      "1d -2c/epoch24.pt\t-0.009\t-0.015\t0.041\t0.375\n",
      "1d -2c/epoch28.pt\t-0.011\t-0.017\t0.040\t0.368\n",
      "1d -2c/epoch30.pt\t-0.007\t-0.012\t0.042\t0.346\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.055\t0.048\t0.038\t0.020\n",
      "1d -4c/epoch4.pt\t0.029\t0.031\t0.036\t0.185\n",
      "1d -4c/epoch6.pt\t0.027\t0.021\t0.043\t0.276\n",
      "1d -4c/epoch8.pt\t0.015\t0.008\t0.051\t0.385\n",
      "1d -4c/epoch10.pt\t0.013\t0.003\t0.057\t0.274\n",
      "1d -4c/epoch12.pt\t0.016\t0.002\t0.060\t0.230\n",
      "1d -4c/epoch14.pt\t0.015\t-0.002\t0.064\t0.358\n",
      "1d -4c/epoch16.pt\t0.010\t-0.002\t0.055\t0.199\n",
      "1d -4c/epoch20.pt\t-0.015\t-0.014\t0.061\t0.233\n",
      "1d -4c/epoch24.pt\t-0.011\t-0.019\t0.054\t0.335\n",
      "1d -4c/epoch28.pt\t-0.026\t-0.020\t0.058\t0.332\n",
      "1d -4c/epoch30.pt\t-0.016\t-0.016\t0.058\t0.325\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.069\t0.074\t0.048\t0.173\n",
      "1d -8c/epoch4.pt\t0.064\t0.057\t0.060\t0.183\n",
      "1d -8c/epoch6.pt\t0.055\t0.049\t0.052\t0.167\n",
      "1d -8c/epoch8.pt\t0.051\t0.045\t0.059\t-0.043\n",
      "1d -8c/epoch10.pt\t0.061\t0.046\t0.064\t0.059\n",
      "1d -8c/epoch12.pt\t0.058\t0.056\t0.061\t0.157\n",
      "1d -8c/epoch14.pt\t0.045\t0.042\t0.057\t0.168\n",
      "1d -8c/epoch16.pt\t0.054\t0.045\t0.056\t0.055\n",
      "1d -8c/epoch20.pt\t0.046\t0.053\t0.055\t0.156\n",
      "1d -8c/epoch24.pt\t0.034\t0.037\t0.060\t0.097\n",
      "1d -8c/epoch28.pt\t0.014\t0.017\t0.057\t0.075\n",
      "1d -8c/epoch30.pt\t0.011\t0.016\t0.055\t-0.090\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.096\t0.085\t0.057\t0.113\n",
      "1d -10c/epoch4.pt\t0.088\t0.090\t0.066\t-0.050\n",
      "1d -10c/epoch6.pt\t0.104\t0.098\t0.064\t-0.127\n",
      "1d -10c/epoch8.pt\t0.111\t0.113\t0.062\t-0.314\n",
      "1d -10c/epoch10.pt\t0.086\t0.088\t0.082\t-0.187\n",
      "1d -10c/epoch12.pt\t0.082\t0.093\t0.091\t-0.216\n",
      "1d -10c/epoch14.pt\t0.091\t0.094\t0.096\t-0.211\n",
      "1d -10c/epoch16.pt\t0.083\t0.086\t0.096\t-0.195\n",
      "1d -10c/epoch20.pt\t0.078\t0.084\t0.094\t-0.245\n",
      "1d -10c/epoch24.pt\t0.076\t0.084\t0.100\t-0.282\n",
      "1d -10c/epoch28.pt\t0.074\t0.084\t0.116\t-0.311\n",
      "1d -10c/epoch30.pt\t0.090\t0.078\t0.125\t-0.316\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/' \n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.014\t0.009\t0.020\t-0.300\n",
      "1d -1c/epoch4.pt\t0.012\t0.012\t0.020\t-0.108\n",
      "1d -1c/epoch6.pt\t0.006\t0.009\t0.021\t-0.084\n",
      "1d -1c/epoch8.pt\t0.008\t0.012\t0.023\t-0.208\n",
      "1d -1c/epoch10.pt\t0.009\t0.008\t0.025\t-0.155\n",
      "1d -1c/epoch12.pt\t0.007\t0.006\t0.025\t-0.200\n",
      "1d -1c/epoch14.pt\t0.007\t0.006\t0.024\t0.018\n",
      "1d -1c/epoch16.pt\t0.005\t0.003\t0.026\t-0.062\n",
      "1d -1c/epoch20.pt\t0.005\t0.006\t0.030\t-0.068\n",
      "1d -1c/epoch24.pt\t0.008\t0.006\t0.033\t0.006\n",
      "1d -1c/epoch28.pt\t0.012\t0.006\t0.033\t0.111\n",
      "1d -1c/epoch30.pt\t0.008\t0.000\t0.034\t0.131\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.017\t0.021\t0.025\t-0.065\n",
      "1d -2c/epoch4.pt\t0.023\t0.020\t0.025\t0.056\n",
      "1d -2c/epoch6.pt\t0.018\t0.016\t0.031\t-0.053\n",
      "1d -2c/epoch8.pt\t0.012\t0.011\t0.029\t-0.027\n",
      "1d -2c/epoch10.pt\t0.001\t0.002\t0.027\t0.124\n",
      "1d -2c/epoch12.pt\t0.007\t0.006\t0.024\t-0.048\n",
      "1d -2c/epoch14.pt\t-0.000\t-0.000\t0.030\t0.140\n",
      "1d -2c/epoch16.pt\t-0.001\t-0.001\t0.035\t-0.012\n",
      "1d -2c/epoch20.pt\t0.001\t0.003\t0.038\t0.023\n",
      "1d -2c/epoch24.pt\t-0.001\t-0.000\t0.037\t0.102\n",
      "1d -2c/epoch28.pt\t-0.005\t-0.000\t0.035\t0.088\n",
      "1d -2c/epoch30.pt\t0.006\t0.004\t0.037\t0.126\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.037\t0.040\t0.027\t-0.321\n",
      "1d -4c/epoch4.pt\t0.031\t0.036\t0.026\t-0.125\n",
      "1d -4c/epoch6.pt\t0.026\t0.032\t0.042\t0.041\n",
      "1d -4c/epoch8.pt\t0.021\t0.019\t0.048\t0.185\n",
      "1d -4c/epoch10.pt\t0.011\t0.013\t0.054\t0.117\n",
      "1d -4c/epoch12.pt\t0.003\t0.013\t0.056\t0.069\n",
      "1d -4c/epoch14.pt\t0.015\t0.009\t0.057\t0.158\n",
      "1d -4c/epoch16.pt\t0.002\t0.008\t0.053\t0.022\n",
      "1d -4c/epoch20.pt\t-0.009\t-0.002\t0.058\t0.094\n",
      "1d -4c/epoch24.pt\t-0.001\t-0.004\t0.055\t0.157\n",
      "1d -4c/epoch28.pt\t0.003\t-0.004\t0.058\t0.157\n",
      "1d -4c/epoch30.pt\t-0.000\t0.000\t0.059\t0.114\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.056\t0.066\t0.049\t0.066\n",
      "1d -8c/epoch4.pt\t0.064\t0.061\t0.055\t0.035\n",
      "1d -8c/epoch6.pt\t0.068\t0.059\t0.050\t-0.064\n",
      "1d -8c/epoch8.pt\t0.053\t0.055\t0.053\t-0.142\n",
      "1d -8c/epoch10.pt\t0.059\t0.056\t0.060\t-0.068\n",
      "1d -8c/epoch12.pt\t0.069\t0.067\t0.058\t-0.059\n",
      "1d -8c/epoch14.pt\t0.053\t0.052\t0.056\t-0.045\n",
      "1d -8c/epoch16.pt\t0.044\t0.055\t0.053\t-0.093\n",
      "1d -8c/epoch20.pt\t0.058\t0.066\t0.060\t-0.015\n",
      "1d -8c/epoch24.pt\t0.045\t0.052\t0.068\t-0.071\n",
      "1d -8c/epoch28.pt\t0.031\t0.034\t0.064\t-0.113\n",
      "1d -8c/epoch30.pt\t0.010\t0.032\t0.065\t-0.224\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.067\t0.077\t0.061\t-0.021\n",
      "1d -10c/epoch4.pt\t0.093\t0.094\t0.075\t-0.138\n",
      "1d -10c/epoch6.pt\t0.117\t0.108\t0.078\t-0.255\n",
      "1d -10c/epoch8.pt\t0.128\t0.124\t0.075\t-0.391\n",
      "1d -10c/epoch10.pt\t0.088\t0.098\t0.091\t-0.277\n",
      "1d -10c/epoch12.pt\t0.107\t0.104\t0.102\t-0.342\n",
      "1d -10c/epoch14.pt\t0.103\t0.105\t0.109\t-0.275\n",
      "1d -10c/epoch16.pt\t0.086\t0.096\t0.108\t-0.277\n",
      "1d -10c/epoch20.pt\t0.090\t0.096\t0.107\t-0.318\n",
      "1d -10c/epoch24.pt\t0.095\t0.099\t0.111\t-0.349\n",
      "1d -10c/epoch28.pt\t0.109\t0.100\t0.127\t-0.394\n",
      "1d -10c/epoch30.pt\t0.112\t0.095\t0.137\t-0.393\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "Similarity should decrease for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.018\t0.016\t0.032\t0.044\n",
      "1d -1c/epoch4.pt\t0.007\t0.004\t0.035\t0.137\n",
      "1d -1c/epoch6.pt\t0.000\t-0.005\t0.039\t0.087\n",
      "1d -1c/epoch8.pt\t-0.005\t-0.009\t0.040\t0.126\n",
      "1d -1c/epoch10.pt\t-0.005\t-0.010\t0.042\t0.036\n",
      "1d -1c/epoch12.pt\t-0.004\t-0.010\t0.041\t0.048\n",
      "1d -1c/epoch14.pt\t-0.003\t-0.009\t0.043\t-0.000\n",
      "1d -1c/epoch16.pt\t-0.009\t-0.012\t0.043\t-0.007\n",
      "1d -1c/epoch20.pt\t-0.011\t-0.012\t0.042\t-0.022\n",
      "1d -1c/epoch24.pt\t-0.013\t-0.014\t0.048\t0.006\n",
      "1d -1c/epoch28.pt\t-0.015\t-0.016\t0.050\t-0.064\n",
      "1d -1c/epoch30.pt\t-0.009\t-0.014\t0.048\t-0.040\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.033\t0.028\t0.035\t-0.052\n",
      "1d -2c/epoch4.pt\t0.017\t0.015\t0.037\t-0.002\n",
      "1d -2c/epoch6.pt\t0.007\t0.003\t0.038\t0.010\n",
      "1d -2c/epoch8.pt\t0.000\t-0.005\t0.041\t0.080\n",
      "1d -2c/epoch10.pt\t0.006\t-0.005\t0.041\t0.081\n",
      "1d -2c/epoch12.pt\t0.002\t-0.008\t0.043\t0.026\n",
      "1d -2c/epoch14.pt\t-0.003\t-0.010\t0.043\t0.090\n",
      "1d -2c/epoch16.pt\t0.000\t-0.011\t0.041\t0.160\n",
      "1d -2c/epoch20.pt\t-0.009\t-0.011\t0.041\t0.027\n",
      "1d -2c/epoch24.pt\t-0.004\t-0.013\t0.046\t0.053\n",
      "1d -2c/epoch28.pt\t-0.006\t-0.013\t0.045\t0.124\n",
      "1d -2c/epoch30.pt\t-0.003\t-0.010\t0.044\t0.127\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.047\t0.049\t0.048\t-0.091\n",
      "1d -4c/epoch4.pt\t0.031\t0.034\t0.044\t0.004\n",
      "1d -4c/epoch6.pt\t0.033\t0.036\t0.044\t0.002\n",
      "1d -4c/epoch8.pt\t0.024\t0.023\t0.049\t-0.028\n",
      "1d -4c/epoch10.pt\t0.024\t0.026\t0.046\t-0.134\n",
      "1d -4c/epoch12.pt\t0.023\t0.022\t0.047\t-0.198\n",
      "1d -4c/epoch14.pt\t0.026\t0.023\t0.052\t-0.142\n",
      "1d -4c/epoch16.pt\t0.020\t0.016\t0.054\t-0.130\n",
      "1d -4c/epoch20.pt\t0.014\t0.013\t0.055\t-0.090\n",
      "1d -4c/epoch24.pt\t0.018\t0.013\t0.057\t-0.102\n",
      "1d -4c/epoch28.pt\t0.012\t0.007\t0.055\t-0.071\n",
      "1d -4c/epoch30.pt\t0.014\t0.007\t0.051\t-0.080\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.080\t0.087\t0.067\t-0.078\n",
      "1d -8c/epoch4.pt\t0.064\t0.074\t0.068\t-0.200\n",
      "1d -8c/epoch6.pt\t0.065\t0.069\t0.065\t-0.127\n",
      "1d -8c/epoch8.pt\t0.057\t0.059\t0.066\t-0.202\n",
      "1d -8c/epoch10.pt\t0.046\t0.049\t0.063\t-0.242\n",
      "1d -8c/epoch12.pt\t0.063\t0.066\t0.068\t-0.254\n",
      "1d -8c/epoch14.pt\t0.056\t0.063\t0.066\t-0.176\n",
      "1d -8c/epoch16.pt\t0.049\t0.057\t0.069\t-0.168\n",
      "1d -8c/epoch20.pt\t0.057\t0.056\t0.074\t-0.193\n",
      "1d -8c/epoch24.pt\t0.050\t0.055\t0.062\t-0.070\n",
      "1d -8c/epoch28.pt\t0.040\t0.045\t0.061\t-0.134\n",
      "1d -8c/epoch30.pt\t0.037\t0.041\t0.058\t-0.066\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.100\t0.101\t0.089\t-0.123\n",
      "1d -10c/epoch4.pt\t0.098\t0.109\t0.098\t-0.141\n",
      "1d -10c/epoch6.pt\t0.106\t0.118\t0.108\t-0.106\n",
      "1d -10c/epoch8.pt\t0.107\t0.117\t0.119\t-0.105\n",
      "1d -10c/epoch10.pt\t0.099\t0.098\t0.140\t-0.079\n",
      "1d -10c/epoch12.pt\t0.102\t0.106\t0.139\t-0.098\n",
      "1d -10c/epoch14.pt\t0.101\t0.113\t0.137\t-0.103\n",
      "1d -10c/epoch16.pt\t0.101\t0.109\t0.140\t-0.079\n",
      "1d -10c/epoch20.pt\t0.097\t0.106\t0.141\t-0.040\n",
      "1d -10c/epoch24.pt\t0.111\t0.111\t0.146\t-0.008\n",
      "1d -10c/epoch28.pt\t0.101\t0.108\t0.149\t0.015\n",
      "1d -10c/epoch30.pt\t0.107\t0.109\t0.151\t0.019\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.008\t0.011\t0.020\t-0.062\n",
      "1d -1c/epoch4.pt\t0.011\t0.012\t0.024\t-0.060\n",
      "1d -1c/epoch6.pt\t0.009\t0.010\t0.025\t-0.050\n",
      "1d -1c/epoch8.pt\t0.010\t0.009\t0.025\t0.006\n",
      "1d -1c/epoch10.pt\t0.004\t0.009\t0.025\t-0.141\n",
      "1d -1c/epoch12.pt\t0.009\t0.011\t0.026\t-0.108\n",
      "1d -1c/epoch14.pt\t0.014\t0.014\t0.031\t-0.143\n",
      "1d -1c/epoch16.pt\t0.010\t0.010\t0.027\t-0.159\n",
      "1d -1c/epoch20.pt\t0.011\t0.012\t0.032\t-0.176\n",
      "1d -1c/epoch24.pt\t0.010\t0.012\t0.034\t-0.147\n",
      "1d -1c/epoch28.pt\t0.010\t0.010\t0.034\t-0.221\n",
      "1d -1c/epoch30.pt\t0.010\t0.012\t0.034\t-0.152\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.022\t0.023\t0.028\t-0.155\n",
      "1d -2c/epoch4.pt\t0.022\t0.023\t0.032\t-0.147\n",
      "1d -2c/epoch6.pt\t0.016\t0.019\t0.030\t-0.142\n",
      "1d -2c/epoch8.pt\t0.012\t0.014\t0.028\t-0.011\n",
      "1d -2c/epoch10.pt\t0.015\t0.014\t0.026\t-0.018\n",
      "1d -2c/epoch12.pt\t0.012\t0.014\t0.031\t-0.101\n",
      "1d -2c/epoch14.pt\t0.013\t0.012\t0.031\t-0.004\n",
      "1d -2c/epoch16.pt\t0.014\t0.011\t0.032\t0.040\n",
      "1d -2c/epoch20.pt\t0.014\t0.013\t0.036\t-0.040\n",
      "1d -2c/epoch24.pt\t0.015\t0.013\t0.035\t-0.055\n",
      "1d -2c/epoch28.pt\t0.015\t0.012\t0.036\t0.050\n",
      "1d -2c/epoch30.pt\t0.019\t0.016\t0.040\t0.004\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.042\t0.044\t0.050\t-0.156\n",
      "1d -4c/epoch4.pt\t0.041\t0.042\t0.045\t-0.109\n",
      "1d -4c/epoch6.pt\t0.042\t0.051\t0.051\t-0.050\n",
      "1d -4c/epoch8.pt\t0.033\t0.041\t0.054\t-0.086\n",
      "1d -4c/epoch10.pt\t0.043\t0.045\t0.054\t-0.198\n",
      "1d -4c/epoch12.pt\t0.040\t0.044\t0.056\t-0.224\n",
      "1d -4c/epoch14.pt\t0.039\t0.046\t0.057\t-0.211\n",
      "1d -4c/epoch16.pt\t0.034\t0.038\t0.062\t-0.189\n",
      "1d -4c/epoch20.pt\t0.036\t0.038\t0.063\t-0.166\n",
      "1d -4c/epoch24.pt\t0.034\t0.039\t0.064\t-0.172\n",
      "1d -4c/epoch28.pt\t0.029\t0.032\t0.061\t-0.153\n",
      "1d -4c/epoch30.pt\t0.033\t0.033\t0.059\t-0.154\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.082\t0.082\t0.077\t-0.107\n",
      "1d -8c/epoch4.pt\t0.073\t0.083\t0.080\t-0.231\n",
      "1d -8c/epoch6.pt\t0.071\t0.084\t0.078\t-0.182\n",
      "1d -8c/epoch8.pt\t0.068\t0.077\t0.080\t-0.227\n",
      "1d -8c/epoch10.pt\t0.063\t0.068\t0.075\t-0.256\n",
      "1d -8c/epoch12.pt\t0.084\t0.088\t0.083\t-0.250\n",
      "1d -8c/epoch14.pt\t0.074\t0.086\t0.083\t-0.169\n",
      "1d -8c/epoch16.pt\t0.075\t0.080\t0.088\t-0.174\n",
      "1d -8c/epoch20.pt\t0.079\t0.080\t0.092\t-0.192\n",
      "1d -8c/epoch24.pt\t0.078\t0.081\t0.081\t-0.120\n",
      "1d -8c/epoch28.pt\t0.061\t0.070\t0.076\t-0.165\n",
      "1d -8c/epoch30.pt\t0.064\t0.067\t0.076\t-0.094\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.088\t0.095\t0.097\t-0.126\n",
      "1d -10c/epoch4.pt\t0.097\t0.117\t0.112\t-0.163\n",
      "1d -10c/epoch6.pt\t0.117\t0.134\t0.124\t-0.129\n",
      "1d -10c/epoch8.pt\t0.133\t0.136\t0.137\t-0.119\n",
      "1d -10c/epoch10.pt\t0.113\t0.117\t0.154\t-0.109\n",
      "1d -10c/epoch12.pt\t0.128\t0.127\t0.154\t-0.128\n",
      "1d -10c/epoch14.pt\t0.128\t0.136\t0.152\t-0.121\n",
      "1d -10c/epoch16.pt\t0.123\t0.131\t0.156\t-0.098\n",
      "1d -10c/epoch20.pt\t0.130\t0.130\t0.157\t-0.081\n",
      "1d -10c/epoch24.pt\t0.130\t0.137\t0.161\t-0.040\n",
      "1d -10c/epoch28.pt\t0.131\t0.134\t0.162\t-0.031\n",
      "1d -10c/epoch30.pt\t0.137\t0.135\t0.164\t-0.018\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotaion -d +c models \n",
    "similarity should decrease for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-3.23%\t-3.30%\t12.66%\t-7.91%\n",
      "-0.005d 1c/epoch4.pt\t-3.15%\t-4.38%\t9.17%\t-31.55%\n",
      "-0.005d 1c/epoch6.pt\t-6.44%\t-7.02%\t7.88%\t-15.84%\n",
      "-0.005d 1c/epoch8.pt\t-7.49%\t-8.33%\t8.87%\t-15.81%\n",
      "-0.005d 1c/epoch10.pt\t-6.13%\t-7.68%\t6.86%\t-3.85%\n",
      "-0.005d 1c/epoch12.pt\t-8.69%\t-8.85%\t6.99%\t1.37%\n",
      "-0.005d 1c/epoch14.pt\t-9.09%\t-10.10%\t8.35%\t-3.49%\n",
      "-0.005d 1c/epoch16.pt\t-10.92%\t-11.49%\t7.98%\t-1.49%\n",
      "-0.005d 1c/epoch20.pt\t-11.19%\t-13.32%\t9.18%\t-3.75%\n",
      "-0.005d 1c/epoch24.pt\t-13.06%\t-13.10%\t8.58%\t-7.34%\n",
      "-0.005d 1c/epoch28.pt\t-13.65%\t-14.44%\t9.16%\t11.99%\n",
      "-0.005d 1c/epoch30.pt\t-12.41%\t-13.15%\t8.81%\t-0.61%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t25.88%\t26.57%\t8.70%\t-49.03%\n",
      "-0.05d 1c/epoch4.pt\t26.74%\t26.79%\t8.82%\t-48.35%\n",
      "-0.05d 1c/epoch6.pt\t18.42%\t18.40%\t8.49%\t-41.98%\n",
      "-0.05d 1c/epoch8.pt\t16.91%\t16.30%\t8.43%\t-39.53%\n",
      "-0.05d 1c/epoch10.pt\t13.68%\t13.10%\t8.65%\t-38.30%\n",
      "-0.05d 1c/epoch12.pt\t11.85%\t11.77%\t8.62%\t-33.96%\n",
      "-0.05d 1c/epoch14.pt\t11.34%\t10.86%\t8.50%\t-34.10%\n",
      "-0.05d 1c/epoch16.pt\t19.42%\t19.67%\t7.99%\t-42.90%\n",
      "-0.05d 1c/epoch20.pt\t10.39%\t10.73%\t7.98%\t-30.80%\n",
      "-0.05d 1c/epoch24.pt\t7.43%\t6.69%\t7.69%\t-24.61%\n",
      "-0.05d 1c/epoch28.pt\t6.06%\t5.69%\t7.69%\t-23.86%\n",
      "-0.05d 1c/epoch30.pt\t5.80%\t5.18%\t7.86%\t-27.99%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-5.67%\t-5.14%\t12.76%\t-11.80%\n",
      "-0.01d 1c/epoch4.pt\t-5.45%\t-6.32%\t8.22%\t-11.04%\n",
      "-0.01d 1c/epoch6.pt\t-10.43%\t-9.86%\t8.48%\t-6.26%\n",
      "-0.01d 1c/epoch8.pt\t-10.04%\t-10.73%\t9.48%\t-14.39%\n",
      "-0.01d 1c/epoch10.pt\t-10.15%\t-11.30%\t8.69%\t-3.57%\n",
      "-0.01d 1c/epoch12.pt\t-11.79%\t-12.41%\t8.56%\t2.08%\n",
      "-0.01d 1c/epoch14.pt\t-12.78%\t-13.86%\t10.41%\t-7.84%\n",
      "-0.01d 1c/epoch16.pt\t-13.04%\t-15.19%\t9.04%\t-2.79%\n",
      "-0.01d 1c/epoch20.pt\t-14.07%\t-16.16%\t9.80%\t4.08%\n",
      "-0.01d 1c/epoch24.pt\t-13.80%\t-16.53%\t9.01%\t0.61%\n",
      "-0.01d 1c/epoch28.pt\t-16.48%\t-18.17%\t9.20%\t5.78%\n",
      "-0.01d 1c/epoch30.pt\t-16.13%\t-16.67%\t8.64%\t2.86%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t29.90%\t30.28%\t9.20%\t-50.00%\n",
      "-0.1d 1c/epoch4.pt\t30.91%\t31.10%\t9.51%\t-50.07%\n",
      "-0.1d 1c/epoch6.pt\t31.36%\t31.30%\t9.62%\t-49.46%\n",
      "-0.1d 1c/epoch8.pt\t31.40%\t31.31%\t9.60%\t-49.46%\n",
      "-0.1d 1c/epoch10.pt\t31.39%\t31.26%\t9.57%\t-49.46%\n",
      "-0.1d 1c/epoch12.pt\t31.23%\t31.20%\t9.57%\t-49.46%\n",
      "-0.1d 1c/epoch14.pt\t30.92%\t31.11%\t9.55%\t-49.46%\n",
      "-0.1d 1c/epoch16.pt\t30.58%\t30.98%\t9.54%\t-49.46%\n",
      "-0.1d 1c/epoch20.pt\t29.77%\t30.60%\t9.47%\t-50.05%\n",
      "-0.1d 1c/epoch24.pt\t28.28%\t29.80%\t9.33%\t-49.63%\n",
      "-0.1d 1c/epoch28.pt\t27.44%\t28.98%\t9.24%\t-49.03%\n",
      "-0.1d 1c/epoch30.pt\t27.11%\t28.59%\t9.31%\t-47.81%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t31.12%\t31.06%\t9.44%\t-49.34%\n",
      "-0.2d 1c/epoch4.pt\t31.80%\t31.79%\t9.76%\t-49.95%\n",
      "-0.2d 1c/epoch6.pt\t31.97%\t32.00%\t9.90%\t-49.95%\n",
      "-0.2d 1c/epoch8.pt\t32.05%\t32.09%\t9.94%\t-49.95%\n",
      "-0.2d 1c/epoch10.pt\t32.04%\t32.12%\t9.96%\t-49.95%\n",
      "-0.2d 1c/epoch12.pt\t32.07%\t32.16%\t9.99%\t-49.95%\n",
      "-0.2d 1c/epoch14.pt\t32.10%\t32.18%\t10.00%\t-49.95%\n",
      "-0.2d 1c/epoch16.pt\t32.12%\t32.20%\t10.01%\t-49.95%\n",
      "-0.2d 1c/epoch20.pt\t32.15%\t32.24%\t10.04%\t-49.95%\n",
      "-0.2d 1c/epoch24.pt\t32.16%\t32.26%\t10.06%\t-49.95%\n",
      "-0.2d 1c/epoch28.pt\t32.17%\t32.25%\t10.05%\t-49.95%\n",
      "-0.2d 1c/epoch30.pt\t32.18%\t32.27%\t10.05%\t-49.95%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t31.57%\t31.24%\t9.35%\t-49.95%\n",
      "-0.4d 1c/epoch4.pt\t31.95%\t31.95%\t9.79%\t-49.95%\n",
      "-0.4d 1c/epoch6.pt\t32.09%\t32.13%\t9.93%\t-49.95%\n",
      "-0.4d 1c/epoch8.pt\t32.14%\t32.21%\t9.98%\t-49.95%\n",
      "-0.4d 1c/epoch10.pt\t32.17%\t32.25%\t10.00%\t-49.22%\n",
      "-0.4d 1c/epoch12.pt\t32.20%\t32.27%\t10.01%\t-49.22%\n",
      "-0.4d 1c/epoch14.pt\t32.21%\t32.29%\t10.01%\t-49.22%\n",
      "-0.4d 1c/epoch16.pt\t32.23%\t32.31%\t10.01%\t-49.22%\n",
      "-0.4d 1c/epoch20.pt\t32.25%\t32.25%\t9.87%\t-49.22%\n",
      "-0.4d 1c/epoch24.pt\t32.26%\t32.25%\t9.84%\t-49.22%\n",
      "-0.4d 1c/epoch28.pt\t32.27%\t32.25%\t9.82%\t-49.22%\n",
      "-0.4d 1c/epoch30.pt\t32.27%\t32.25%\t9.83%\t-49.22%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t31.55%\t31.41%\t9.38%\t-49.95%\n",
      "-0.8d 1c/epoch4.pt\t32.01%\t32.03%\t9.79%\t-49.22%\n",
      "-0.8d 1c/epoch6.pt\t32.14%\t32.19%\t9.93%\t-49.22%\n",
      "-0.8d 1c/epoch8.pt\t32.19%\t32.26%\t9.98%\t-49.22%\n",
      "-0.8d 1c/epoch10.pt\t32.19%\t32.26%\t9.97%\t-49.22%\n",
      "-0.8d 1c/epoch12.pt\t32.22%\t32.25%\t9.92%\t-49.22%\n",
      "-0.8d 1c/epoch14.pt\t32.21%\t32.13%\t9.70%\t-49.22%\n",
      "-0.8d 1c/epoch16.pt\t32.22%\t32.04%\t9.57%\t-49.22%\n",
      "-0.8d 1c/epoch20.pt\t32.25%\t32.09%\t9.61%\t-49.22%\n",
      "-0.8d 1c/epoch24.pt\t32.26%\t32.10%\t9.60%\t-49.22%\n",
      "-0.8d 1c/epoch28.pt\t32.27%\t32.13%\t9.63%\t-49.22%\n",
      "-0.8d 1c/epoch30.pt\t32.27%\t32.14%\t9.65%\t-49.22%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.49%\t-2.08%\t3.65%\t16.30%\n",
      "-0.005d 1c/epoch4.pt\t-1.78%\t-1.98%\t2.96%\t1.82%\n",
      "-0.005d 1c/epoch6.pt\t-3.78%\t-3.44%\t3.42%\t6.87%\n",
      "-0.005d 1c/epoch8.pt\t-5.01%\t-4.59%\t3.79%\t4.96%\n",
      "-0.005d 1c/epoch10.pt\t-4.12%\t-4.20%\t3.36%\t-4.46%\n",
      "-0.005d 1c/epoch12.pt\t-4.12%\t-4.50%\t3.19%\t9.18%\n",
      "-0.005d 1c/epoch14.pt\t-4.22%\t-4.23%\t4.21%\t9.39%\n",
      "-0.005d 1c/epoch16.pt\t-5.62%\t-5.11%\t4.61%\t13.94%\n",
      "-0.005d 1c/epoch20.pt\t-5.32%\t-5.04%\t5.82%\t10.41%\n",
      "-0.005d 1c/epoch24.pt\t-4.97%\t-4.92%\t5.15%\t6.87%\n",
      "-0.005d 1c/epoch28.pt\t-5.66%\t-6.42%\t4.66%\t9.46%\n",
      "-0.005d 1c/epoch30.pt\t-5.67%\t-5.59%\t6.16%\t3.87%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t23.12%\t27.79%\t15.47%\t-14.54%\n",
      "-0.05d 1c/epoch4.pt\t28.99%\t29.18%\t12.14%\t-11.80%\n",
      "-0.05d 1c/epoch6.pt\t20.02%\t21.98%\t11.22%\t-17.84%\n",
      "-0.05d 1c/epoch8.pt\t18.12%\t20.05%\t10.46%\t-24.71%\n",
      "-0.05d 1c/epoch10.pt\t18.20%\t16.58%\t9.83%\t-31.97%\n",
      "-0.05d 1c/epoch12.pt\t14.17%\t16.12%\t11.46%\t-24.71%\n",
      "-0.05d 1c/epoch14.pt\t14.36%\t16.73%\t12.81%\t-19.32%\n",
      "-0.05d 1c/epoch16.pt\t23.19%\t26.05%\t13.40%\t-20.27%\n",
      "-0.05d 1c/epoch20.pt\t18.62%\t19.01%\t13.23%\t-20.11%\n",
      "-0.05d 1c/epoch24.pt\t13.45%\t14.87%\t11.85%\t-15.81%\n",
      "-0.05d 1c/epoch28.pt\t11.42%\t13.71%\t12.74%\t-22.46%\n",
      "-0.05d 1c/epoch30.pt\t9.17%\t12.75%\t12.19%\t-21.28%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-3.96%\t-3.92%\t4.71%\t11.14%\n",
      "-0.01d 1c/epoch4.pt\t-4.09%\t-3.93%\t3.81%\t48.26%\n",
      "-0.01d 1c/epoch6.pt\t-6.68%\t-6.29%\t4.09%\t15.76%\n",
      "-0.01d 1c/epoch8.pt\t-5.67%\t-6.98%\t5.32%\t16.63%\n",
      "-0.01d 1c/epoch10.pt\t-7.75%\t-7.82%\t4.92%\t-4.29%\n",
      "-0.01d 1c/epoch12.pt\t-7.83%\t-8.06%\t4.61%\t13.88%\n",
      "-0.01d 1c/epoch14.pt\t-7.47%\t-7.98%\t6.38%\t4.46%\n",
      "-0.01d 1c/epoch16.pt\t-8.69%\t-8.81%\t4.67%\t12.22%\n",
      "-0.01d 1c/epoch20.pt\t-7.18%\t-7.87%\t6.34%\t10.17%\n",
      "-0.01d 1c/epoch24.pt\t-7.12%\t-8.35%\t6.37%\t16.10%\n",
      "-0.01d 1c/epoch28.pt\t-9.08%\t-10.15%\t6.78%\t4.39%\n",
      "-0.01d 1c/epoch30.pt\t-9.57%\t-9.10%\t6.97%\t3.25%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t27.09%\t31.50%\t15.83%\t-16.36%\n",
      "-0.1d 1c/epoch4.pt\t33.45%\t33.49%\t12.77%\t-15.76%\n",
      "-0.1d 1c/epoch6.pt\t33.22%\t34.87%\t12.18%\t-25.22%\n",
      "-0.1d 1c/epoch8.pt\t35.52%\t35.06%\t11.83%\t-29.64%\n",
      "-0.1d 1c/epoch10.pt\t34.90%\t34.75%\t11.25%\t-42.00%\n",
      "-0.1d 1c/epoch12.pt\t35.66%\t35.54%\t12.16%\t-37.92%\n",
      "-0.1d 1c/epoch14.pt\t37.02%\t36.98%\t14.42%\t-31.36%\n",
      "-0.1d 1c/epoch16.pt\t35.31%\t37.36%\t14.05%\t-33.60%\n",
      "-0.1d 1c/epoch20.pt\t41.34%\t38.89%\t14.74%\t-34.47%\n",
      "-0.1d 1c/epoch24.pt\t38.50%\t37.98%\t14.08%\t-32.63%\n",
      "-0.1d 1c/epoch28.pt\t36.74%\t37.00%\t15.25%\t-34.71%\n",
      "-0.1d 1c/epoch30.pt\t35.70%\t36.15%\t14.80%\t-35.47%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t28.28%\t32.28%\t15.91%\t-17.11%\n",
      "-0.2d 1c/epoch4.pt\t34.09%\t34.18%\t13.00%\t-16.36%\n",
      "-0.2d 1c/epoch6.pt\t33.75%\t35.58%\t12.47%\t-25.22%\n",
      "-0.2d 1c/epoch8.pt\t35.99%\t35.83%\t12.17%\t-30.25%\n",
      "-0.2d 1c/epoch10.pt\t35.41%\t35.61%\t11.71%\t-42.00%\n",
      "-0.2d 1c/epoch12.pt\t36.24%\t36.50%\t12.51%\t-36.84%\n",
      "-0.2d 1c/epoch14.pt\t37.68%\t38.05%\t14.80%\t-31.24%\n",
      "-0.2d 1c/epoch16.pt\t36.24%\t38.58%\t14.34%\t-32.99%\n",
      "-0.2d 1c/epoch20.pt\t43.04%\t40.52%\t15.06%\t-34.47%\n",
      "-0.2d 1c/epoch24.pt\t41.16%\t40.44%\t14.60%\t-33.16%\n",
      "-0.2d 1c/epoch28.pt\t41.47%\t40.27%\t15.82%\t-34.34%\n",
      "-0.2d 1c/epoch30.pt\t39.23%\t39.84%\t15.49%\t-35.04%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t28.47%\t32.46%\t15.87%\t-17.77%\n",
      "-0.4d 1c/epoch4.pt\t34.30%\t34.34%\t13.03%\t-16.36%\n",
      "-0.4d 1c/epoch6.pt\t33.87%\t35.71%\t12.50%\t-25.22%\n",
      "-0.4d 1c/epoch8.pt\t36.08%\t35.96%\t12.22%\t-30.25%\n",
      "-0.4d 1c/epoch10.pt\t35.50%\t35.74%\t11.75%\t-42.00%\n",
      "-0.4d 1c/epoch12.pt\t36.32%\t36.61%\t12.54%\t-36.30%\n",
      "-0.4d 1c/epoch14.pt\t37.87%\t38.16%\t14.82%\t-31.24%\n",
      "-0.4d 1c/epoch16.pt\t36.33%\t38.69%\t14.34%\t-32.26%\n",
      "-0.4d 1c/epoch20.pt\t43.18%\t40.53%\t14.99%\t-33.74%\n",
      "-0.4d 1c/epoch24.pt\t41.21%\t40.43%\t14.45%\t-33.16%\n",
      "-0.4d 1c/epoch28.pt\t41.52%\t40.26%\t15.69%\t-34.88%\n",
      "-0.4d 1c/epoch30.pt\t39.32%\t39.81%\t15.32%\t-35.04%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t28.81%\t32.63%\t15.86%\t-17.23%\n",
      "-0.8d 1c/epoch4.pt\t34.43%\t34.42%\t13.02%\t-16.36%\n",
      "-0.8d 1c/epoch6.pt\t33.93%\t35.77%\t12.50%\t-25.22%\n",
      "-0.8d 1c/epoch8.pt\t36.14%\t36.00%\t12.21%\t-30.25%\n",
      "-0.8d 1c/epoch10.pt\t35.50%\t35.75%\t11.72%\t-42.00%\n",
      "-0.8d 1c/epoch12.pt\t36.33%\t36.60%\t12.48%\t-36.84%\n",
      "-0.8d 1c/epoch14.pt\t37.90%\t38.00%\t14.58%\t-31.24%\n",
      "-0.8d 1c/epoch16.pt\t36.34%\t38.42%\t14.10%\t-32.87%\n",
      "-0.8d 1c/epoch20.pt\t43.17%\t40.37%\t14.88%\t-33.20%\n",
      "-0.8d 1c/epoch24.pt\t41.19%\t40.28%\t14.28%\t-33.16%\n",
      "-0.8d 1c/epoch28.pt\t41.46%\t40.14%\t15.58%\t-34.88%\n",
      "-0.8d 1c/epoch30.pt\t39.28%\t39.71%\t15.17%\t-35.04%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotation -d +c models \n",
    "similarity should increase for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-2.35%\t-5.07%\t14.75%\t13.70%\n",
      "-0.005d 1c/epoch4.pt\t-3.15%\t-5.32%\t11.80%\t17.44%\n",
      "-0.005d 1c/epoch6.pt\t-5.01%\t-7.53%\t10.33%\t25.93%\n",
      "-0.005d 1c/epoch8.pt\t-6.67%\t-7.60%\t9.32%\t14.64%\n",
      "-0.005d 1c/epoch10.pt\t-6.75%\t-7.70%\t8.23%\t31.50%\n",
      "-0.005d 1c/epoch12.pt\t-8.18%\t-9.25%\t8.89%\t25.94%\n",
      "-0.005d 1c/epoch14.pt\t-6.97%\t-9.77%\t9.27%\t16.92%\n",
      "-0.005d 1c/epoch16.pt\t-9.10%\t-10.17%\t9.41%\t18.06%\n",
      "-0.005d 1c/epoch20.pt\t-11.00%\t-11.48%\t9.15%\t15.94%\n",
      "-0.005d 1c/epoch24.pt\t-12.41%\t-12.32%\t9.43%\t29.29%\n",
      "-0.005d 1c/epoch28.pt\t-11.38%\t-12.72%\t9.75%\t19.38%\n",
      "-0.005d 1c/epoch30.pt\t-12.02%\t-13.19%\t9.71%\t16.11%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t30.32%\t30.67%\t11.33%\t0.95%\n",
      "-0.05d 1c/epoch4.pt\t30.13%\t30.80%\t12.26%\t2.09%\n",
      "-0.05d 1c/epoch6.pt\t19.64%\t21.48%\t10.39%\t6.45%\n",
      "-0.05d 1c/epoch8.pt\t17.01%\t18.77%\t9.93%\t8.22%\n",
      "-0.05d 1c/epoch10.pt\t13.35%\t15.61%\t9.89%\t9.61%\n",
      "-0.05d 1c/epoch12.pt\t12.61%\t14.53%\t9.86%\t10.75%\n",
      "-0.05d 1c/epoch14.pt\t11.62%\t13.64%\t9.90%\t10.93%\n",
      "-0.05d 1c/epoch16.pt\t22.03%\t23.17%\t9.91%\t1.59%\n",
      "-0.05d 1c/epoch20.pt\t11.01%\t13.36%\t9.12%\t6.69%\n",
      "-0.05d 1c/epoch24.pt\t7.83%\t9.30%\t9.35%\t9.71%\n",
      "-0.05d 1c/epoch28.pt\t6.97%\t8.22%\t9.32%\t13.39%\n",
      "-0.05d 1c/epoch30.pt\t5.88%\t7.35%\t9.60%\t13.59%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-4.20%\t-6.91%\t14.17%\t12.53%\n",
      "-0.01d 1c/epoch4.pt\t-5.73%\t-7.45%\t11.64%\t13.00%\n",
      "-0.01d 1c/epoch6.pt\t-8.37%\t-9.64%\t9.66%\t17.67%\n",
      "-0.01d 1c/epoch8.pt\t-7.53%\t-9.49%\t8.97%\t10.85%\n",
      "-0.01d 1c/epoch10.pt\t-9.07%\t-10.83%\t8.87%\t26.39%\n",
      "-0.01d 1c/epoch12.pt\t-9.86%\t-12.67%\t9.82%\t21.17%\n",
      "-0.01d 1c/epoch14.pt\t-11.76%\t-12.96%\t10.36%\t21.94%\n",
      "-0.01d 1c/epoch16.pt\t-12.46%\t-13.67%\t9.82%\t27.56%\n",
      "-0.01d 1c/epoch20.pt\t-13.54%\t-15.08%\t9.86%\t22.99%\n",
      "-0.01d 1c/epoch24.pt\t-15.36%\t-16.29%\t9.76%\t23.99%\n",
      "-0.01d 1c/epoch28.pt\t-15.03%\t-15.92%\t10.34%\t17.78%\n",
      "-0.01d 1c/epoch30.pt\t-15.30%\t-16.28%\t9.82%\t10.37%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t34.36%\t35.06%\t12.69%\t-0.10%\n",
      "-0.1d 1c/epoch4.pt\t35.33%\t35.84%\t12.96%\t-0.55%\n",
      "-0.1d 1c/epoch6.pt\t35.38%\t36.03%\t13.05%\t0.16%\n",
      "-0.1d 1c/epoch8.pt\t35.26%\t36.05%\t13.04%\t0.16%\n",
      "-0.1d 1c/epoch10.pt\t35.12%\t35.99%\t13.06%\t0.16%\n",
      "-0.1d 1c/epoch12.pt\t35.14%\t35.93%\t13.09%\t0.51%\n",
      "-0.1d 1c/epoch14.pt\t35.00%\t35.82%\t13.05%\t0.60%\n",
      "-0.1d 1c/epoch16.pt\t34.83%\t35.63%\t13.05%\t0.42%\n",
      "-0.1d 1c/epoch20.pt\t34.49%\t35.10%\t12.98%\t0.51%\n",
      "-0.1d 1c/epoch24.pt\t33.58%\t34.15%\t12.89%\t0.89%\n",
      "-0.1d 1c/epoch28.pt\t32.39%\t33.18%\t12.66%\t1.26%\n",
      "-0.1d 1c/epoch30.pt\t31.69%\t32.72%\t12.60%\t1.35%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t34.88%\t35.77%\t12.74%\t-0.20%\n",
      "-0.2d 1c/epoch4.pt\t35.75%\t36.58%\t13.06%\t0.06%\n",
      "-0.2d 1c/epoch6.pt\t35.95%\t36.81%\t13.14%\t0.05%\n",
      "-0.2d 1c/epoch8.pt\t35.97%\t36.91%\t13.17%\t-0.04%\n",
      "-0.2d 1c/epoch10.pt\t35.99%\t36.96%\t13.19%\t0.05%\n",
      "-0.2d 1c/epoch12.pt\t36.00%\t37.00%\t13.20%\t0.05%\n",
      "-0.2d 1c/epoch14.pt\t36.03%\t37.02%\t13.21%\t-0.04%\n",
      "-0.2d 1c/epoch16.pt\t36.03%\t37.04%\t13.22%\t-0.04%\n",
      "-0.2d 1c/epoch20.pt\t36.06%\t37.07%\t13.23%\t-0.13%\n",
      "-0.2d 1c/epoch24.pt\t36.08%\t37.10%\t13.24%\t-0.13%\n",
      "-0.2d 1c/epoch28.pt\t36.05%\t37.10%\t13.24%\t-0.13%\n",
      "-0.2d 1c/epoch30.pt\t36.06%\t37.12%\t13.25%\t-0.22%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t35.39%\t36.05%\t12.85%\t-1.11%\n",
      "-0.4d 1c/epoch4.pt\t35.91%\t36.79%\t13.09%\t-0.31%\n",
      "-0.4d 1c/epoch6.pt\t36.02%\t36.97%\t13.16%\t-0.04%\n",
      "-0.4d 1c/epoch8.pt\t36.06%\t37.05%\t13.19%\t-0.13%\n",
      "-0.4d 1c/epoch10.pt\t36.08%\t37.10%\t13.22%\t-0.22%\n",
      "-0.4d 1c/epoch12.pt\t36.08%\t37.13%\t13.23%\t-0.22%\n",
      "-0.4d 1c/epoch14.pt\t36.10%\t37.16%\t13.24%\t-0.22%\n",
      "-0.4d 1c/epoch16.pt\t36.12%\t37.18%\t13.26%\t-0.22%\n",
      "-0.4d 1c/epoch20.pt\t36.12%\t37.19%\t13.27%\t-0.22%\n",
      "-0.4d 1c/epoch24.pt\t36.13%\t37.21%\t13.28%\t-0.31%\n",
      "-0.4d 1c/epoch28.pt\t36.13%\t37.22%\t13.28%\t-0.31%\n",
      "-0.4d 1c/epoch30.pt\t36.13%\t37.22%\t13.28%\t-0.31%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t35.47%\t36.23%\t12.90%\t-1.02%\n",
      "-0.8d 1c/epoch4.pt\t35.92%\t36.86%\t13.08%\t-0.04%\n",
      "-0.8d 1c/epoch6.pt\t36.05%\t37.03%\t13.17%\t-0.04%\n",
      "-0.8d 1c/epoch8.pt\t36.09%\t37.11%\t13.21%\t-0.13%\n",
      "-0.8d 1c/epoch10.pt\t36.10%\t37.13%\t13.23%\t-0.13%\n",
      "-0.8d 1c/epoch12.pt\t36.11%\t37.15%\t13.24%\t-0.22%\n",
      "-0.8d 1c/epoch14.pt\t36.10%\t37.13%\t13.23%\t-0.22%\n",
      "-0.8d 1c/epoch16.pt\t36.08%\t37.10%\t13.23%\t-0.50%\n",
      "-0.8d 1c/epoch20.pt\t36.10%\t37.15%\t13.25%\t-0.58%\n",
      "-0.8d 1c/epoch24.pt\t36.11%\t37.16%\t13.26%\t-0.67%\n",
      "-0.8d 1c/epoch28.pt\t36.11%\t37.18%\t13.27%\t-0.58%\n",
      "-0.8d 1c/epoch30.pt\t36.12%\t37.19%\t13.27%\t-0.58%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-2.07%\t-2.43%\t3.26%\t-13.37%\n",
      "-0.005d 1c/epoch4.pt\t-2.13%\t-2.70%\t4.23%\t15.58%\n",
      "-0.005d 1c/epoch6.pt\t-3.39%\t-3.53%\t4.55%\t5.30%\n",
      "-0.005d 1c/epoch8.pt\t-3.67%\t-4.26%\t3.91%\t3.78%\n",
      "-0.005d 1c/epoch10.pt\t-4.11%\t-4.57%\t4.02%\t11.90%\n",
      "-0.005d 1c/epoch12.pt\t-4.55%\t-4.57%\t4.48%\t13.97%\n",
      "-0.005d 1c/epoch14.pt\t-4.21%\t-4.94%\t4.61%\t8.99%\n",
      "-0.005d 1c/epoch16.pt\t-4.09%\t-3.81%\t4.63%\t5.23%\n",
      "-0.005d 1c/epoch20.pt\t-5.24%\t-5.40%\t4.94%\t3.78%\n",
      "-0.005d 1c/epoch24.pt\t-4.80%\t-5.37%\t4.55%\t18.40%\n",
      "-0.005d 1c/epoch28.pt\t-5.03%\t-6.06%\t6.32%\t6.46%\n",
      "-0.005d 1c/epoch30.pt\t-5.45%\t-6.10%\t6.43%\t3.00%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t29.32%\t33.31%\t19.95%\t-8.81%\n",
      "-0.05d 1c/epoch4.pt\t29.19%\t33.42%\t19.18%\t-2.10%\n",
      "-0.05d 1c/epoch6.pt\t23.02%\t25.48%\t15.04%\t-9.55%\n",
      "-0.05d 1c/epoch8.pt\t19.16%\t22.11%\t13.73%\t-2.79%\n",
      "-0.05d 1c/epoch10.pt\t17.03%\t18.75%\t13.38%\t-6.44%\n",
      "-0.05d 1c/epoch12.pt\t17.29%\t19.21%\t13.97%\t-2.64%\n",
      "-0.05d 1c/epoch14.pt\t15.09%\t18.47%\t13.71%\t-2.18%\n",
      "-0.05d 1c/epoch16.pt\t27.70%\t29.53%\t15.35%\t-7.00%\n",
      "-0.05d 1c/epoch20.pt\t17.41%\t19.45%\t13.49%\t-6.26%\n",
      "-0.05d 1c/epoch24.pt\t14.09%\t16.25%\t12.35%\t-6.64%\n",
      "-0.05d 1c/epoch28.pt\t12.29%\t14.88%\t12.62%\t-1.89%\n",
      "-0.05d 1c/epoch30.pt\t11.16%\t14.44%\t12.70%\t-2.92%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-3.94%\t-4.27%\t4.77%\t-14.78%\n",
      "-0.01d 1c/epoch4.pt\t-4.27%\t-4.83%\t5.45%\t12.16%\n",
      "-0.01d 1c/epoch6.pt\t-5.65%\t-5.64%\t5.20%\t-6.14%\n",
      "-0.01d 1c/epoch8.pt\t-5.59%\t-6.14%\t5.12%\t-4.60%\n",
      "-0.01d 1c/epoch10.pt\t-7.85%\t-7.69%\t5.57%\t9.57%\n",
      "-0.01d 1c/epoch12.pt\t-7.63%\t-7.99%\t6.06%\t2.65%\n",
      "-0.01d 1c/epoch14.pt\t-7.32%\t-8.13%\t6.02%\t13.15%\n",
      "-0.01d 1c/epoch16.pt\t-6.43%\t-7.31%\t5.78%\t18.40%\n",
      "-0.01d 1c/epoch20.pt\t-8.92%\t-8.99%\t6.61%\t11.03%\n",
      "-0.01d 1c/epoch24.pt\t-8.60%\t-9.33%\t6.76%\t8.85%\n",
      "-0.01d 1c/epoch28.pt\t-7.46%\t-9.25%\t7.97%\t4.31%\n",
      "-0.01d 1c/epoch30.pt\t-7.58%\t-9.18%\t7.66%\t-2.16%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t32.61%\t37.70%\t21.33%\t-8.54%\n",
      "-0.1d 1c/epoch4.pt\t34.69%\t38.45%\t20.11%\t-4.45%\n",
      "-0.1d 1c/epoch6.pt\t37.31%\t40.03%\t18.38%\t-12.55%\n",
      "-0.1d 1c/epoch8.pt\t35.82%\t39.40%\t17.22%\t-7.92%\n",
      "-0.1d 1c/epoch10.pt\t36.73%\t39.12%\t17.00%\t-10.05%\n",
      "-0.1d 1c/epoch12.pt\t39.36%\t40.61%\t17.67%\t-8.37%\n",
      "-0.1d 1c/epoch14.pt\t37.83%\t40.65%\t17.95%\t-8.02%\n",
      "-0.1d 1c/epoch16.pt\t39.97%\t41.99%\t17.98%\t-7.40%\n",
      "-0.1d 1c/epoch20.pt\t40.78%\t41.18%\t17.37%\t-7.84%\n",
      "-0.1d 1c/epoch24.pt\t41.02%\t41.10%\t16.88%\t-8.34%\n",
      "-0.1d 1c/epoch28.pt\t37.76%\t39.84%\t17.24%\t-5.81%\n",
      "-0.1d 1c/epoch30.pt\t38.37%\t39.81%\t16.75%\t-6.24%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t33.07%\t38.41%\t21.37%\t-8.97%\n",
      "-0.2d 1c/epoch4.pt\t35.87%\t39.20%\t20.22%\t-3.91%\n",
      "-0.2d 1c/epoch6.pt\t38.22%\t40.81%\t18.44%\t-12.82%\n",
      "-0.2d 1c/epoch8.pt\t36.79%\t40.26%\t17.28%\t-8.28%\n",
      "-0.2d 1c/epoch10.pt\t37.85%\t40.10%\t17.11%\t-10.95%\n",
      "-0.2d 1c/epoch12.pt\t41.53%\t41.68%\t17.76%\t-8.80%\n",
      "-0.2d 1c/epoch14.pt\t38.65%\t41.85%\t18.03%\t-8.67%\n",
      "-0.2d 1c/epoch16.pt\t41.16%\t43.41%\t18.00%\t-7.41%\n",
      "-0.2d 1c/epoch20.pt\t42.64%\t43.16%\t17.49%\t-7.94%\n",
      "-0.2d 1c/epoch24.pt\t43.96%\t44.05%\t17.08%\t-9.16%\n",
      "-0.2d 1c/epoch28.pt\t42.03%\t43.77%\t17.57%\t-7.27%\n",
      "-0.2d 1c/epoch30.pt\t43.82%\t44.22%\t17.18%\t-7.16%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t33.90%\t38.69%\t21.54%\t-9.42%\n",
      "-0.4d 1c/epoch4.pt\t36.03%\t39.41%\t20.25%\t-4.19%\n",
      "-0.4d 1c/epoch6.pt\t38.28%\t40.96%\t18.45%\t-12.65%\n",
      "-0.4d 1c/epoch8.pt\t37.26%\t40.40%\t17.30%\t-8.28%\n",
      "-0.4d 1c/epoch10.pt\t37.97%\t40.24%\t17.14%\t-10.96%\n",
      "-0.4d 1c/epoch12.pt\t42.07%\t41.81%\t17.78%\t-8.71%\n",
      "-0.4d 1c/epoch14.pt\t38.72%\t41.99%\t18.06%\t-8.94%\n",
      "-0.4d 1c/epoch16.pt\t41.32%\t43.54%\t18.02%\t-7.67%\n",
      "-0.4d 1c/epoch20.pt\t42.72%\t43.28%\t17.52%\t-8.03%\n",
      "-0.4d 1c/epoch24.pt\t44.12%\t44.16%\t17.12%\t-9.16%\n",
      "-0.4d 1c/epoch28.pt\t42.14%\t43.88%\t17.62%\t-7.45%\n",
      "-0.4d 1c/epoch30.pt\t43.94%\t44.32%\t17.22%\t-7.42%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t33.62%\t38.87%\t21.57%\t-9.51%\n",
      "-0.8d 1c/epoch4.pt\t36.10%\t39.48%\t20.26%\t-3.92%\n",
      "-0.8d 1c/epoch6.pt\t38.37%\t41.03%\t18.47%\t-12.56%\n",
      "-0.8d 1c/epoch8.pt\t37.51%\t40.46%\t17.32%\t-8.37%\n",
      "-0.8d 1c/epoch10.pt\t38.01%\t40.27%\t17.15%\t-10.96%\n",
      "-0.8d 1c/epoch12.pt\t42.19%\t41.83%\t17.79%\t-8.63%\n",
      "-0.8d 1c/epoch14.pt\t38.72%\t41.96%\t18.07%\t-8.76%\n",
      "-0.8d 1c/epoch16.pt\t41.30%\t43.47%\t18.01%\t-7.51%\n",
      "-0.8d 1c/epoch20.pt\t42.72%\t43.23%\t17.52%\t-8.13%\n",
      "-0.8d 1c/epoch24.pt\t44.10%\t44.12%\t17.12%\t-9.34%\n",
      "-0.8d 1c/epoch28.pt\t42.15%\t43.85%\t17.62%\t-7.54%\n",
      "-0.8d 1c/epoch30.pt\t43.93%\t44.29%\t17.22%\t-7.51%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
