{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluations.intrinsic_eval import cherry_words, generic_words\n",
    "from decomposer import Decomposer, DecomposerConfig\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "sns.set()\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "PE = torch.load(\n",
    "    '../../results/pretrained/init.pt', map_location=DEVICE)['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    path = '../../results/' + path\n",
    "    stuff = torch.load(path, map_location=DEVICE)['model']\n",
    "    return stuff.embedding.weight.detach().numpy()\n",
    "\n",
    "def gather(words):\n",
    "    word_ids = [PE.word_to_id[w] for w in words]\n",
    "    freq = [PE.Dem_frequency[w] + PE.GOP_frequency[w] for w in words]\n",
    "    skew = [PE.R_ratio(w) for w in words]\n",
    "    return word_ids, freq, skew\n",
    "\n",
    "def plot(coordinates, words, freq, skew, path):\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    sns.scatterplot(\n",
    "        coordinates[:,0], coordinates[:,1], \n",
    "        hue=skew, palette='coolwarm', hue_norm=(0, 1),\n",
    "        size=freq, sizes=(100, 1000), \n",
    "        legend=None, ax=ax)\n",
    "    for coord, word in zip(coordinates, words):\n",
    "        ax.annotate(word, coord, fontsize=12)\n",
    "    with open(path, 'wb') as file:\n",
    "        fig.savefig(file, dpi=300)\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cherry_ids, cherry_freq, cherry_skew = gather(cherry_words)\n",
    "generic_ids, generic_freq, generic_skew = gather(generic_words)\n",
    "\n",
    "GOP_words = [w for w in PE.word_to_id.keys()\n",
    "             if PE.GOP_frequency[w] > 99 and PE.R_ratio(w) > 0.75]\n",
    "print(len(GOP_words))\n",
    "# GOP_words = random.sample(GOP_words, 100)\n",
    "GOP_ids, GOP_freq, GOP_skew = gather(GOP_words)\n",
    "\n",
    "random_words = [w for w in PE.word_to_id.keys() \n",
    "                if PE.GOP_frequency[w] + PE.Dem_frequency[w] > 99]\n",
    "random_words = random.sample(random_words, 50)\n",
    "random_ids, random_freq, random_skew = gather(random_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "#     'M0 pretrained': load('pretrained/init.pt'),\n",
    "#     'M1 L1 -0.05d': load('cono space remove deno/L1 -0.05d/epoch50.pt'),\n",
    "#     'M2 L4 -0.05d': load('cono space remove deno/L4 -0.05d/epoch50.pt'),\n",
    "    'M3 +5 -0.05d': load('affine/L4 +5 -0.05d/epoch50.pt'),\n",
    "    'M4 +5 -0.1d': load('affine/L4 +5 -0.1d/epoch50.pt'),\n",
    "    'M5 +5 -0.2d': load('affine/L4 +5 -0.2d/epoch50.pt'),\n",
    "    'M6 +5 -0.5d': load('affine/L4 +5 -0.5d/epoch50.pt'),\n",
    "    'M7 +5 -1d': load('affine/L4 +5 -1d/epoch50.pt'),\n",
    "    'M8 +10 -1.5d': load('affine/L4 +10 -1.5d/epoch50.pt'),\n",
    "    'M9 +10 -2d': load('affine/L4 +10 -2d/epoch50.pt'),\n",
    "    'M10 +5 0c -1d': load('affine/L4 +5 0c/epoch50.pt'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_dir = '../../analysis/t-SNE'\n",
    "for model_name, embed in models.items():\n",
    "    space = embed[GOP_ids]\n",
    "    visual = TSNE(perplexity=10, learning_rate=1).fit_transform(space)\n",
    "    plot(visual, GOP_words, GOP_freq, GOP_skew, \n",
    "         f'{out_dir}/GOP {model_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_dir = '../../analysis/t-SNE'\n",
    "for model_name, embed in models.items():\n",
    "    space = embed[cherry_ids]\n",
    "#     space = PCA(n_components=30).fit_transform(space)\n",
    "    visual = TSNE(\n",
    "        perplexity=4, learning_rate=10, \n",
    "        n_iter=5000, n_iter_without_progress=1000).fit_transform(space)\n",
    "    \n",
    "    plot(visual, cherry_words, cherry_freq, cherry_skew, \n",
    "         f'{out_dir}/cherry {model_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../../analysis/t-SNE'\n",
    "for model_name, embed in models.items():\n",
    "    space = embed[generic_ids]\n",
    "    visual = TSNE(perplexity=5, learning_rate=1).fit_transform(space)\n",
    "    plot(visual, generic_words, generic_freq, generic_skew, \n",
    "         f'{out_dir}/generic {model_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../../analysis/t-SNE'\n",
    "for model_name, embed in models.items():\n",
    "    space = embed[random_ids]\n",
    "    visual = TSNE(\n",
    "        perplexity=20, learning_rate=10, n_iter=5000).fit_transform(space)\n",
    "    plot(visual, random_words, random_freq, random_skew, \n",
    "         f'{out_dir}/random {model_name}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
