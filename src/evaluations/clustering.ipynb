{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocabulary from /home/webson/Research/congressional_adversary/results/search/pretrained/init.pt\n",
      "Vocab size = 138,443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webson/Research/congressional_adversary/src/data.py:56: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  self.R_ratio = self.cono_freq[2] / (self.cono_freq[0] + self.cono_freq[2])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, Union, List, Dict, Iterable, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from decomposer import Decomposer, DecomposerConfig\n",
    "from recomposer import Recomposer, RecomposerConfig\n",
    "from data import GroundedWord\n",
    "from evaluations.helpers import load_en_masse, ground\n",
    "\n",
    "# from evaluations.helpers import GroundedWord, load_recomposers_en_masse\n",
    "# from evaluations.clustering import graph_en_masse\n",
    "# from evaluations.euphemism import cherry_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfc84649662441c9190ded8eb37d9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading ../../results/pious/true cross/epoch1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webson/Research/congressional_adversary/congressional_env/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'decomposer.Decomposer' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../../results/pious/intraDS/epoch1.pt\n",
      "Loading ../../results/pious/sans bound/epoch1.pt\n",
      "Loading ../../results/pious/true cross/epoch3.pt\n",
      "Loading ../../results/pious/intraDS/epoch3.pt\n",
      "Loading ../../results/pious/sans bound/epoch3.pt\n",
      "Loading ../../results/pious/true cross/epoch5.pt\n",
      "Loading ../../results/pious/intraDS/epoch5.pt\n",
      "Loading ../../results/pious/sans bound/epoch5.pt\n",
      "\n",
      "pretrained\n",
      "true cross epoch1\n",
      "intraDS epoch1\n",
      "sans bound epoch1\n",
      "true cross epoch3\n",
      "intraDS epoch3\n",
      "sans bound epoch3\n",
      "true cross epoch5\n",
      "intraDS epoch5\n",
      "sans bound epoch5\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path('../../results/pious/')\n",
    "deno_space, cono_space = load_en_masse(\n",
    "    base_dir, \n",
    "    patterns=['*/epoch1.pt', '*/epoch3.pt', '*/epoch5.pt'], \n",
    "    recomposer=True)\n",
    "for name in deno_space.keys():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sns.set()\n",
    "\n",
    "def plot(\n",
    "        coordinates: np.ndarray,\n",
    "        words: List[GroundedWord],\n",
    "        path: Path\n",
    "        ) -> None:\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    skew = [w.R_ratio for w in words]\n",
    "    freq = [w.freq for w in words]\n",
    "    sns.scatterplot(\n",
    "        coordinates[:, 0], coordinates[:, 1],\n",
    "        hue=skew, palette='coolwarm', hue_norm=(0, 1),\n",
    "        size=freq, sizes=(200, 1000),\n",
    "        legend=None, ax=ax)\n",
    "    for coord, w in zip(coordinates, words):\n",
    "        ax.annotate(w.word, coord, fontsize=12)\n",
    "    with open(path, 'wb') as file:\n",
    "        fig.savefig(file, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_categorical(\n",
    "        coordinates: np.ndarray,\n",
    "        words: List[GroundedWord],\n",
    "        path: Path,\n",
    "        fancy: bool = False\n",
    "        ) -> None:\n",
    "    if fancy:\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        categories = [w.majority_deno for w in words]\n",
    "        freq = [w.freq for w in words]\n",
    "        sns.scatterplot(\n",
    "            coordinates[:, 0], coordinates[:, 1],\n",
    "            hue=categories, palette='muted', hue_norm=(0, 1),\n",
    "            size=freq, sizes=(200, 1000),\n",
    "            legend='brief', \n",
    "            ax=ax)\n",
    "        chartBox = ax.get_position()\n",
    "        ax.set_position(  # adjust legend\n",
    "            [chartBox.x0, chartBox.y0, chartBox.width * 0.6, chartBox.height])\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(1.45, 0.8), ncol=1)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        freq = [w.freq for w in words]\n",
    "        sns.scatterplot(\n",
    "            coordinates[:, 0], coordinates[:, 1], ax=ax)\n",
    "\n",
    "    for coord, w in zip(coordinates, words):\n",
    "        ax.annotate(w.word, coord, fontsize=12)\n",
    "    with open(path, 'wb') as file:\n",
    "        fig.savefig(file, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def graph_en_masse(\n",
    "        models: Dict[str, np.ndarray],\n",
    "        out_dir: Path,\n",
    "        reduction: str,  # 'PCA', 'TSNE', or 'both'\n",
    "        words: List[GroundedWord],\n",
    "        # hues: Union[List[float], List[int]],\n",
    "        # sizes: List[int],\n",
    "        perplexity: Optional[int] = None,\n",
    "        categorical: bool = False\n",
    "        ) -> None:\n",
    "    Path.mkdir(out_dir, parents=True, exist_ok=True)\n",
    "    word_ids = np.array([w.id for w in words])\n",
    "    for model_name, embed in tqdm(models.items()):\n",
    "        space = embed[word_ids]\n",
    "        if reduction == 'PCA':\n",
    "            visual = PCA(n_components=2).fit_transform(space)\n",
    "        elif reduction == 'TSNE':\n",
    "            assert perplexity is not None\n",
    "            visual = TSNE(\n",
    "                perplexity=perplexity, learning_rate=10,\n",
    "                n_iter=5000, n_iter_without_progress=1000).fit_transform(space)\n",
    "        elif reduction == 'both':\n",
    "            assert perplexity is not None\n",
    "            space = PCA(n_components=30).fit_transform(space)\n",
    "            visual = TSNE(\n",
    "                perplexity=perplexity, learning_rate=10,\n",
    "                n_iter=5000, n_iter_without_progress=1000).fit_transform(space)\n",
    "        else:\n",
    "            raise ValueError('unknown dimension reduction method')\n",
    "        if categorical:\n",
    "            plot_categorical(visual, words, out_dir / f'{model_name}.png')\n",
    "        else:\n",
    "            plot(visual, words, out_dir / f'{model_name}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cherry_words = [\n",
    "    'government', 'washington',\n",
    "    'estate_tax', 'death_tax',\n",
    "    'public_option', 'government_run',\n",
    "    'foreign_trade', 'international_trade',\n",
    "#     'cut_taxes', 'trickle_down'\n",
    "]\n",
    "cherry_words = [ground[w] for w in cherry_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "test_path = Path('../../data/ellie/partisan_sample.hp.txt')\n",
    "with open(test_path) as file:\n",
    "    test_words = [ground[word.strip()] for word in file]\n",
    "sampled_test = random.sample(test_words, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566cf3955d514393a0379d7732312146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6247e55d91684931bf79f272c2ce16a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69840f8f19864f8b8bfe0f02d05e2a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445878c254c948aab9017287bbe0d6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = deno_space\n",
    "grounded_words = sampled_test\n",
    "\n",
    "graph_en_masse(\n",
    "    models, out_dir=base_dir / 'test/deno_space/t-SNE p2',\n",
    "    reduction='TSNE', perplexity=2, words=grounded_words)\n",
    "\n",
    "graph_en_masse(\n",
    "    models, out_dir=base_dir / 'test/deno_space/t-SNE p3',\n",
    "    reduction='TSNE', perplexity=3, words=grounded_words)\n",
    "\n",
    "graph_en_masse(\n",
    "    models, out_dir=base_dir / 'test/deno_space/t-SNE p5',\n",
    "    reduction='TSNE', perplexity=5, words=grounded_words)\n",
    "\n",
    "graph_en_masse(\n",
    "    models, out_dir=base_dir / 'test/deno_space/t-SNE p25',\n",
    "    reduction='TSNE', perplexity=25, words=grounded_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connotation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a4f94b439046b5b8d970b9d4dbdbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c801c88826840ad8ee806de4ef776d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4505406a014b5b8838a150582c9ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = cono_space\n",
    "grounded_words = sampled_test\n",
    "\n",
    "graph_en_masse(\n",
    "    models, out_dir=base_dir / 'test/cono_space/t-SNE p25',\n",
    "    reduction='TSNE', perplexity=25, words=grounded_words)\n",
    "graph_en_masse(\n",
    "    models, out_dir=base_dir / 'test/cono_space/t-SNE p3',\n",
    "    reduction='TSNE', perplexity=3, words=grounded_words)\n",
    "graph_en_masse(\n",
    "    models, out_dir=base_dir / 'test/cono_space/t-SNE p2',\n",
    "    reduction='TSNE', perplexity=2, words=grounded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = deno_space\n",
    "# grounded_words = cherry_words\n",
    "\n",
    "# graph_en_masse(\n",
    "#     models, out_dir=base_dir / 'test_cherry/deno_space/t-SNE p5',\n",
    "#     reduction='TSNE', perplexity=5, words=grounded_words)\n",
    "# graph_en_masse(\n",
    "#     models, out_dir=base_dir / 'test_cherry/deno_space/t-SNE p3',\n",
    "#     reduction='TSNE', perplexity=3, words=grounded_words)\n",
    "# graph_en_masse(\n",
    "#     models, out_dir=base_dir / 'test_cherry/deno_space/t-SNE p2',\n",
    "#     reduction='TSNE', perplexity=2, words=grounded_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
