{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from typing import Set, Tuple, NamedTuple, List, Dict, Counter, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from decomposer import AdversarialDecomposer, AdversarialConfig\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Embedding():\n",
    "    \n",
    "    def __init__(self, path: str, source: Optional[str] = None):\n",
    "        if source is None or source == 'adversarial':\n",
    "            self.init_from_adversarial(path)\n",
    "        elif source == 'skip_gram':\n",
    "            self.init_from_skip_gram(path)\n",
    "        elif source == 'plain_text':\n",
    "            self.init_from_plain_text(path)\n",
    "        else:\n",
    "            raise ValueError('Unknown embedding source.')\n",
    "            \n",
    "    def init_from_adversarial(self, path: str, device=torch.device('cpu')):\n",
    "        payload = torch.load(path, map_location=device)\n",
    "        model = payload['model']\n",
    "        self.word_to_id = model.word_to_id\n",
    "        self.id_to_word = model.id_to_word \n",
    "        self.Dem_frequency: Counter[str] = model.Dem_frequency\n",
    "        self.GOP_frequency: Counter[str] = model.GOP_frequency\n",
    "        \n",
    "        # encoded layer\n",
    "        self.embedding = model.export_encoded_embedding(device=device)\n",
    "#         self.embedding = model.export_decomposed_embedding(device=device)\n",
    "\n",
    "#         # manually choose which layer to export\n",
    "#         all_vocab_ids = torch.arange(\n",
    "#             len(self.word_to_id), dtype=torch.long, device=device)\n",
    "#         with torch.no_grad():\n",
    "#             embed = model.embedding(all_vocab_ids)\n",
    "#             encoded = model.encoder(embed)\n",
    "#             self.cono_logits = model.cono_decoder(encoded)\n",
    "            \n",
    "#     def init_from_adversarial(self, path: str):        \n",
    "#         config = DenotationEncoderConfig()\n",
    "#         config.input_dir = '../../data/processed/adversarial/44_Obama_1e-5'\n",
    "#         data = AdversarialDataset(config)\n",
    "#         model = DenotationEncoder(config, data)\n",
    "#         model.load_state_dict(torch.load(path))\n",
    "#         self.embedding = model.export_decomposed_embedding().to('cpu')\n",
    "#         self.word_to_id = model.word_to_id\n",
    "#         self.id_to_word = model.id_to_word\n",
    "\n",
    "    def init_from_skip_gram(self, paths: Tuple[str, str]) -> None:\n",
    "        \"\"\"Directly extract the weights of a single layer.\"\"\"\n",
    "        model_path, vocab_path = paths\n",
    "        with open(model_path, 'rb') as model_file:\n",
    "            state_dict = torch.load(model_file, map_location='cpu')\n",
    "    #     print(state_dict.keys())\n",
    "        self.embedding = state_dict['center_embedding.weight'].numpy()\n",
    "        with open(vocab_path, 'rb') as vocab_file:\n",
    "            self.word_to_id, self.id_to_word, _ = pickle.load(vocab_file)\n",
    "\n",
    "    def init_from_plain_text(self, path: str) -> Tuple[np.array, Dict[str, int]]:\n",
    "        id_generator = 0\n",
    "        word_to_id: Dict[str, int] = {}\n",
    "        embeddings: List[float] = []\n",
    "        embedding_file = open(path)\n",
    "        vocab_size, num_dimensions = map(int, embedding_file.readline().split())\n",
    "        print(f'vocab_size = {vocab_size:,}, num_dimensions = {num_dimensions}')\n",
    "        print(f'Loading embeddings from {path}', flush=True)\n",
    "        for line in embedding_file:\n",
    "            line: List[str] = line.split()  # type: ignore\n",
    "            word = line[0]\n",
    "            vector = np.array(line[-num_dimensions:], dtype=np.float64)\n",
    "            embeddings.append(vector)\n",
    "            word_to_id[word] = id_generator\n",
    "            id_generator += 1\n",
    "        embedding_file.close()\n",
    "        print('Done')\n",
    "        self.id_to_word = {val: key for key, val in word_to_id.items()}\n",
    "        self.word_to_id = word_to_id\n",
    "        self.embedding = np.array(embeddings)\n",
    "        \n",
    "    def write_to_tensorboard_projector(self, tb_dir: str) -> None:\n",
    "        from torch.utils import tensorboard\n",
    "        tb = tensorboard.SummaryWriter(log_dir=tb_dir)\n",
    "        all_vocab_ids = range(len(self.word_to_id))\n",
    "        embedding_labels = [\n",
    "            self.id_to_word[word_id]\n",
    "            for word_id in all_vocab_ids]\n",
    "        tb.add_embedding(\n",
    "            self.embedding[:9999], \n",
    "            embedding_labels[:9999], \n",
    "            global_step=0)\n",
    "        \n",
    "    def export_web_projector(self, out_dir: str) -> None:\n",
    "        random_indices = np.random.randint(len(self.embedding), size=10000)\n",
    "        subset_embedding = self.embedding[random_indices].tolist()\n",
    "        \n",
    "        vector_path = os.path.join(out_dir, 'tensorboard.tsv')\n",
    "        with open(vector_path, 'w') as vector_file:\n",
    "            for vector in subset_embedding:\n",
    "                vector_file.write('\\t'.join(map(str, vector)) + '\\n')\n",
    "\n",
    "        label_path = os.path.join(out_dir, 'tensorboard_labels.tsv')\n",
    "        with open(label_path, 'w') as label_file:\n",
    "            for index in random_indices:\n",
    "                label_file.write(self.id_to_word[index] + '\\n')\n",
    "\n",
    "    def cosine_similarity(self, query1: str, query2: str) -> float:\n",
    "        try:\n",
    "            query1_id = self.word_to_id[query1]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query1}')\n",
    "            raise error\n",
    "        try:\n",
    "            query2_id = self.word_to_id[query2]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query2}')\n",
    "            raise error\n",
    "        vectors = self.embedding[(query1_id, query2_id), :]\n",
    "        similarity = 1 - distance.cosine(vectors[0], vectors[1])\n",
    "        return similarity\n",
    "\n",
    "    def nearest_neighbor(self, query: str, top_k: int = 10):\n",
    "        try:\n",
    "            query_id = self.word_to_id[query]\n",
    "        except KeyError:\n",
    "            raise KeyError(f'{query} is out of vocabulary. Sorry!')    \n",
    "        query_vec = self.embedding[query_id]\n",
    "        \n",
    "        distances = [distance.cosine(query_vec, vec) \n",
    "                     for vec in self.embedding]\n",
    "        neighbors = np.argsort(distances)\n",
    "        print(f\"{query}'s neareset neighbors:\")\n",
    "        for ranking in range(1, top_k + 1):\n",
    "            word_id = neighbors[ranking]\n",
    "            word = self.id_to_word[word_id]\n",
    "            cosine_similarity = 1 - distances[word_id]\n",
    "            print(f'{cosine_similarity:.4f}\\t{word}')\n",
    "        print()\n",
    "        \n",
    "\n",
    "class PhrasePair(NamedTuple):\n",
    "    query: str\n",
    "    neighbor: str\n",
    "    deno_sim: float\n",
    "    cono_sim: float\n",
    "    \n",
    "\n",
    "def load_cherry(path, exclude_hard_examples=True):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['semantic_similarity'] and row['cono_similarity']:\n",
    "                if (exclude_hard_examples and \n",
    "                        'hard example' in row['comment'].lower()):\n",
    "                    continue\n",
    "                data.append(PhrasePair(\n",
    "                    row['query'], \n",
    "                    row['neighbor'], \n",
    "#                     row['query_words'], \n",
    "#                     row['neighbor_words'], \n",
    "                    float(row['semantic_similarity']), \n",
    "                    float(row['cono_similarity'])))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_MTurk_results(path):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            qc = row['median_query_cono']\n",
    "            nc = row['median_neighbor_cono']\n",
    "            if qc and nc:  # nonempty string\n",
    "                qc = float(qc)\n",
    "                nc = float(nc)\n",
    "                if qc == 0 or nc == 0:  # unable to judge\n",
    "                    continue\n",
    "                \n",
    "#                 cono_sim = 5 - abs(qc - nc)\n",
    "            \n",
    "                if ((qc > 3 and nc > 3) \n",
    "                        or (qc < 3 and nc < 3) \n",
    "                        or (qc == 3 and nc == 3)):\n",
    "                    cono_sim = 5\n",
    "                else:\n",
    "                    cono_sim = 1\n",
    "    \n",
    "                data.append(PhrasePair( \n",
    "                    row['query_words'], \n",
    "                    row['neighbor_words'], \n",
    "                    float(row['median_deno']), \n",
    "                    cono_sim))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def correlate_sim_deltas(model, ref_model, phrase_pairs, verbose=False):\n",
    "    label_deltas = []\n",
    "    model_deltas = []\n",
    "    if verbose:\n",
    "        print(f'deno_sim\\tcono_sim\\tref_sim\\tmodel_sim')\n",
    "    \n",
    "    for pair in phrase_pairs:\n",
    "        try:\n",
    "            sim = model.cosine_similarity(pair.query, pair.neighbor)\n",
    "            ref_sim = ref_model.cosine_similarity(pair.query, pair.neighbor)\n",
    "        except KeyError:\n",
    "            continue \n",
    "        model_delta = sim - ref_sim\n",
    "        model_deltas.append(model_delta)\n",
    "        label_deltas.append(pair.deno_sim - pair.cono_sim)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'{pair.deno_sim}  {pair.cono_sim}  {ref_sim:.2%}  {sim:.2%}  '\n",
    "                  f'{pair.query}  {pair.neighbor}')\n",
    "\n",
    "    median = np.median(model_deltas)\n",
    "    mean = np.mean(model_deltas)\n",
    "    stddev = np.std(model_deltas)\n",
    "    rho, _ = spearmanr(model_deltas, label_deltas)\n",
    "    return rho, median, mean, stddev\n",
    "\n",
    "\n",
    "def preview(things):\n",
    "    for stuff in things:\n",
    "        q, n, d, c = stuff\n",
    "        print(d, c, q, n, sep='\\t')\n",
    "\n",
    "\n",
    "def same_deno(pair):\n",
    "    return pair.deno_sim >= 3\n",
    "\n",
    "\n",
    "def same_cono(pair):\n",
    "    return pair.cono_sim >= 3\n",
    "        \n",
    "        \n",
    "def is_euphemism(pair) -> bool:\n",
    "    return same_deno(pair) and not same_cono(pair)\n",
    "\n",
    "\n",
    "def is_party_platform(pair) -> bool:\n",
    "    return not same_deno(pair) and same_cono(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cherry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 labeled entries at ../../data/evaluation/cherries/labeled_Dem_samples.tsv\n",
      "Loaded 29 labeled entries at ../../data/evaluation/cherries/labeled_GOP_samples.tsv\n",
      "Loaded 32 labeled entries at ../../data/evaluation/cherries/remove_deno.tsv\n",
      "39 euphemism\n",
      "5.0\t1.0\ttax_breaks\tbipartisan_tax_relief\n",
      "5.0\t1.0\tstar_wars\tstrategic_defense_initiative\n",
      "5.0\t1.0\tstar_wars\tmissile_defense\n",
      "4.0\t1.0\tmilitary_spending\tfederal_spending\n",
      "4.0\t1.0\tmilitary_spending\tgovernment_spending\n",
      "4.5\t1.0\tassault_weapons\tfirearms\n",
      "5.0\t1.0\tassault_weapons\trifles\n",
      "4.0\t2.0\tcredit_card_companies\tcreditors\n",
      "3.0\t2.0\ttrickledown\tcut_taxes\n",
      "4.0\t2.0\twaterboarding\tinterrogation\n",
      "5.0\t1.0\tantichoice\tprolife\n",
      "4.0\t2.0\tprivate_insurance_companies\tmedicare_advantage_program\n",
      "5.0\t1.0\tnuclear_option\tconstitutional_option\n",
      "5.0\t2.0\tcorporate_profits\tearnings\n",
      "5.0\t1.0\tdeath_tax\testate_tax\n",
      "5.0\t2.0\tunborn\tfetus\n",
      "5.0\t2.0\tpartialbirth_abortion\tlateterm\n",
      "5.0\t1.0\tpartialbirth_abortion\tdx\n",
      "5.0\t1.0\tillegals\tundocumented_immigrants\n",
      "5.0\t1.0\tgovernmentrun\tpublic_option\n",
      "4.0\t1.0\tmedical_liability\tmedical_malpractice\n",
      "5.0\t1.0\tgovernment_takeover\tnational_health_insurance\n",
      "5.0\t1.0\tstimulus_bill\trecovery_and_reinvestment\n",
      "5.0\t1.0\tproabortion\tprochoice\n",
      "4.0\t1.0\tproabortion\tfamily_planning\n",
      "5.0\t1.0\tgovernmentrun_health_care\tsinglepayer\n",
      "4.0\t1.0\twelfare_state\tnational_health_insurance\n",
      "5.0\t1.0\tobamacare\thealth_care_reform\n",
      "5.0\t1.0\tsocialized_medicine\tsinglepayer\n",
      "5.0\t1.0\tsocialized_medicine\tuniversal_health_care\n",
      "5.0\t1.0\tpolitical_speech\tcampaign_spending\n",
      "5.0\t1.0\tpolitical_speech\tindependent_expenditures\n",
      "4.0\t1.0\twashington_spending\tmilitary_spending\n",
      "5.0\t1.0\tmassive_immigration\timmigration\n",
      "5.0\t1.0\tmassive_immigration\tundocumented_workers\n",
      "5.0\t1.0\tmassive_immigration\tnewcomers\n",
      "5.0\t1.0\tforced_busing\tbusing\n",
      "5.0\t1.0\tforced_busing\tdesegregation\n",
      "4.0\t1.0\tgrowth_of_government\tincreases_in_defense\n",
      "\n",
      "35 party platform\n",
      "2.0\t5.0\twealthiest_americans\ttax_breaks\n",
      "2.0\t5.0\tbillion_tax_cut\twealthiest_americans\n",
      "2.0\t5.0\trecord_profits\tbig_oil_companies\n",
      "1.0\t5.0\tdeath_tax\tunborn\n",
      "1.0\t5.0\tpartialbirth_abortion\tillegals\n",
      "1.0\t5.0\thigher_taxes\tproabortion\n",
      "1.0\t5.0\tgovernment_takeover\tprogrowth\n",
      "1.0\t5.0\tobamacare\tislamists\n",
      "1.0\t5.0\tgovernmentrun_health_care\tnational_energy_tax\n",
      "1.0\t5.0\twelfare_state\tmedical_liability\n",
      "1.0\t5.0\tlimited_government\tmassive_immigration\n",
      "1.0\t5.0\tforced_busing\tpolitical_speech\n",
      "1.0\t5.0\tcapandtax\tsocialized_medicine\n",
      "1.0\t5.0\twashington_spending\ttort_reform\n",
      "1.0\t5.0\tschool_choice\tfreddie_and_fannie\n",
      "1.0\t5.0\tbig_government\tflat_tax\n",
      "1.0\t5.0\toverregulation\tsocial_security_lockbox\n",
      "1.0\t5.0\tgovernmentrun\tillegal_narcotics\n",
      "1.0\t5.0\tmandatory_minimum\ttax_hike\n",
      "1.0\t5.0\tmassive_debt\tdefinition_of_marriage\n",
      "1.0\t5.0\trecord_profits\tbig_oil_companies\n",
      "1.0\t5.0\tdx\tundocumented_immigrants\n",
      "1.0\t5.0\tpublic_option\tcorporate_profits\n",
      "1.0\t5.0\tnational_health_insurance\tbigger_government\n",
      "1.0\t5.0\ttrickledown\tuniversal_health_care\n",
      "1.0\t5.0\trecovery_and_reinvestment\twaterboarding\n",
      "1.0\t5.0\tincreases_in_defense\tantichoice\n",
      "1.0\t5.0\tnuclear_arms_race\tdrug_industry\n",
      "1.0\t5.0\tprivate_accounts\tmilitary_spending\n",
      "1.0\t5.0\tstar_wars\tinequality\n",
      "1.0\t5.0\ttax_breaks\tsocial_justice\n",
      "1.0\t5.0\twomens_rights\tbig_oil_companies\n",
      "1.0\t5.0\toccupation_of_iraq\tbig_banks\n",
      "1.0\t5.0\twealthiest_americans\tassault_weapons\n",
      "1.0\t5.0\tvoodoo\tpublic_option\n"
     ]
    }
   ],
   "source": [
    "Dem_pairs = load_cherry(    \n",
    "    '../../data/evaluation/cherries/labeled_Dem_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "GOP_pairs = load_cherry(\n",
    "    '../../data/evaluation/cherries/labeled_GOP_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "val_data = Dem_pairs + GOP_pairs\n",
    "\n",
    "euphemism = list(filter(is_euphemism, val_data))\n",
    "party_platform = list(filter(is_party_platform, val_data))\n",
    "party_platform += load_cherry(\n",
    "    '../../data/evaluation/cherries/remove_deno.tsv',\n",
    "    exclude_hard_examples=False)\n",
    "\n",
    "print(f'{len(euphemism)} euphemism')\n",
    "preview(euphemism)\n",
    "print(f'\\n{len(party_platform)} party platform')\n",
    "preview(party_platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualification Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-dde0e06d7a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m test_data = load_cherry(\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'../../data/evaluation/qualification_30.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     exclude_hard_examples=False)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Same entity denotation, different party connotation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-3074a931cc57>\u001b[0m in \u001b[0;36mload_cherry\u001b[0;34m(path, exclude_hard_examples)\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 data.append(PhrasePair(\n\u001b[0;32m--> 169\u001b[0;31m                     \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neighbor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;31m#                     row['query_words'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'query'"
     ]
    }
   ],
   "source": [
    "test_data = load_cherry(\n",
    "    '../../data/evaluation/qualification_30.csv', \n",
    "    exclude_hard_examples=False)\n",
    "\n",
    "euphemism = list(filter(is_euphemism, test_data))\n",
    "party_platform = list(filter(is_party_platform, test_data))\n",
    "\n",
    "print(f'{len(euphemism)} euphemism')\n",
    "print(f'{len(party_platform)} party platform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 318 labeled entries at ../../data/evaluation/combined_result.csv\n",
      "37 euphemism\n",
      "3.0\t1\tobamacare\thealth_care_law\n",
      "3.0\t1\tbilingual_ballots\tvoting_systems\n",
      "3.0\t1\tmedical_liability_insurance\tmedical_liability_crisis\n",
      "3.0\t1\tthe_distinguished_acting_republican_leader\tdistinguished_minority_leader\n",
      "3.0\t1\ttrillion_debt\tnational_debt\n",
      "4.0\t1\trecovery_and_reinvestment\tstimulus\n",
      "4.5\t1\tlaidoff_workers\tdisplaced_workers\n",
      "3.0\t1\ttrillion_in_debt\ttrillion\n",
      "3.0\t1\trepublican_congressman\tthencongressman\n",
      "3.0\t1\tthe_classroom_act\tsmaller_class_size\n",
      "3.0\t1\tincrease_supply\tdrill_our_way\n",
      "3.0\t1\tlilly_ledbetter\tequal_employment_opportunity_commission\n",
      "3.0\t1\tmegabanks\tbanks\n",
      "3.0\t1\tconstitutional_option\tchange_the_rules\n",
      "3.0\t1\tballistic_missile_attack\tlaunchonwarning\n",
      "5.0\t1\tprivate_accounts\tpersonal_accounts\n",
      "3.5\t1\tdrill_our_way\tenergy_independent\n",
      "5.0\t1\tdeath_tax\testate_taxes\n",
      "3.0\t1\tgun_dealers\tgun\n",
      "3.0\t1\tarctic_wildlife_refuge\tnorth_slope\n",
      "4.0\t1\tgovernment_option\tgovernment_health_care\n",
      "3.0\t1\ttax_penalty\tmarriage_penalty_relief\n",
      "3.0\t1\tthe_disclose_act\treal_campaign_finance\n",
      "3.0\t1\tenmons\tsupreme_court_decision\n",
      "3.0\t1\tcedaw\tconvention\n",
      "3.0\t1\tbigspending\tliberals\n",
      "3.0\t1\tnegroes\tnonwhite\n",
      "4.0\t1\tliving_wage\tminimum_wage\n",
      "3.0\t1\tright_to_overtime\tovertime_pay\n",
      "3.0\t1\tbig_banks\taig\n",
      "3.0\t1\tgrowth_rate\tpercent_per_year\n",
      "3.0\t1\tantihunger\tfood_banks\n",
      "3.0\t1\tgun_lobby\tgun_laws\n",
      "3.0\t1\tthe_tax_limitation_amendment\tlower_taxes\n",
      "3.0\t1\ttargeted_tax\tmarriage_penalty_relief\n",
      "3.0\t1\tkilled_by_gunfire\tdied\n",
      "3.0\t1\tmerrill_lynch\twall_street_banks\n",
      "\n",
      "111 party platform\n",
      "2.0\t5\tasian_pacific_americans\thispanicamericans\n",
      "2.0\t5\tgun_safety\tmandatory_minimum_sentencing\n",
      "2.0\t5\teskimos\tarctic_refuge\n",
      "2.0\t5\tasianamerican\thispanicamerican\n",
      "2.0\t5\ttaxes_too_much\tdebt_tax\n",
      "2.0\t5\tlabor_laws\tinternational_labor_organization\n",
      "2.0\t5\tteaching_hospitals\tmedicaid_patients\n",
      "2.0\t5\tpottawatomis\tcherokees\n",
      "2.0\t5\thuman_resources_committee\tthe_family_support_act\n",
      "2.0\t5\tkansai\tfsx_deal\n",
      "2.0\t5\tdrill_our_way\tarctic_wildlife_refuge\n",
      "2.5\t5\twar_against_iraq\tgo_to_war\n",
      "2.5\t5\tmilitary_solution\tpolitical_solution\n",
      "2.0\t5\tdebasement\thigh_interest_rate\n",
      "2.0\t5\tdisabled_veterans_tax\tretirees\n",
      "2.0\t5\tcollege_more_affordable\tperchild_tax_credit\n",
      "2.0\t5\tasianamerican\tsubgroup\n",
      "2.0\t5\tolder_people\tsnowewyden\n",
      "2.0\t5\tlulac\tcongressional_hispanic_caucus\n",
      "2.0\t5\tcost_jobs\tnew_taxes\n",
      "2.0\t5\tclintonmitchell\tnational_health_insurance\n",
      "2.0\t5\tletelier\taugusto\n",
      "2.0\t5\tparamilitaries\tchiapas\n",
      "2.0\t5\thatchleahy\tthe_omnibus_crime_bill\n",
      "2.0\t5\tvenereal\thepatitis_b\n",
      "2.0\t5\tbillion_a_month\tnew_debt\n",
      "2.0\t5\toverthrow_the_government\tnicaragua\n",
      "2.0\t5\tbrief_period\textend_beyond\n",
      "2.0\t5\trove\tpress_secretary\n",
      "2.0\t5\tconkling\twhig\n",
      "2.5\t5\tmaytag\tgalesburg\n",
      "2.0\t5\tnuclear_secrets\tcia_agent\n",
      "2.0\t5\tperchlorate\tradium\n",
      "2.0\t5\tlifetime_appointment\tsecond_highest_court\n",
      "2.0\t5\tkarl_rove\twhite_house\n",
      "2.0\t5\tbreckinridge\thenry_clay\n",
      "2.5\t5\tnasp\taeronautical\n",
      "2.0\t5\tgreenaway\tdistrict_court_judge\n",
      "2.0\t5\tsnowewyden\tmedicare_bill\n",
      "2.0\t5\tconablehance\tlast_years_tax\n",
      "2.0\t5\tlargest_tax_increase\tborrowandspend\n",
      "2.0\t5\tpeople_of_indiana\teighth_district_of\n",
      "2.0\t5\ttaxpayer_funding\tthe_disclose_act\n",
      "2.0\t5\tovervalued_dollar\ttrade_imbalance\n",
      "2.0\t5\thepatitis_b\tvenereal\n",
      "2.0\t5\tearly_grades\treducing_class_size\n",
      "2.0\t5\thealth_care_law\tsecond_opinion\n",
      "2.0\t5\tsave_their_homes\thousing_market\n",
      "2.0\t5\tthe_american_energy_act\tincrease_the_supply\n",
      "1.0\t5\tgun_safety_legislation\tthe_juvenile_justice_bill\n",
      "2.0\t5\tmonterey\tsonoma\n",
      "2.0\t5\tblue_dogs\tfiscal_responsibility\n",
      "2.0\t5\tcredit_authority\tbudget_authority\n",
      "2.0\t5\tnonhispanic\tafrican_americans\n",
      "2.0\t5\trepublican_congressman\tfreshman_class\n",
      "2.0\t5\tpercent_of_social\textend_the_solvency\n",
      "2.0\t5\texxonmobil\tchevron\n",
      "2.0\t5\tbuild_america_bonds\tcreates_jobs\n",
      "2.0\t5\ttax_freedom_day\tcost_of_government\n",
      "2.0\t5\tquickening\twomans_life\n",
      "2.0\t5\tgifted_and_talented\tbasic_skills\n",
      "2.5\t5\tcredit_authority\ttax_expenditures\n",
      "2.0\t5\tnuclear_arms_race\tsuperpowers\n",
      "2.0\t5\teducation_savings_account\tperchild_tax_credit\n",
      "2.0\t5\tfire_safety\tcampus\n",
      "2.0\t5\trecovery_act\tjumpstarting\n",
      "2.0\t5\toctober_surprise\tken_starr\n",
      "2.5\t5\tkagen\tkanjorski\n",
      "2.0\t5\tam_on_tuesday\tam_on_wednesday\n",
      "2.0\t5\textend_the_solvency\tsocial_security_money\n",
      "2.0\t5\tpaydown\ttrillion\n",
      "2.0\t5\tschool_facilities\tthe_teacher_empowerment_act\n",
      "2.5\t5\tmonterey\tmorro\n",
      "2.0\t5\tiraqi_leaders\tpolitical_reconciliation\n",
      "2.0\t5\teliminate_the_marriage\tmarriage_penalty_relief\n",
      "2.0\t5\tearl_warren\tchief_justice_rehnquist\n",
      "2.0\t5\ttraditional_interpretation\tnarrow_interpretation\n",
      "2.0\t5\tmedical_liability\tpass_health_care\n",
      "2.0\t5\trepublican_leaderships\tmajoritys\n",
      "2.0\t5\trepublican_bill\tthe_democratic_bill\n",
      "2.0\t5\tsenators_can_expect\trollcall_votes_today\n",
      "2.0\t5\tpedophile\texploitive\n",
      "2.0\t5\tprogressive_message\tprogressive_caucus\n",
      "2.0\t5\treconsider_laid_upon\tbill_be_considered\n",
      "2.0\t5\tmedgar\tdorothy_height\n",
      "2.0\t5\tredeploy\tforces_in_iraq\n",
      "2.0\t5\tlasater\thillary_rodham_clinton\n",
      "2.0\t5\tcurrent_hate_crimes\thate_crimes_legislation\n",
      "2.0\t5\tmedgar\twiley\n",
      "2.0\t5\ttraumatic_brain\tamputations\n",
      "2.0\t5\tmerkley\tjack_reed\n",
      "2.5\t5\tprovides_for_consideration\tlead_sponsor\n",
      "2.5\t5\tnuclear_weapons_testing\tcomprehensive_test_ban\n",
      "2.5\t5\tfannie_lou_hamer\trosa_parks\n",
      "2.5\t5\tketchikan\tpulp\n",
      "2.0\t5\temployer_mandates\tnational_health_insurance\n",
      "2.0\t5\tlifetime_appointment\tjohn_roberts\n",
      "2.0\t5\tthe_republican_bill\tthe_democrat_bill\n",
      "2.0\t5\tdistrict_of_california\trobert_dornan\n",
      "2.0\t5\thead_start_teachers\tthe_classroom_act\n",
      "2.0\t5\tnational_debt_repayment_act\tsocial_security_trust_fund\n",
      "2.0\t5\tcourts_of_appeals\tmajority_support\n",
      "2.0\t5\tseaport_security\tair_cargo\n",
      "2.0\t5\tmedical_wastes\tsludge\n",
      "2.0\t5\texport_subsidies\tovervalued_dollar\n",
      "2.0\t5\tkaktovik\ttundra\n",
      "2.0\t5\tagrifactories\tfamily_farm\n",
      "2.0\t5\tamniotic_fluid\tstem_cells\n",
      "2.0\t5\tmegaton\tdetonating\n",
      "2.0\t5\tallowed_to_speak\tminutes_in_length\n",
      "2.0\t5\tstate_of_indiana\teighth_congressional_district\n"
     ]
    }
   ],
   "source": [
    "# test_data = load_MTurk_results('../../data/evaluation/qualification_30.csv')\n",
    "test_data = load_MTurk_results('../../data/evaluation/combined_result.csv')\n",
    "\n",
    "euphemism = list(filter(is_euphemism, test_data))\n",
    "party_platform = list(filter(is_party_platform, test_data))\n",
    "\n",
    "print(f'{len(euphemism)} euphemism')\n",
    "preview(euphemism)\n",
    "print(f'\\n{len(party_platform)} party platform')\n",
    "preview(party_platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 111,387, num_dimensions = 300\n",
      "Loading embeddings from ../../data/pretrained_word2vec/for_real.txt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pretrained = Embedding('../../data/pretrained_word2vec/for_real.txt', 'plain_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "similarity should increase for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.017\t0.016\t0.029\t0.372\n",
      "1d -1c/epoch4.pt\t0.004\t-0.001\t0.036\t0.268\n",
      "1d -1c/epoch6.pt\t-0.002\t-0.007\t0.037\t0.187\n",
      "1d -1c/epoch8.pt\t-0.005\t-0.009\t0.043\t0.252\n",
      "1d -1c/epoch10.pt\t-0.004\t-0.010\t0.033\t0.215\n",
      "1d -1c/epoch12.pt\t-0.010\t-0.013\t0.038\t0.116\n",
      "1d -1c/epoch14.pt\t-0.004\t-0.005\t0.040\t0.191\n",
      "1d -1c/epoch16.pt\t-0.003\t-0.009\t0.034\t0.128\n",
      "1d -1c/epoch20.pt\t-0.014\t-0.011\t0.036\t0.068\n",
      "1d -1c/epoch24.pt\t-0.006\t-0.008\t0.037\t0.072\n",
      "1d -1c/epoch28.pt\t-0.014\t-0.017\t0.038\t0.111\n",
      "1d -1c/epoch30.pt\t-0.013\t-0.016\t0.040\t0.080\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.029\t0.027\t0.033\t0.226\n",
      "1d -2c/epoch4.pt\t0.005\t0.008\t0.039\t0.284\n",
      "1d -2c/epoch6.pt\t0.008\t-0.002\t0.047\t0.264\n",
      "1d -2c/epoch8.pt\t0.010\t-0.002\t0.050\t0.228\n",
      "1d -2c/epoch10.pt\t0.003\t-0.006\t0.054\t0.216\n",
      "1d -2c/epoch12.pt\t-0.002\t-0.010\t0.054\t0.268\n",
      "1d -2c/epoch14.pt\t0.001\t-0.014\t0.058\t0.206\n",
      "1d -2c/epoch16.pt\t-0.001\t-0.012\t0.052\t0.139\n",
      "1d -2c/epoch20.pt\t-0.004\t-0.009\t0.055\t0.041\n",
      "1d -2c/epoch24.pt\t0.003\t-0.011\t0.051\t0.165\n",
      "1d -2c/epoch28.pt\t0.003\t-0.011\t0.052\t0.133\n",
      "1d -2c/epoch30.pt\t0.007\t-0.006\t0.049\t0.005\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.044\t0.052\t0.044\t0.229\n",
      "1d -4c/epoch4.pt\t0.029\t0.026\t0.047\t0.256\n",
      "1d -4c/epoch6.pt\t0.031\t0.034\t0.035\t0.374\n",
      "1d -4c/epoch8.pt\t0.023\t0.022\t0.038\t0.321\n",
      "1d -4c/epoch10.pt\t0.019\t0.017\t0.048\t0.449\n",
      "1d -4c/epoch12.pt\t0.021\t0.016\t0.051\t0.374\n",
      "1d -4c/epoch14.pt\t0.019\t0.022\t0.061\t0.415\n",
      "1d -4c/epoch16.pt\t0.013\t0.021\t0.049\t0.283\n",
      "1d -4c/epoch20.pt\t0.001\t0.015\t0.055\t0.291\n",
      "1d -4c/epoch24.pt\t0.005\t0.014\t0.053\t0.302\n",
      "1d -4c/epoch28.pt\t0.014\t0.014\t0.061\t0.281\n",
      "1d -4c/epoch30.pt\t0.019\t0.018\t0.062\t0.210\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.077\t0.076\t0.048\t0.091\n",
      "1d -8c/epoch4.pt\t0.045\t0.055\t0.043\t-0.180\n",
      "1d -8c/epoch6.pt\t0.057\t0.055\t0.033\t-0.129\n",
      "1d -8c/epoch8.pt\t0.046\t0.039\t0.032\t0.073\n",
      "1d -8c/epoch10.pt\t0.035\t0.037\t0.035\t0.291\n",
      "1d -8c/epoch12.pt\t0.047\t0.048\t0.052\t0.347\n",
      "1d -8c/epoch14.pt\t0.041\t0.044\t0.045\t0.242\n",
      "1d -8c/epoch16.pt\t0.056\t0.053\t0.040\t0.146\n",
      "1d -8c/epoch20.pt\t0.038\t0.051\t0.051\t0.019\n",
      "1d -8c/epoch24.pt\t0.030\t0.036\t0.054\t0.073\n",
      "1d -8c/epoch28.pt\t0.026\t0.025\t0.056\t-0.134\n",
      "1d -8c/epoch30.pt\t0.022\t0.020\t0.064\t-0.217\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.080\t0.088\t0.064\t-0.129\n",
      "1d -10c/epoch4.pt\t0.073\t0.084\t0.074\t-0.193\n",
      "1d -10c/epoch6.pt\t0.085\t0.091\t0.079\t-0.129\n",
      "1d -10c/epoch8.pt\t0.086\t0.087\t0.101\t-0.030\n",
      "1d -10c/epoch10.pt\t0.079\t0.064\t0.122\t-0.091\n",
      "1d -10c/epoch12.pt\t0.080\t0.063\t0.128\t-0.161\n",
      "1d -10c/epoch14.pt\t0.088\t0.072\t0.124\t-0.181\n",
      "1d -10c/epoch16.pt\t0.085\t0.069\t0.124\t-0.263\n",
      "1d -10c/epoch20.pt\t0.080\t0.069\t0.120\t-0.275\n",
      "1d -10c/epoch24.pt\t0.085\t0.076\t0.120\t-0.205\n",
      "1d -10c/epoch28.pt\t0.089\t0.083\t0.116\t-0.151\n",
      "1d -10c/epoch30.pt\t0.078\t0.075\t0.124\t-0.149\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/' \n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.011\t0.014\t0.019\t0.032\n",
      "1d -1c/epoch4.pt\t0.006\t0.010\t0.020\t0.025\n",
      "1d -1c/epoch6.pt\t0.006\t0.010\t0.018\t0.008\n",
      "1d -1c/epoch8.pt\t0.008\t0.009\t0.023\t0.269\n",
      "1d -1c/epoch10.pt\t0.009\t0.011\t0.024\t-0.092\n",
      "1d -1c/epoch12.pt\t0.010\t0.011\t0.026\t-0.107\n",
      "1d -1c/epoch14.pt\t0.019\t0.020\t0.024\t-0.010\n",
      "1d -1c/epoch16.pt\t0.013\t0.017\t0.028\t-0.184\n",
      "1d -1c/epoch20.pt\t0.009\t0.016\t0.031\t-0.191\n",
      "1d -1c/epoch24.pt\t0.012\t0.019\t0.035\t-0.175\n",
      "1d -1c/epoch28.pt\t0.010\t0.010\t0.032\t-0.065\n",
      "1d -1c/epoch30.pt\t0.008\t0.010\t0.031\t-0.084\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.020\t0.025\t0.022\t-0.061\n",
      "1d -2c/epoch4.pt\t0.019\t0.019\t0.017\t0.085\n",
      "1d -2c/epoch6.pt\t0.014\t0.016\t0.021\t0.170\n",
      "1d -2c/epoch8.pt\t0.012\t0.016\t0.029\t0.198\n",
      "1d -2c/epoch10.pt\t0.014\t0.014\t0.031\t0.145\n",
      "1d -2c/epoch12.pt\t0.012\t0.015\t0.032\t0.236\n",
      "1d -2c/epoch14.pt\t0.010\t0.012\t0.038\t0.196\n",
      "1d -2c/epoch16.pt\t0.011\t0.014\t0.030\t0.004\n",
      "1d -2c/epoch20.pt\t0.014\t0.018\t0.038\t-0.167\n",
      "1d -2c/epoch24.pt\t0.014\t0.016\t0.036\t-0.019\n",
      "1d -2c/epoch28.pt\t0.016\t0.017\t0.038\t-0.086\n",
      "1d -2c/epoch30.pt\t0.018\t0.020\t0.038\t-0.162\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.036\t0.050\t0.040\t0.127\n",
      "1d -4c/epoch4.pt\t0.028\t0.037\t0.029\t0.087\n",
      "1d -4c/epoch6.pt\t0.034\t0.051\t0.045\t0.212\n",
      "1d -4c/epoch8.pt\t0.028\t0.041\t0.043\t0.148\n",
      "1d -4c/epoch10.pt\t0.027\t0.037\t0.043\t0.425\n",
      "1d -4c/epoch12.pt\t0.033\t0.040\t0.048\t0.278\n",
      "1d -4c/epoch14.pt\t0.025\t0.047\t0.059\t0.365\n",
      "1d -4c/epoch16.pt\t0.029\t0.046\t0.056\t0.101\n",
      "1d -4c/epoch20.pt\t0.019\t0.042\t0.064\t0.120\n",
      "1d -4c/epoch24.pt\t0.022\t0.042\t0.061\t0.081\n",
      "1d -4c/epoch28.pt\t0.031\t0.042\t0.070\t0.127\n",
      "1d -4c/epoch30.pt\t0.024\t0.044\t0.074\t0.127\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.068\t0.074\t0.065\t-0.073\n",
      "1d -8c/epoch4.pt\t0.055\t0.067\t0.058\t-0.228\n",
      "1d -8c/epoch6.pt\t0.067\t0.072\t0.058\t-0.112\n",
      "1d -8c/epoch8.pt\t0.055\t0.057\t0.050\t-0.028\n",
      "1d -8c/epoch10.pt\t0.053\t0.057\t0.045\t0.025\n",
      "1d -8c/epoch12.pt\t0.063\t0.073\t0.055\t0.232\n",
      "1d -8c/epoch14.pt\t0.073\t0.069\t0.056\t0.122\n",
      "1d -8c/epoch16.pt\t0.076\t0.078\t0.059\t-0.061\n",
      "1d -8c/epoch20.pt\t0.066\t0.078\t0.068\t-0.059\n",
      "1d -8c/epoch24.pt\t0.046\t0.063\t0.069\t-0.055\n",
      "1d -8c/epoch28.pt\t0.037\t0.052\t0.077\t-0.110\n",
      "1d -8c/epoch30.pt\t0.032\t0.046\t0.088\t-0.179\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.072\t0.087\t0.084\t-0.155\n",
      "1d -10c/epoch4.pt\t0.085\t0.095\t0.092\t-0.261\n",
      "1d -10c/epoch6.pt\t0.096\t0.109\t0.104\t-0.182\n",
      "1d -10c/epoch8.pt\t0.098\t0.106\t0.120\t-0.111\n",
      "1d -10c/epoch10.pt\t0.094\t0.084\t0.143\t-0.150\n",
      "1d -10c/epoch12.pt\t0.087\t0.088\t0.150\t-0.208\n",
      "1d -10c/epoch14.pt\t0.095\t0.098\t0.148\t-0.216\n",
      "1d -10c/epoch16.pt\t0.086\t0.094\t0.148\t-0.273\n",
      "1d -10c/epoch20.pt\t0.087\t0.096\t0.142\t-0.267\n",
      "1d -10c/epoch24.pt\t0.111\t0.104\t0.142\t-0.282\n",
      "1d -10c/epoch28.pt\t0.110\t0.110\t0.135\t-0.192\n",
      "1d -10c/epoch30.pt\t0.089\t0.101\t0.143\t-0.215\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "Similarity should decrease for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.001\t-0.009\t0.050\t0.177\n",
      "1d -1c/epoch4.pt\t0.008\t-0.006\t0.048\t0.025\n",
      "1d -1c/epoch6.pt\t-0.005\t-0.013\t0.043\t0.167\n",
      "1d -1c/epoch8.pt\t-0.005\t-0.011\t0.040\t0.136\n",
      "1d -1c/epoch10.pt\t0.003\t-0.012\t0.044\t0.106\n",
      "1d -1c/epoch12.pt\t0.002\t-0.007\t0.042\t0.177\n",
      "1d -1c/epoch14.pt\t0.016\t0.011\t0.045\t-0.015\n",
      "1d -1c/epoch16.pt\t-0.009\t-0.004\t0.045\t0.126\n",
      "1d -1c/epoch20.pt\t0.002\t-0.008\t0.046\t0.157\n",
      "1d -1c/epoch24.pt\t0.003\t-0.003\t0.049\t0.157\n",
      "1d -1c/epoch28.pt\t-0.003\t-0.003\t0.052\t0.157\n",
      "1d -1c/epoch30.pt\t0.001\t-0.003\t0.054\t0.187\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t-0.002\t0.005\t0.048\t0.258\n",
      "1d -2c/epoch4.pt\t0.006\t0.002\t0.047\t0.227\n",
      "1d -2c/epoch6.pt\t0.010\t-0.005\t0.047\t0.086\n",
      "1d -2c/epoch8.pt\t0.000\t-0.010\t0.055\t0.167\n",
      "1d -2c/epoch10.pt\t-0.005\t-0.011\t0.050\t0.136\n",
      "1d -2c/epoch12.pt\t0.012\t-0.002\t0.051\t0.076\n",
      "1d -2c/epoch14.pt\t0.005\t-0.012\t0.051\t0.187\n",
      "1d -2c/epoch16.pt\t-0.002\t-0.007\t0.052\t0.187\n",
      "1d -2c/epoch20.pt\t0.008\t-0.001\t0.054\t0.136\n",
      "1d -2c/epoch24.pt\t0.008\t0.001\t0.058\t0.126\n",
      "1d -2c/epoch28.pt\t0.005\t-0.002\t0.062\t0.106\n",
      "1d -2c/epoch30.pt\t0.005\t0.004\t0.059\t0.147\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.037\t0.017\t0.068\t0.126\n",
      "1d -4c/epoch4.pt\t0.003\t0.005\t0.069\t0.207\n",
      "1d -4c/epoch6.pt\t0.032\t0.017\t0.062\t0.076\n",
      "1d -4c/epoch8.pt\t0.018\t0.014\t0.059\t0.116\n",
      "1d -4c/epoch10.pt\t0.014\t0.012\t0.060\t0.147\n",
      "1d -4c/epoch12.pt\t0.029\t0.021\t0.058\t0.056\n",
      "1d -4c/epoch14.pt\t0.023\t0.025\t0.062\t0.096\n",
      "1d -4c/epoch16.pt\t0.023\t0.017\t0.053\t0.066\n",
      "1d -4c/epoch20.pt\t0.020\t0.017\t0.055\t0.106\n",
      "1d -4c/epoch24.pt\t0.020\t0.021\t0.062\t0.035\n",
      "1d -4c/epoch28.pt\t0.027\t0.025\t0.064\t0.015\n",
      "1d -4c/epoch30.pt\t0.030\t0.030\t0.068\t-0.025\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.065\t0.069\t0.069\t0.045\n",
      "1d -8c/epoch4.pt\t0.060\t0.047\t0.082\t0.025\n",
      "1d -8c/epoch6.pt\t0.013\t0.009\t0.084\t0.237\n",
      "1d -8c/epoch8.pt\t0.034\t0.009\t0.080\t0.126\n",
      "1d -8c/epoch10.pt\t0.018\t0.006\t0.071\t0.217\n",
      "1d -8c/epoch12.pt\t0.038\t0.031\t0.102\t0.116\n",
      "1d -8c/epoch14.pt\t0.028\t0.013\t0.083\t0.147\n",
      "1d -8c/epoch16.pt\t0.020\t0.031\t0.092\t0.086\n",
      "1d -8c/epoch20.pt\t0.049\t0.032\t0.132\t-0.005\n",
      "1d -8c/epoch24.pt\t0.038\t0.028\t0.103\t0.056\n",
      "1d -8c/epoch28.pt\t0.006\t0.012\t0.092\t0.066\n",
      "1d -8c/epoch30.pt\t0.002\t0.008\t0.099\t0.096\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.075\t0.082\t0.159\t0.015\n",
      "1d -10c/epoch4.pt\t0.090\t0.072\t0.175\t0.015\n",
      "1d -10c/epoch6.pt\t0.083\t0.065\t0.160\t0.035\n",
      "1d -10c/epoch8.pt\t0.094\t0.074\t0.171\t0.005\n",
      "1d -10c/epoch10.pt\t0.085\t0.080\t0.174\t0.025\n",
      "1d -10c/epoch12.pt\t0.104\t0.095\t0.182\t-0.015\n",
      "1d -10c/epoch14.pt\t0.118\t0.116\t0.184\t-0.035\n",
      "1d -10c/epoch16.pt\t0.130\t0.117\t0.179\t-0.025\n",
      "1d -10c/epoch20.pt\t0.144\t0.137\t0.177\t-0.096\n",
      "1d -10c/epoch24.pt\t0.143\t0.132\t0.185\t-0.076\n",
      "1d -10c/epoch28.pt\t0.096\t0.139\t0.211\t-0.035\n",
      "1d -10c/epoch30.pt\t0.099\t0.128\t0.215\t-0.056\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.013\t0.014\t0.027\t-0.136\n",
      "1d -1c/epoch4.pt\t0.016\t0.016\t0.031\t-0.066\n",
      "1d -1c/epoch6.pt\t0.009\t0.007\t0.025\t-0.147\n",
      "1d -1c/epoch8.pt\t0.009\t0.010\t0.032\t-0.136\n",
      "1d -1c/epoch10.pt\t0.002\t0.005\t0.040\t-0.136\n",
      "1d -1c/epoch12.pt\t0.015\t0.013\t0.039\t-0.147\n",
      "1d -1c/epoch14.pt\t0.036\t0.034\t0.048\t-0.248\n",
      "1d -1c/epoch16.pt\t0.023\t0.017\t0.046\t-0.197\n",
      "1d -1c/epoch20.pt\t0.015\t0.015\t0.046\t-0.106\n",
      "1d -1c/epoch24.pt\t0.017\t0.023\t0.048\t-0.126\n",
      "1d -1c/epoch28.pt\t0.015\t0.024\t0.044\t-0.187\n",
      "1d -1c/epoch30.pt\t0.027\t0.021\t0.045\t-0.197\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.015\t0.027\t0.038\t0.035\n",
      "1d -2c/epoch4.pt\t0.019\t0.023\t0.048\t0.025\n",
      "1d -2c/epoch6.pt\t0.013\t0.014\t0.043\t-0.045\n",
      "1d -2c/epoch8.pt\t0.007\t0.010\t0.052\t-0.005\n",
      "1d -2c/epoch10.pt\t0.005\t0.007\t0.049\t-0.086\n",
      "1d -2c/epoch12.pt\t0.014\t0.018\t0.052\t-0.086\n",
      "1d -2c/epoch14.pt\t0.011\t0.012\t0.047\t-0.045\n",
      "1d -2c/epoch16.pt\t0.013\t0.014\t0.058\t-0.025\n",
      "1d -2c/epoch20.pt\t0.020\t0.022\t0.065\t-0.056\n",
      "1d -2c/epoch24.pt\t0.026\t0.028\t0.067\t-0.106\n",
      "1d -2c/epoch28.pt\t0.029\t0.025\t0.069\t-0.136\n",
      "1d -2c/epoch30.pt\t0.032\t0.028\t0.068\t-0.096\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.030\t0.040\t0.061\t0.045\n",
      "1d -4c/epoch4.pt\t0.024\t0.027\t0.055\t0.056\n",
      "1d -4c/epoch6.pt\t0.033\t0.036\t0.062\t-0.025\n",
      "1d -4c/epoch8.pt\t0.041\t0.034\t0.072\t-0.035\n",
      "1d -4c/epoch10.pt\t0.041\t0.030\t0.072\t-0.015\n",
      "1d -4c/epoch12.pt\t0.042\t0.042\t0.066\t-0.167\n",
      "1d -4c/epoch14.pt\t0.046\t0.048\t0.066\t-0.086\n",
      "1d -4c/epoch16.pt\t0.036\t0.037\t0.069\t-0.086\n",
      "1d -4c/epoch20.pt\t0.043\t0.041\t0.079\t-0.076\n",
      "1d -4c/epoch24.pt\t0.036\t0.048\t0.083\t-0.096\n",
      "1d -4c/epoch28.pt\t0.064\t0.052\t0.087\t-0.177\n",
      "1d -4c/epoch30.pt\t0.062\t0.054\t0.093\t-0.187\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.099\t0.091\t0.082\t-0.147\n",
      "1d -8c/epoch4.pt\t0.063\t0.069\t0.099\t-0.045\n",
      "1d -8c/epoch6.pt\t0.028\t0.028\t0.093\t0.157\n",
      "1d -8c/epoch8.pt\t0.023\t0.029\t0.091\t0.096\n",
      "1d -8c/epoch10.pt\t0.022\t0.023\t0.087\t0.147\n",
      "1d -8c/epoch12.pt\t0.061\t0.052\t0.121\t-0.045\n",
      "1d -8c/epoch14.pt\t0.014\t0.036\t0.109\t0.056\n",
      "1d -8c/epoch16.pt\t0.018\t0.052\t0.129\t0.025\n",
      "1d -8c/epoch20.pt\t0.034\t0.056\t0.161\t-0.005\n",
      "1d -8c/epoch24.pt\t0.065\t0.055\t0.137\t-0.076\n",
      "1d -8c/epoch28.pt\t0.032\t0.039\t0.120\t-0.056\n",
      "1d -8c/epoch30.pt\t0.013\t0.032\t0.136\t0.025\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.075\t0.105\t0.164\t-0.035\n",
      "1d -10c/epoch4.pt\t0.083\t0.093\t0.181\t-0.035\n",
      "1d -10c/epoch6.pt\t0.121\t0.085\t0.171\t-0.025\n",
      "1d -10c/epoch8.pt\t0.096\t0.094\t0.186\t-0.025\n",
      "1d -10c/epoch10.pt\t0.113\t0.097\t0.189\t-0.056\n",
      "1d -10c/epoch12.pt\t0.119\t0.115\t0.200\t-0.076\n",
      "1d -10c/epoch14.pt\t0.147\t0.139\t0.203\t-0.086\n",
      "1d -10c/epoch16.pt\t0.145\t0.137\t0.205\t-0.106\n",
      "1d -10c/epoch20.pt\t0.141\t0.161\t0.199\t-0.136\n",
      "1d -10c/epoch24.pt\t0.136\t0.159\t0.194\t-0.116\n",
      "1d -10c/epoch28.pt\t0.137\t0.165\t0.204\t-0.096\n",
      "1d -10c/epoch30.pt\t0.135\t0.152\t0.209\t-0.116\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotaion -d +c models \n",
    "similarity should decrease for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.90%\t-6.09%\t15.90%\t13.02%\n",
      "-0.005d 1c/epoch4.pt\t-3.21%\t-9.09%\t13.04%\t15.72%\n",
      "-0.005d 1c/epoch6.pt\t-5.77%\t-9.27%\t13.25%\t30.27%\n",
      "-0.005d 1c/epoch8.pt\t-5.62%\t-11.04%\t14.08%\t7.94%\n",
      "-0.005d 1c/epoch10.pt\t-5.01%\t-7.10%\t8.57%\t12.57%\n",
      "-0.005d 1c/epoch12.pt\t-9.19%\t-9.56%\t9.25%\t22.59%\n",
      "-0.005d 1c/epoch14.pt\t-8.22%\t-9.24%\t8.08%\t19.04%\n",
      "-0.005d 1c/epoch16.pt\t-7.38%\t-10.45%\t9.09%\t17.19%\n",
      "-0.005d 1c/epoch20.pt\t-10.05%\t-11.58%\t8.84%\t1.30%\n",
      "-0.005d 1c/epoch24.pt\t-9.06%\t-12.02%\t8.90%\t18.89%\n",
      "-0.005d 1c/epoch28.pt\t-9.85%\t-12.58%\t9.64%\t25.11%\n",
      "-0.005d 1c/epoch30.pt\t-9.17%\t-11.36%\t8.71%\t34.97%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t23.64%\t26.40%\t10.85%\t0.28%\n",
      "-0.05d 1c/epoch4.pt\t24.48%\t27.31%\t11.41%\t-6.15%\n",
      "-0.05d 1c/epoch6.pt\t16.31%\t17.88%\t9.01%\t-9.14%\n",
      "-0.05d 1c/epoch8.pt\t13.93%\t15.64%\t8.74%\t-10.14%\n",
      "-0.05d 1c/epoch10.pt\t9.89%\t11.98%\t8.49%\t-13.85%\n",
      "-0.05d 1c/epoch12.pt\t8.06%\t9.97%\t8.60%\t-13.91%\n",
      "-0.05d 1c/epoch14.pt\t8.45%\t9.55%\t8.43%\t-12.55%\n",
      "-0.05d 1c/epoch16.pt\t16.41%\t19.04%\t9.48%\t-9.40%\n",
      "-0.05d 1c/epoch20.pt\t8.35%\t10.20%\t8.43%\t-6.79%\n",
      "-0.05d 1c/epoch24.pt\t3.99%\t5.36%\t8.49%\t-7.97%\n",
      "-0.05d 1c/epoch28.pt\t3.17%\t3.86%\t8.17%\t-8.64%\n",
      "-0.05d 1c/epoch30.pt\t2.40%\t3.13%\t8.55%\t-2.94%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-1.90%\t-7.85%\t15.76%\t8.31%\n",
      "-0.01d 1c/epoch4.pt\t-5.17%\t-10.15%\t12.21%\t9.42%\n",
      "-0.01d 1c/epoch6.pt\t-7.78%\t-10.82%\t12.03%\t27.50%\n",
      "-0.01d 1c/epoch8.pt\t-5.64%\t-11.14%\t11.83%\t-0.85%\n",
      "-0.01d 1c/epoch10.pt\t-9.09%\t-9.82%\t8.96%\t-0.63%\n",
      "-0.01d 1c/epoch12.pt\t-10.51%\t-11.32%\t8.40%\t14.15%\n",
      "-0.01d 1c/epoch14.pt\t-10.63%\t-11.06%\t7.36%\t16.23%\n",
      "-0.01d 1c/epoch16.pt\t-10.71%\t-13.00%\t8.77%\t9.55%\n",
      "-0.01d 1c/epoch20.pt\t-10.98%\t-14.39%\t10.07%\t-3.84%\n",
      "-0.01d 1c/epoch24.pt\t-11.27%\t-13.37%\t8.55%\t10.52%\n",
      "-0.01d 1c/epoch28.pt\t-11.85%\t-13.42%\t9.28%\t14.02%\n",
      "-0.01d 1c/epoch30.pt\t-10.80%\t-12.55%\t8.86%\t30.16%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t28.03%\t31.08%\t12.69%\t-6.39%\n",
      "-0.1d 1c/epoch4.pt\t29.20%\t32.01%\t13.08%\t-6.26%\n",
      "-0.1d 1c/epoch6.pt\t29.46%\t32.24%\t13.16%\t-6.26%\n",
      "-0.1d 1c/epoch8.pt\t29.56%\t32.25%\t13.19%\t-6.84%\n",
      "-0.1d 1c/epoch10.pt\t29.55%\t32.21%\t13.19%\t-6.84%\n",
      "-0.1d 1c/epoch12.pt\t29.65%\t32.18%\t13.19%\t-6.84%\n",
      "-0.1d 1c/epoch14.pt\t29.58%\t32.07%\t13.18%\t-6.84%\n",
      "-0.1d 1c/epoch16.pt\t29.42%\t31.92%\t13.17%\t-6.84%\n",
      "-0.1d 1c/epoch20.pt\t28.80%\t31.44%\t13.08%\t-6.64%\n",
      "-0.1d 1c/epoch24.pt\t27.46%\t30.47%\t12.93%\t-7.06%\n",
      "-0.1d 1c/epoch28.pt\t26.61%\t29.42%\t12.72%\t-7.92%\n",
      "-0.1d 1c/epoch30.pt\t26.34%\t28.97%\t12.67%\t-6.68%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t29.60%\t32.06%\t12.95%\t-5.55%\n",
      "-0.2d 1c/epoch4.pt\t30.28%\t32.77%\t13.17%\t-6.68%\n",
      "-0.2d 1c/epoch6.pt\t30.47%\t32.98%\t13.24%\t-7.11%\n",
      "-0.2d 1c/epoch8.pt\t30.53%\t33.07%\t13.28%\t-7.11%\n",
      "-0.2d 1c/epoch10.pt\t30.58%\t33.12%\t13.30%\t-6.26%\n",
      "-0.2d 1c/epoch12.pt\t30.60%\t33.16%\t13.32%\t-6.39%\n",
      "-0.2d 1c/epoch14.pt\t30.57%\t33.17%\t13.32%\t-6.39%\n",
      "-0.2d 1c/epoch16.pt\t30.56%\t33.20%\t13.33%\t-6.39%\n",
      "-0.2d 1c/epoch20.pt\t30.53%\t33.21%\t13.32%\t-5.82%\n",
      "-0.2d 1c/epoch24.pt\t30.58%\t33.23%\t13.31%\t-6.26%\n",
      "-0.2d 1c/epoch28.pt\t30.67%\t33.25%\t13.32%\t-5.27%\n",
      "-0.2d 1c/epoch30.pt\t30.72%\t33.27%\t13.33%\t-5.27%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t30.10%\t32.35%\t13.11%\t-6.39%\n",
      "-0.4d 1c/epoch4.pt\t30.54%\t33.00%\t13.27%\t-6.81%\n",
      "-0.4d 1c/epoch6.pt\t30.65%\t33.15%\t13.31%\t-7.11%\n",
      "-0.4d 1c/epoch8.pt\t30.66%\t33.22%\t13.32%\t-6.39%\n",
      "-0.4d 1c/epoch10.pt\t30.73%\t33.28%\t13.34%\t-5.69%\n",
      "-0.4d 1c/epoch12.pt\t30.79%\t33.31%\t13.36%\t-5.69%\n",
      "-0.4d 1c/epoch14.pt\t30.82%\t33.33%\t13.37%\t-5.69%\n",
      "-0.4d 1c/epoch16.pt\t30.86%\t33.36%\t13.38%\t-5.27%\n",
      "-0.4d 1c/epoch20.pt\t30.90%\t33.39%\t13.40%\t-5.27%\n",
      "-0.4d 1c/epoch24.pt\t30.93%\t33.41%\t13.40%\t-5.69%\n",
      "-0.4d 1c/epoch28.pt\t30.95%\t33.42%\t13.41%\t-5.69%\n",
      "-0.4d 1c/epoch30.pt\t30.95%\t33.43%\t13.41%\t-5.69%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t30.34%\t32.59%\t13.18%\t-5.97%\n",
      "-0.8d 1c/epoch4.pt\t30.70%\t33.12%\t13.32%\t-6.68%\n",
      "-0.8d 1c/epoch6.pt\t30.80%\t33.25%\t13.36%\t-7.11%\n",
      "-0.8d 1c/epoch8.pt\t30.82%\t33.31%\t13.37%\t-5.82%\n",
      "-0.8d 1c/epoch10.pt\t30.85%\t33.32%\t13.37%\t-5.69%\n",
      "-0.8d 1c/epoch12.pt\t30.88%\t33.35%\t13.38%\t-5.27%\n",
      "-0.8d 1c/epoch14.pt\t30.88%\t33.36%\t13.39%\t-5.27%\n",
      "-0.8d 1c/epoch16.pt\t30.89%\t33.34%\t13.39%\t-5.98%\n",
      "-0.8d 1c/epoch20.pt\t30.92%\t33.37%\t13.39%\t-5.69%\n",
      "-0.8d 1c/epoch24.pt\t30.92%\t33.39%\t13.40%\t-5.69%\n",
      "-0.8d 1c/epoch28.pt\t30.93%\t33.41%\t13.40%\t-5.69%\n",
      "-0.8d 1c/epoch30.pt\t30.93%\t33.41%\t13.40%\t-5.69%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.99%\t-2.26%\t2.23%\t8.96%\n",
      "-0.005d 1c/epoch4.pt\t-0.86%\t-1.34%\t3.71%\t26.24%\n",
      "-0.005d 1c/epoch6.pt\t-2.65%\t-3.21%\t4.17%\t29.86%\n",
      "-0.005d 1c/epoch8.pt\t-4.20%\t-5.29%\t5.16%\t-8.08%\n",
      "-0.005d 1c/epoch10.pt\t-2.51%\t-3.03%\t3.11%\t24.46%\n",
      "-0.005d 1c/epoch12.pt\t-4.44%\t-4.50%\t3.07%\t4.93%\n",
      "-0.005d 1c/epoch14.pt\t-2.71%\t-3.49%\t3.60%\t-8.37%\n",
      "-0.005d 1c/epoch16.pt\t-4.68%\t-4.48%\t4.64%\t8.79%\n",
      "-0.005d 1c/epoch20.pt\t-3.43%\t-3.09%\t3.97%\t10.40%\n",
      "-0.005d 1c/epoch24.pt\t-3.76%\t-3.44%\t3.48%\t10.67%\n",
      "-0.005d 1c/epoch28.pt\t-4.01%\t-4.35%\t4.63%\t-3.72%\n",
      "-0.005d 1c/epoch30.pt\t-5.20%\t-4.35%\t4.80%\t3.21%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t24.39%\t30.23%\t20.44%\t-9.45%\n",
      "-0.05d 1c/epoch4.pt\t31.64%\t35.06%\t19.84%\t-3.55%\n",
      "-0.05d 1c/epoch6.pt\t20.39%\t23.94%\t16.07%\t-17.81%\n",
      "-0.05d 1c/epoch8.pt\t15.53%\t21.39%\t15.82%\t-8.02%\n",
      "-0.05d 1c/epoch10.pt\t12.28%\t16.05%\t12.04%\t-8.99%\n",
      "-0.05d 1c/epoch12.pt\t15.78%\t15.03%\t11.78%\t-25.07%\n",
      "-0.05d 1c/epoch14.pt\t12.27%\t15.30%\t11.07%\t-25.57%\n",
      "-0.05d 1c/epoch16.pt\t23.96%\t25.01%\t13.40%\t-13.23%\n",
      "-0.05d 1c/epoch20.pt\t15.09%\t18.69%\t13.97%\t-1.33%\n",
      "-0.05d 1c/epoch24.pt\t12.85%\t13.93%\t12.25%\t-11.52%\n",
      "-0.05d 1c/epoch28.pt\t9.16%\t12.08%\t13.46%\t-21.98%\n",
      "-0.05d 1c/epoch30.pt\t7.56%\t10.14%\t12.14%\t-24.39%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-4.33%\t-4.02%\t3.19%\t-2.90%\n",
      "-0.01d 1c/epoch4.pt\t-1.60%\t-2.40%\t5.96%\t14.70%\n",
      "-0.01d 1c/epoch6.pt\t-4.82%\t-4.76%\t4.99%\t14.51%\n",
      "-0.01d 1c/epoch8.pt\t-4.59%\t-5.39%\t5.65%\t-20.63%\n",
      "-0.01d 1c/epoch10.pt\t-5.66%\t-5.75%\t3.50%\t-21.18%\n",
      "-0.01d 1c/epoch12.pt\t-5.73%\t-6.26%\t4.23%\t-22.62%\n",
      "-0.01d 1c/epoch14.pt\t-4.38%\t-5.31%\t4.69%\t-25.55%\n",
      "-0.01d 1c/epoch16.pt\t-6.31%\t-7.03%\t4.95%\t-8.79%\n",
      "-0.01d 1c/epoch20.pt\t-4.94%\t-5.91%\t4.91%\t-1.03%\n",
      "-0.01d 1c/epoch24.pt\t-4.40%\t-4.79%\t4.65%\t-7.63%\n",
      "-0.01d 1c/epoch28.pt\t-4.59%\t-5.20%\t6.56%\t-6.54%\n",
      "-0.01d 1c/epoch30.pt\t-5.47%\t-5.54%\t4.77%\t-3.14%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t26.80%\t34.90%\t22.59%\t-9.16%\n",
      "-0.1d 1c/epoch4.pt\t35.75%\t39.76%\t21.64%\t-5.49%\n",
      "-0.1d 1c/epoch6.pt\t33.29%\t38.30%\t20.80%\t-17.80%\n",
      "-0.1d 1c/epoch8.pt\t32.14%\t38.00%\t21.22%\t-8.99%\n",
      "-0.1d 1c/epoch10.pt\t34.07%\t36.29%\t17.48%\t-7.15%\n",
      "-0.1d 1c/epoch12.pt\t38.67%\t37.25%\t17.90%\t-17.02%\n",
      "-0.1d 1c/epoch14.pt\t38.04%\t37.82%\t16.56%\t-18.23%\n",
      "-0.1d 1c/epoch16.pt\t37.35%\t37.90%\t17.17%\t-12.08%\n",
      "-0.1d 1c/epoch20.pt\t32.63%\t39.93%\t19.76%\t-3.45%\n",
      "-0.1d 1c/epoch24.pt\t38.51%\t39.04%\t17.96%\t-12.52%\n",
      "-0.1d 1c/epoch28.pt\t34.20%\t37.64%\t19.35%\t-14.83%\n",
      "-0.1d 1c/epoch30.pt\t30.60%\t35.98%\t18.26%\t-19.63%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t27.52%\t35.89%\t22.81%\t-9.58%\n",
      "-0.2d 1c/epoch4.pt\t36.29%\t40.53%\t21.72%\t-4.70%\n",
      "-0.2d 1c/epoch6.pt\t33.92%\t39.04%\t20.84%\t-17.23%\n",
      "-0.2d 1c/epoch8.pt\t33.65%\t38.82%\t21.30%\t-10.03%\n",
      "-0.2d 1c/epoch10.pt\t34.71%\t37.19%\t17.60%\t-5.74%\n",
      "-0.2d 1c/epoch12.pt\t39.29%\t38.22%\t18.08%\t-16.59%\n",
      "-0.2d 1c/epoch14.pt\t38.87%\t38.92%\t16.73%\t-19.91%\n",
      "-0.2d 1c/epoch16.pt\t38.82%\t39.17%\t17.34%\t-12.36%\n",
      "-0.2d 1c/epoch20.pt\t35.56%\t41.70%\t19.94%\t-3.30%\n",
      "-0.2d 1c/epoch24.pt\t40.42%\t41.80%\t18.24%\t-13.01%\n",
      "-0.2d 1c/epoch28.pt\t36.70%\t41.47%\t19.66%\t-14.96%\n",
      "-0.2d 1c/epoch30.pt\t36.38%\t40.28%\t18.86%\t-18.11%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t27.70%\t36.18%\t22.98%\t-9.88%\n",
      "-0.4d 1c/epoch4.pt\t36.43%\t40.75%\t21.82%\t-5.27%\n",
      "-0.4d 1c/epoch6.pt\t34.10%\t39.21%\t20.89%\t-16.81%\n",
      "-0.4d 1c/epoch8.pt\t33.78%\t38.97%\t21.33%\t-10.45%\n",
      "-0.4d 1c/epoch10.pt\t34.86%\t37.35%\t17.64%\t-5.74%\n",
      "-0.4d 1c/epoch12.pt\t39.42%\t38.37%\t18.12%\t-16.59%\n",
      "-0.4d 1c/epoch14.pt\t38.98%\t39.08%\t16.77%\t-20.33%\n",
      "-0.4d 1c/epoch16.pt\t39.02%\t39.33%\t17.39%\t-12.36%\n",
      "-0.4d 1c/epoch20.pt\t35.69%\t41.88%\t20.02%\t-3.72%\n",
      "-0.4d 1c/epoch24.pt\t40.53%\t41.98%\t18.34%\t-12.59%\n",
      "-0.4d 1c/epoch28.pt\t36.80%\t41.65%\t19.74%\t-14.54%\n",
      "-0.4d 1c/epoch30.pt\t36.55%\t40.43%\t18.95%\t-18.53%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t27.81%\t36.42%\t23.04%\t-9.45%\n",
      "-0.8d 1c/epoch4.pt\t36.47%\t40.87%\t21.88%\t-4.70%\n",
      "-0.8d 1c/epoch6.pt\t34.14%\t39.31%\t20.94%\t-16.81%\n",
      "-0.8d 1c/epoch8.pt\t33.85%\t39.06%\t21.38%\t-10.03%\n",
      "-0.8d 1c/epoch10.pt\t34.88%\t37.40%\t17.67%\t-5.74%\n",
      "-0.8d 1c/epoch12.pt\t39.45%\t38.41%\t18.14%\t-16.59%\n",
      "-0.8d 1c/epoch14.pt\t39.06%\t39.11%\t16.80%\t-20.33%\n",
      "-0.8d 1c/epoch16.pt\t38.68%\t39.31%\t17.42%\t-12.36%\n",
      "-0.8d 1c/epoch20.pt\t35.70%\t41.85%\t20.01%\t-3.72%\n",
      "-0.8d 1c/epoch24.pt\t40.53%\t41.97%\t18.34%\t-12.59%\n",
      "-0.8d 1c/epoch28.pt\t36.80%\t41.63%\t19.73%\t-14.54%\n",
      "-0.8d 1c/epoch30.pt\t36.54%\t40.42%\t18.94%\t-18.53%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotation -d +c models \n",
    "similarity should increase for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t11.76%\t15.89%\t19.39%\t-15.66%\n",
      "-0.005d 1c/epoch4.pt\t6.12%\t7.55%\t16.83%\t1.52%\n",
      "-0.005d 1c/epoch6.pt\t5.72%\t4.41%\t15.28%\t1.52%\n",
      "-0.005d 1c/epoch8.pt\t1.86%\t0.62%\t13.03%\t13.64%\n",
      "-0.005d 1c/epoch10.pt\t3.18%\t4.49%\t12.66%\t1.52%\n",
      "-0.005d 1c/epoch12.pt\t-0.13%\t-0.38%\t14.91%\t2.53%\n",
      "-0.005d 1c/epoch14.pt\t1.69%\t0.51%\t9.40%\t-13.64%\n",
      "-0.005d 1c/epoch16.pt\t-1.31%\t-0.83%\t11.08%\t-9.60%\n",
      "-0.005d 1c/epoch20.pt\t-2.92%\t-2.13%\t11.43%\t0.51%\n",
      "-0.005d 1c/epoch24.pt\t-1.99%\t-1.05%\t10.99%\t-8.59%\n",
      "-0.005d 1c/epoch28.pt\t-1.52%\t-1.67%\t10.75%\t-3.54%\n",
      "-0.005d 1c/epoch30.pt\t-3.87%\t-2.36%\t12.01%\t-7.58%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t69.25%\t61.04%\t20.77%\t-45.98%\n",
      "-0.05d 1c/epoch4.pt\t71.93%\t64.30%\t22.37%\t-45.98%\n",
      "-0.05d 1c/epoch6.pt\t49.16%\t46.24%\t17.84%\t-45.98%\n",
      "-0.05d 1c/epoch8.pt\t43.90%\t41.94%\t16.74%\t-45.98%\n",
      "-0.05d 1c/epoch10.pt\t40.99%\t35.43%\t16.46%\t-44.97%\n",
      "-0.05d 1c/epoch12.pt\t34.39%\t33.31%\t15.79%\t-43.96%\n",
      "-0.05d 1c/epoch14.pt\t37.08%\t32.72%\t15.80%\t-42.95%\n",
      "-0.05d 1c/epoch16.pt\t53.65%\t47.66%\t17.72%\t-45.98%\n",
      "-0.05d 1c/epoch20.pt\t40.05%\t34.40%\t16.12%\t-44.97%\n",
      "-0.05d 1c/epoch24.pt\t31.53%\t27.94%\t16.42%\t-42.95%\n",
      "-0.05d 1c/epoch28.pt\t27.62%\t26.23%\t15.92%\t-42.95%\n",
      "-0.05d 1c/epoch30.pt\t27.08%\t24.99%\t16.07%\t-42.95%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t12.66%\t14.07%\t19.41%\t-16.68%\n",
      "-0.01d 1c/epoch4.pt\t4.67%\t5.98%\t15.66%\t0.51%\n",
      "-0.01d 1c/epoch6.pt\t2.37%\t2.75%\t13.69%\t0.51%\n",
      "-0.01d 1c/epoch8.pt\t-0.32%\t-0.56%\t11.76%\t6.57%\n",
      "-0.01d 1c/epoch10.pt\t4.01%\t3.71%\t11.93%\t-9.60%\n",
      "-0.01d 1c/epoch12.pt\t-2.42%\t-2.37%\t12.34%\t-1.52%\n",
      "-0.01d 1c/epoch14.pt\t-0.53%\t-0.77%\t7.54%\t-14.65%\n",
      "-0.01d 1c/epoch16.pt\t-1.51%\t-0.61%\t9.06%\t-18.70%\n",
      "-0.01d 1c/epoch20.pt\t-3.56%\t-1.45%\t10.94%\t-4.55%\n",
      "-0.01d 1c/epoch24.pt\t-3.12%\t-1.52%\t10.43%\t-13.64%\n",
      "-0.01d 1c/epoch28.pt\t-1.56%\t-1.25%\t11.14%\t-12.63%\n",
      "-0.01d 1c/epoch30.pt\t-3.53%\t-1.97%\t11.97%\t-26.78%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t81.68%\t72.16%\t24.78%\t-45.98%\n",
      "-0.1d 1c/epoch4.pt\t84.66%\t75.07%\t25.81%\t-45.98%\n",
      "-0.1d 1c/epoch6.pt\t85.58%\t75.62%\t25.96%\t-45.98%\n",
      "-0.1d 1c/epoch8.pt\t85.94%\t75.68%\t25.96%\t-45.98%\n",
      "-0.1d 1c/epoch10.pt\t85.94%\t75.64%\t25.95%\t-45.98%\n",
      "-0.1d 1c/epoch12.pt\t85.72%\t75.61%\t25.93%\t-45.98%\n",
      "-0.1d 1c/epoch14.pt\t85.30%\t75.45%\t25.86%\t-45.98%\n",
      "-0.1d 1c/epoch16.pt\t85.14%\t75.19%\t25.77%\t-45.98%\n",
      "-0.1d 1c/epoch20.pt\t84.35%\t74.39%\t25.56%\t-45.98%\n",
      "-0.1d 1c/epoch24.pt\t81.66%\t72.79%\t25.15%\t-45.98%\n",
      "-0.1d 1c/epoch28.pt\t79.56%\t71.16%\t24.72%\t-45.98%\n",
      "-0.1d 1c/epoch30.pt\t79.19%\t70.43%\t24.54%\t-45.98%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t82.90%\t73.28%\t24.95%\t-45.98%\n",
      "-0.2d 1c/epoch4.pt\t87.06%\t76.14%\t26.03%\t-45.98%\n",
      "-0.2d 1c/epoch6.pt\t87.92%\t76.84%\t26.32%\t-45.98%\n",
      "-0.2d 1c/epoch8.pt\t88.10%\t77.11%\t26.43%\t-45.98%\n",
      "-0.2d 1c/epoch10.pt\t88.18%\t77.21%\t26.47%\t-45.98%\n",
      "-0.2d 1c/epoch12.pt\t88.30%\t77.32%\t26.51%\t-45.98%\n",
      "-0.2d 1c/epoch14.pt\t88.33%\t77.37%\t26.53%\t-45.98%\n",
      "-0.2d 1c/epoch16.pt\t88.38%\t77.42%\t26.55%\t-45.98%\n",
      "-0.2d 1c/epoch20.pt\t88.37%\t77.48%\t26.57%\t-45.98%\n",
      "-0.2d 1c/epoch24.pt\t88.46%\t77.53%\t26.58%\t-45.98%\n",
      "-0.2d 1c/epoch28.pt\t88.47%\t77.50%\t26.57%\t-45.98%\n",
      "-0.2d 1c/epoch30.pt\t88.55%\t77.54%\t26.58%\t-45.98%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t84.74%\t74.75%\t25.44%\t-45.98%\n",
      "-0.4d 1c/epoch4.pt\t87.88%\t76.75%\t26.27%\t-45.98%\n",
      "-0.4d 1c/epoch6.pt\t88.23%\t77.20%\t26.45%\t-45.98%\n",
      "-0.4d 1c/epoch8.pt\t88.32%\t77.39%\t26.52%\t-45.98%\n",
      "-0.4d 1c/epoch10.pt\t88.46%\t77.50%\t26.56%\t-45.98%\n",
      "-0.4d 1c/epoch12.pt\t88.54%\t77.52%\t26.56%\t-45.98%\n",
      "-0.4d 1c/epoch14.pt\t88.59%\t77.58%\t26.58%\t-45.98%\n",
      "-0.4d 1c/epoch16.pt\t88.64%\t77.64%\t26.60%\t-45.98%\n",
      "-0.4d 1c/epoch20.pt\t88.71%\t77.70%\t26.62%\t-45.98%\n",
      "-0.4d 1c/epoch24.pt\t88.72%\t77.75%\t26.63%\t-45.98%\n",
      "-0.4d 1c/epoch28.pt\t88.74%\t77.78%\t26.65%\t-45.98%\n",
      "-0.4d 1c/epoch30.pt\t88.76%\t77.79%\t26.65%\t-45.98%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t85.20%\t75.35%\t25.73%\t-45.98%\n",
      "-0.8d 1c/epoch4.pt\t88.21%\t77.01%\t26.36%\t-45.98%\n",
      "-0.8d 1c/epoch6.pt\t88.46%\t77.40%\t26.52%\t-45.98%\n",
      "-0.8d 1c/epoch8.pt\t88.58%\t77.55%\t26.58%\t-45.98%\n",
      "-0.8d 1c/epoch10.pt\t88.59%\t77.58%\t26.58%\t-45.98%\n",
      "-0.8d 1c/epoch12.pt\t88.65%\t77.60%\t26.58%\t-45.98%\n",
      "-0.8d 1c/epoch14.pt\t88.68%\t77.62%\t26.58%\t-45.98%\n",
      "-0.8d 1c/epoch16.pt\t88.56%\t77.59%\t26.57%\t-45.98%\n",
      "-0.8d 1c/epoch20.pt\t88.59%\t77.66%\t26.60%\t-45.98%\n",
      "-0.8d 1c/epoch24.pt\t88.67%\t77.72%\t26.62%\t-45.98%\n",
      "-0.8d 1c/epoch28.pt\t88.71%\t77.75%\t26.63%\t-45.98%\n",
      "-0.8d 1c/epoch30.pt\t88.73%\t77.76%\t26.63%\t-45.98%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.42%\t-1.58%\t4.00%\t17.69%\n",
      "-0.005d 1c/epoch4.pt\t-1.22%\t-1.32%\t3.94%\t-8.59%\n",
      "-0.005d 1c/epoch6.pt\t-1.84%\t-1.68%\t4.79%\t5.56%\n",
      "-0.005d 1c/epoch8.pt\t-1.57%\t-1.86%\t4.82%\t2.53%\n",
      "-0.005d 1c/epoch10.pt\t-1.24%\t-1.51%\t3.83%\t4.55%\n",
      "-0.005d 1c/epoch12.pt\t-2.03%\t-1.29%\t4.22%\t-3.54%\n",
      "-0.005d 1c/epoch14.pt\t-0.97%\t-1.13%\t3.74%\t4.55%\n",
      "-0.005d 1c/epoch16.pt\t-2.69%\t-2.14%\t5.21%\t0.51%\n",
      "-0.005d 1c/epoch20.pt\t-1.00%\t-1.94%\t5.45%\t-3.54%\n",
      "-0.005d 1c/epoch24.pt\t-3.32%\t-3.63%\t7.06%\t2.53%\n",
      "-0.005d 1c/epoch28.pt\t-2.09%\t-3.87%\t8.44%\t2.53%\n",
      "-0.005d 1c/epoch30.pt\t-2.91%\t-2.33%\t7.49%\t5.56%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t41.48%\t43.58%\t26.00%\t-46.99%\n",
      "-0.05d 1c/epoch4.pt\t60.99%\t55.44%\t26.01%\t-46.99%\n",
      "-0.05d 1c/epoch6.pt\t38.12%\t40.15%\t22.63%\t-46.99%\n",
      "-0.05d 1c/epoch8.pt\t41.65%\t39.46%\t20.57%\t-46.99%\n",
      "-0.05d 1c/epoch10.pt\t29.07%\t29.43%\t19.31%\t-45.98%\n",
      "-0.05d 1c/epoch12.pt\t31.45%\t32.40%\t19.71%\t-45.98%\n",
      "-0.05d 1c/epoch14.pt\t30.58%\t31.08%\t17.44%\t-43.96%\n",
      "-0.05d 1c/epoch16.pt\t51.74%\t46.36%\t19.90%\t-46.99%\n",
      "-0.05d 1c/epoch20.pt\t36.11%\t34.59%\t16.72%\t-44.97%\n",
      "-0.05d 1c/epoch24.pt\t25.75%\t25.36%\t16.32%\t-41.94%\n",
      "-0.05d 1c/epoch28.pt\t22.43%\t24.03%\t17.37%\t-38.91%\n",
      "-0.05d 1c/epoch30.pt\t25.34%\t25.02%\t17.83%\t-38.91%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-3.46%\t-3.39%\t5.40%\t8.59%\n",
      "-0.01d 1c/epoch4.pt\t-3.48%\t-2.89%\t6.51%\t6.57%\n",
      "-0.01d 1c/epoch6.pt\t-3.57%\t-3.34%\t6.69%\t3.54%\n",
      "-0.01d 1c/epoch8.pt\t-2.62%\t-3.04%\t6.39%\t-8.59%\n",
      "-0.01d 1c/epoch10.pt\t-3.03%\t-2.30%\t4.68%\t-11.62%\n",
      "-0.01d 1c/epoch12.pt\t-5.32%\t-3.28%\t6.12%\t-1.52%\n",
      "-0.01d 1c/epoch14.pt\t-2.69%\t-2.41%\t5.18%\t-12.63%\n",
      "-0.01d 1c/epoch16.pt\t-3.21%\t-1.92%\t6.77%\t-9.60%\n",
      "-0.01d 1c/epoch20.pt\t-2.63%\t-1.25%\t5.89%\t-1.52%\n",
      "-0.01d 1c/epoch24.pt\t-3.87%\t-4.11%\t7.29%\t-4.55%\n",
      "-0.01d 1c/epoch28.pt\t-2.82%\t-3.45%\t10.97%\t-13.64%\n",
      "-0.01d 1c/epoch30.pt\t-4.45%\t-1.95%\t10.27%\t-12.63%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t58.02%\t54.69%\t28.30%\t-45.98%\n",
      "-0.1d 1c/epoch4.pt\t73.93%\t66.20%\t28.35%\t-45.98%\n",
      "-0.1d 1c/epoch6.pt\t72.37%\t69.53%\t29.19%\t-46.99%\n",
      "-0.1d 1c/epoch8.pt\t79.38%\t73.20%\t28.83%\t-46.99%\n",
      "-0.1d 1c/epoch10.pt\t74.03%\t69.63%\t27.19%\t-45.98%\n",
      "-0.1d 1c/epoch12.pt\t78.31%\t74.70%\t28.11%\t-45.98%\n",
      "-0.1d 1c/epoch14.pt\t82.25%\t73.81%\t26.82%\t-45.98%\n",
      "-0.1d 1c/epoch16.pt\t82.59%\t73.89%\t26.15%\t-46.99%\n",
      "-0.1d 1c/epoch20.pt\t82.92%\t74.59%\t25.94%\t-45.98%\n",
      "-0.1d 1c/epoch24.pt\t77.99%\t70.21%\t24.78%\t-46.99%\n",
      "-0.1d 1c/epoch28.pt\t76.67%\t68.96%\t25.00%\t-46.99%\n",
      "-0.1d 1c/epoch30.pt\t77.89%\t70.46%\t25.62%\t-46.99%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t60.82%\t55.82%\t28.48%\t-45.98%\n",
      "-0.2d 1c/epoch4.pt\t75.44%\t67.27%\t28.53%\t-45.98%\n",
      "-0.2d 1c/epoch6.pt\t74.31%\t70.75%\t29.48%\t-46.99%\n",
      "-0.2d 1c/epoch8.pt\t80.20%\t74.63%\t29.31%\t-46.99%\n",
      "-0.2d 1c/epoch10.pt\t75.45%\t71.21%\t27.66%\t-45.98%\n",
      "-0.2d 1c/epoch12.pt\t80.45%\t76.41%\t28.57%\t-45.98%\n",
      "-0.2d 1c/epoch14.pt\t84.93%\t75.73%\t27.35%\t-45.98%\n",
      "-0.2d 1c/epoch16.pt\t84.39%\t76.12%\t26.71%\t-46.99%\n",
      "-0.2d 1c/epoch20.pt\t86.81%\t77.67%\t26.80%\t-45.98%\n",
      "-0.2d 1c/epoch24.pt\t82.64%\t74.95%\t25.96%\t-45.98%\n",
      "-0.2d 1c/epoch28.pt\t84.13%\t75.30%\t26.60%\t-46.99%\n",
      "-0.2d 1c/epoch30.pt\t85.07%\t77.57%\t27.36%\t-45.98%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t61.20%\t57.28%\t28.59%\t-45.98%\n",
      "-0.4d 1c/epoch4.pt\t75.86%\t67.88%\t28.65%\t-45.98%\n",
      "-0.4d 1c/epoch6.pt\t75.13%\t71.11%\t29.54%\t-46.99%\n",
      "-0.4d 1c/epoch8.pt\t80.33%\t74.92%\t29.40%\t-46.99%\n",
      "-0.4d 1c/epoch10.pt\t75.82%\t71.50%\t27.73%\t-45.98%\n",
      "-0.4d 1c/epoch12.pt\t80.52%\t76.61%\t28.62%\t-45.98%\n",
      "-0.4d 1c/epoch14.pt\t85.14%\t75.94%\t27.40%\t-45.98%\n",
      "-0.4d 1c/epoch16.pt\t84.63%\t76.34%\t26.76%\t-46.99%\n",
      "-0.4d 1c/epoch20.pt\t86.33%\t77.89%\t26.85%\t-45.98%\n",
      "-0.4d 1c/epoch24.pt\t82.98%\t75.17%\t26.02%\t-45.98%\n",
      "-0.4d 1c/epoch28.pt\t84.24%\t75.58%\t26.67%\t-46.99%\n",
      "-0.4d 1c/epoch30.pt\t85.41%\t77.82%\t27.42%\t-45.98%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t62.17%\t57.89%\t28.84%\t-45.98%\n",
      "-0.8d 1c/epoch4.pt\t76.18%\t68.14%\t28.71%\t-45.98%\n",
      "-0.8d 1c/epoch6.pt\t75.53%\t71.31%\t29.60%\t-46.99%\n",
      "-0.8d 1c/epoch8.pt\t80.42%\t75.07%\t29.45%\t-46.99%\n",
      "-0.8d 1c/epoch10.pt\t75.92%\t71.57%\t27.76%\t-45.98%\n",
      "-0.8d 1c/epoch12.pt\t80.65%\t76.69%\t28.65%\t-45.98%\n",
      "-0.8d 1c/epoch14.pt\t85.24%\t75.99%\t27.42%\t-45.98%\n",
      "-0.8d 1c/epoch16.pt\t84.55%\t76.29%\t26.74%\t-46.99%\n",
      "-0.8d 1c/epoch20.pt\t85.90%\t77.86%\t26.85%\t-45.98%\n",
      "-0.8d 1c/epoch24.pt\t82.97%\t75.14%\t26.01%\t-45.98%\n",
      "-0.8d 1c/epoch28.pt\t84.21%\t75.55%\t26.66%\t-46.99%\n",
      "-0.8d 1c/epoch30.pt\t85.40%\t77.79%\t27.42%\t-45.98%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
