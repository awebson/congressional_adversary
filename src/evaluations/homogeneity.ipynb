{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Set, Tuple, Union, List, Dict, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import editdistance\n",
    "\n",
    "from decomposer import Decomposer, DecomposerConfig\n",
    "# from recomposer import Recomposer, RecomposerConfig\n",
    "from utils.improvised_typing import Scalar, Vector, Matrix, R3Tensor\n",
    "\n",
    "DEVICE = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webson/Research/congressional_adversary/congressional_env/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'decomposer.Decomposer' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.home() / 'Research/congressional_adversary/results'\n",
    "base_path = BASE_DIR / 'news/validation/3bins/-3c L1/epoch3.pt'\n",
    "model = torch.load(base_path)['model'].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(\n",
    "        self,\n",
    "        query_ids: Vector,\n",
    "        top_k: int = 10,\n",
    "        verbose: bool = False,\n",
    "        ) -> Matrix:\n",
    "    with torch.no_grad():\n",
    "        query_vectors = self.embedding(query_ids)\n",
    "        try:\n",
    "            cos_sim = F.cosine_similarity(\n",
    "                query_vectors.unsqueeze(1),\n",
    "                self.embedding.weight.unsqueeze(0),\n",
    "                dim=2)\n",
    "        except RuntimeError:  # insufficient GPU memory\n",
    "            cos_sim = torch.stack([\n",
    "                F.cosine_similarity(qv.unsqueeze(0), self.embedding.weight)\n",
    "                for qv in query_vectors])\n",
    "        cos_sim, neighbor_ids = cos_sim.topk(k=top_k, dim=-1)\n",
    "        if verbose:\n",
    "            return cos_sim[:, 1:], neighbor_ids[:, 1:]\n",
    "        else:  # excludes the first neighbor, which is always the query itself\n",
    "            return neighbor_ids[:, 1:]\n",
    "\n",
    "\n",
    "# def init_deno_grounding(self, top_k = 10):  \n",
    "#     self.deno_grounding: Dict[int, Set[int]] = {} \n",
    "# #     self.deno_grounding: List[Set[int]] = []  # only when iterating all vocab ids\n",
    "#     all_vocab_ids = torch.arange(self.embedding.num_embeddings, device=DEVICE)\n",
    "#     for qid in tqdm(all_vocab_ids, desc='Initializing deno grounding'):\n",
    "#         qv = self.pretrained_embed(qid)\n",
    "#         qid = qid.item()\n",
    "#         qw = self.id_to_word[qid]\n",
    "#         cos_sim = F.cosine_similarity(qv.unsqueeze(0), self.pretrained_embed.weight)\n",
    "#         cos_sim, neighbor_ids = cos_sim.topk(k=top_k + 5, dim=-1)\n",
    "#         neighbor_ids = [\n",
    "#             nid for nid in neighbor_ids.tolist()\n",
    "#             if editdistance.eval(qw, self.id_to_word[nid]) > 3]\n",
    "#         self.deno_grounding[qid] = set(neighbor_ids[:top_k])\n",
    "# #         self.deno_grounding.append(set(neighbor_ids[:top_k]))\n",
    "\n",
    "\n",
    "def init_deno_grounding(self, query_ids: Vector, top_k = 10) -> Dict[int, Set[int]]:  \n",
    "    deno_grounding: Dict[int, Set[int]] = {} \n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_vectors = self.embedding(query_ids)\n",
    "    cos_sim = F.cosine_similarity(\n",
    "        query_vectors.unsqueeze(1),\n",
    "        self.pretrained_embed.weight.unsqueeze(0),\n",
    "        dim=2)\n",
    "    cos_sim, top_neighbor_ids = cos_sim.topk(k=top_k, dim=-1)\n",
    "    \n",
    "    for query_index, sorted_target_indices in enumerate(top_neighbor_ids):\n",
    "        qid = query_ids[query_index].item()\n",
    "        qw = self.id_to_word[qid]\n",
    "        neighbor_ids = [\n",
    "            nid for nid in sorted_target_indices.tolist()\n",
    "            if editdistance.eval(qw, self.id_to_word[nid]) > 3]\n",
    "        deno_grounding[qid] = set(neighbor_ids[:top_k])\n",
    "    return deno_grounding\n",
    "\n",
    "\n",
    "\n",
    "def deno_homogeneity(\n",
    "        self,\n",
    "        query_ids: Vector,\n",
    "        top_k: int = 10\n",
    "        ) -> float:\n",
    "    neighbor_ids = self.nearest_neighbors(query_ids, top_k + 5)\n",
    "    deno_homogeneity = []\n",
    "    for query_index, sorted_neighbor_indices in enumerate(neighbor_ids):\n",
    "        query_id = query_ids[query_index].item()\n",
    "        query_word = self.id_to_word[query_id]\n",
    "        query_deno: Set[int] = self.deno_grounding[query_id]\n",
    "\n",
    "        num_neighbors = 0\n",
    "        \n",
    "        deno_overlap = len([\n",
    "            nid for nid in sorted_neighbor_indices.tolist()\n",
    "            if editdistance.eval(query_word, self.id_to_word[nid]) > 3\n",
    "                and nid in query_deno]) / len(query_deno)\n",
    "        deno_homogeneity.append(deno_overlap)\n",
    "    return deno_homogeneity #np.mean(deno_homogeneity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.7777777777777778]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = torch.tensor([42, 32, 52]).to(DEVICE)\n",
    "dg = init_deno_grounding(model, query)\n",
    "model.deno_grounding = dg\n",
    "deno_homogeneity(model, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbors(model, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.deno_grounding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
