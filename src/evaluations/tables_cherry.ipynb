{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from typing import Set, Tuple, NamedTuple, List, Dict, Counter, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from decomposer import AdversarialDecomposer, AdversarialConfig\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Embedding():\n",
    "    \n",
    "    def __init__(self, path: str, source: Optional[str] = None):\n",
    "        if source is None or source == 'adversarial':\n",
    "            self.init_from_adversarial(path)\n",
    "        elif source == 'skip_gram':\n",
    "            self.init_from_skip_gram(path)\n",
    "        elif source == 'plain_text':\n",
    "            self.init_from_plain_text(path)\n",
    "        else:\n",
    "            raise ValueError('Unknown embedding source.')\n",
    "            \n",
    "    def init_from_adversarial(self, path: str, device=torch.device('cpu')):\n",
    "        payload = torch.load(path, map_location=device)\n",
    "        model = payload['model']\n",
    "        self.word_to_id = model.word_to_id\n",
    "        self.id_to_word = model.id_to_word \n",
    "        self.Dem_frequency: Counter[str] = model.Dem_frequency\n",
    "        self.GOP_frequency: Counter[str] = model.GOP_frequency\n",
    "        \n",
    "        # encoded layer\n",
    "        self.embedding = model.export_encoded_embedding(device=device)\n",
    "#         self.embedding = model.export_decomposed_embedding(device=device)\n",
    "\n",
    "#         # manually choose which layer to export\n",
    "#         all_vocab_ids = torch.arange(\n",
    "#             len(self.word_to_id), dtype=torch.long, device=device)\n",
    "#         with torch.no_grad():\n",
    "#             embed = model.embedding(all_vocab_ids)\n",
    "#             encoded = model.encoder(embed)\n",
    "#             self.cono_logits = model.cono_decoder(encoded)\n",
    "            \n",
    "#     def init_from_adversarial(self, path: str):        \n",
    "#         config = DenotationEncoderConfig()\n",
    "#         config.input_dir = '../../data/processed/adversarial/44_Obama_1e-5'\n",
    "#         data = AdversarialDataset(config)\n",
    "#         model = DenotationEncoder(config, data)\n",
    "#         model.load_state_dict(torch.load(path))\n",
    "#         self.embedding = model.export_decomposed_embedding().to('cpu')\n",
    "#         self.word_to_id = model.word_to_id\n",
    "#         self.id_to_word = model.id_to_word\n",
    "\n",
    "    def init_from_skip_gram(self, paths: Tuple[str, str]) -> None:\n",
    "        \"\"\"Directly extract the weights of a single layer.\"\"\"\n",
    "        model_path, vocab_path = paths\n",
    "        with open(model_path, 'rb') as model_file:\n",
    "            state_dict = torch.load(model_file, map_location='cpu')\n",
    "    #     print(state_dict.keys())\n",
    "        self.embedding = state_dict['center_embedding.weight'].numpy()\n",
    "        with open(vocab_path, 'rb') as vocab_file:\n",
    "            self.word_to_id, self.id_to_word, _ = pickle.load(vocab_file)\n",
    "\n",
    "    def init_from_plain_text(self, path: str) -> Tuple[np.array, Dict[str, int]]:\n",
    "        id_generator = 0\n",
    "        word_to_id: Dict[str, int] = {}\n",
    "        embeddings: List[float] = []\n",
    "        embedding_file = open(path)\n",
    "        vocab_size, num_dimensions = map(int, embedding_file.readline().split())\n",
    "        print(f'vocab_size = {vocab_size:,}, num_dimensions = {num_dimensions}')\n",
    "        print(f'Loading embeddings from {path}', flush=True)\n",
    "        for line in embedding_file:\n",
    "            line: List[str] = line.split()  # type: ignore\n",
    "            word = line[0]\n",
    "            vector = np.array(line[-num_dimensions:], dtype=np.float64)\n",
    "            embeddings.append(vector)\n",
    "            word_to_id[word] = id_generator\n",
    "            id_generator += 1\n",
    "        embedding_file.close()\n",
    "        print('Done')\n",
    "        self.id_to_word = {val: key for key, val in word_to_id.items()}\n",
    "        self.word_to_id = word_to_id\n",
    "        self.embedding = np.array(embeddings)\n",
    "        \n",
    "    def write_to_tensorboard_projector(self, tb_dir: str) -> None:\n",
    "        from torch.utils import tensorboard\n",
    "        tb = tensorboard.SummaryWriter(log_dir=tb_dir)\n",
    "        all_vocab_ids = range(len(self.word_to_id))\n",
    "        embedding_labels = [\n",
    "            self.id_to_word[word_id]\n",
    "            for word_id in all_vocab_ids]\n",
    "        tb.add_embedding(\n",
    "            self.embedding[:9999], \n",
    "            embedding_labels[:9999], \n",
    "            global_step=0)\n",
    "        \n",
    "    def export_web_projector(self, out_dir: str) -> None:\n",
    "        random_indices = np.random.randint(len(self.embedding), size=10000)\n",
    "        subset_embedding = self.embedding[random_indices].tolist()\n",
    "        \n",
    "        vector_path = os.path.join(out_dir, 'tensorboard.tsv')\n",
    "        with open(vector_path, 'w') as vector_file:\n",
    "            for vector in subset_embedding:\n",
    "                vector_file.write('\\t'.join(map(str, vector)) + '\\n')\n",
    "\n",
    "        label_path = os.path.join(out_dir, 'tensorboard_labels.tsv')\n",
    "        with open(label_path, 'w') as label_file:\n",
    "            for index in random_indices:\n",
    "                label_file.write(self.id_to_word[index] + '\\n')\n",
    "\n",
    "    def cosine_similarity(self, query1: str, query2: str) -> float:\n",
    "        try:\n",
    "            query1_id = self.word_to_id[query1]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query1}')\n",
    "            raise error\n",
    "        try:\n",
    "            query2_id = self.word_to_id[query2]\n",
    "        except KeyError as error:\n",
    "            print(f'Out of vocabulary: {query2}')\n",
    "            raise error\n",
    "        vectors = self.embedding[(query1_id, query2_id), :]\n",
    "        similarity = 1 - distance.cosine(vectors[0], vectors[1])\n",
    "        return similarity\n",
    "\n",
    "    def nearest_neighbor(self, query: str, top_k: int = 10):\n",
    "        try:\n",
    "            query_id = self.word_to_id[query]\n",
    "        except KeyError:\n",
    "            raise KeyError(f'{query} is out of vocabulary. Sorry!')    \n",
    "        query_vec = self.embedding[query_id]\n",
    "        \n",
    "        distances = [distance.cosine(query_vec, vec) \n",
    "                     for vec in self.embedding]\n",
    "        neighbors = np.argsort(distances)\n",
    "        print(f\"{query}'s neareset neighbors:\")\n",
    "        for ranking in range(1, top_k + 1):\n",
    "            word_id = neighbors[ranking]\n",
    "            word = self.id_to_word[word_id]\n",
    "            cosine_similarity = 1 - distances[word_id]\n",
    "            print(f'{cosine_similarity:.4f}\\t{word}')\n",
    "        print()\n",
    "        \n",
    "\n",
    "class PhrasePair(NamedTuple):\n",
    "    query: str\n",
    "    neighbor: str\n",
    "    deno_sim: float\n",
    "    cono_sim: float\n",
    "        \n",
    "\n",
    "def load_cherry(path, exclude_hard_examples=True):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['semantic_similarity'] and row['cono_similarity']:\n",
    "                if (exclude_hard_examples and \n",
    "                        'hard example' in row['comment'].lower()):\n",
    "                    continue\n",
    "                data.append(PhrasePair(\n",
    "                    row['query'], \n",
    "                    row['neighbor'], \n",
    "#                     row['query_words'], \n",
    "#                     row['neighbor_words'], \n",
    "                    float(row['semantic_similarity']), \n",
    "                    float(row['cono_similarity'])))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_MTurk_results(path):\n",
    "    data = []\n",
    "    with open(path) as file:\n",
    "        if path.endswith('tsv'):\n",
    "            reader = csv.DictReader(file, dialect=csv.excel_tab)\n",
    "        else:\n",
    "            reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['median_deno'] and row['median_query_cono']:\n",
    "                \n",
    "                cono_sim = 5 - abs(\n",
    "                    float(row['median_query_cono']) - \n",
    "                    float(row['median_neighbor_cono']))\n",
    "                \n",
    "                data.append(PhrasePair( \n",
    "                    row['query_words'], \n",
    "                    row['neighbor_words'], \n",
    "                    float(row['median_deno']), \n",
    "                    cono_sim))\n",
    "    print(f'Loaded {len(data)} labeled entries at {path}')\n",
    "    return data\n",
    "\n",
    "\n",
    "def correlate_sim_deltas(model, ref_model, phrase_pairs, verbose=False):\n",
    "    label_deltas = []\n",
    "    model_deltas = []\n",
    "    if verbose:\n",
    "        print(f'deno_sim\\tcono_sim\\tref_sim\\tmodel_sim')\n",
    "    \n",
    "    for pair in phrase_pairs:\n",
    "        try:\n",
    "            sim = model.cosine_similarity(pair.query, pair.neighbor)\n",
    "            ref_sim = ref_model.cosine_similarity(pair.query, pair.neighbor)\n",
    "        except KeyError:\n",
    "            continue \n",
    "        model_delta = sim - ref_sim\n",
    "        model_deltas.append(model_delta)\n",
    "        label_deltas.append(pair.deno_sim - pair.cono_sim)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'{pair.deno_sim}  {pair.cono_sim}  {ref_sim:.2%}  {sim:.2%}  '\n",
    "                  f'{pair.query}  {pair.neighbor}')\n",
    "\n",
    "    median = np.median(model_deltas)\n",
    "    mean = np.mean(model_deltas)\n",
    "    stddev = np.std(model_deltas)\n",
    "    rho, _ = spearmanr(model_deltas, label_deltas)\n",
    "    return rho, median, mean, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cherry Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 labeled entries at ../../data/evaluation/cherries/labeled_Dem_samples.tsv\n",
      "Loaded 29 labeled entries at ../../data/evaluation/cherries/labeled_GOP_samples.tsv\n",
      "Loaded 32 labeled entries at ../../data/evaluation/cherries/remove_deno.tsv\n",
      "45 euphemism\n",
      "42 party platform\n"
     ]
    }
   ],
   "source": [
    "Dem_pairs = load_cherry(    \n",
    "    '../../data/evaluation/cherries/labeled_Dem_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "GOP_pairs = load_cherry(\n",
    "    '../../data/evaluation/cherries/labeled_GOP_samples.tsv',\n",
    "    exclude_hard_examples=True)\n",
    "test_data = Dem_pairs + GOP_pairs\n",
    "\n",
    "# Same entity denotation, different party connotation.\n",
    "euphemism = [pair for pair in test_data\n",
    "             if pair.deno_sim > pair.cono_sim]\n",
    "\n",
    "# Different entity denotation, same party connotation.\n",
    "party_platform = [pair for pair in test_data\n",
    "                  if pair.deno_sim < pair.cono_sim]\n",
    "party_platform += load_cherry(\n",
    "    '../../data/evaluation/cherries/remove_deno.tsv',\n",
    "    exclude_hard_examples=False)\n",
    "\n",
    "print(f'{len(euphemism)} euphemism')\n",
    "print(f'{len(party_platform)} party platform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = load_MTurk_results('../../data/evaluation/qualification_30.csv')\n",
    "test_data = load_MTurk_results('../../data/evaluation/combined_result.csv')\n",
    "\n",
    "# Same entity denotation, different party connotation.\n",
    "euphemism = [pair for pair in test_data\n",
    "             if pair.deno_sim > pair.cono_sim]\n",
    "\n",
    "# Different entity denotation, same party connotation.\n",
    "party_platform = [pair for pair in test_data\n",
    "                  if pair.deno_sim < pair.cono_sim]\n",
    "\n",
    "print(f'{len(euphemism)} euphemism (deno_sim > cono_sim)')\n",
    "print(f'{len(party_platform)} party platform (deno_sim < cono_sim)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\t1.0\ttax_breaks\tbipartisan_tax_relief\n",
      "5.0\t1.0\tstar_wars\tstrategic_defense_initiative\n",
      "5.0\t1.0\tstar_wars\tmissile_defense\n",
      "4.0\t1.0\tmilitary_spending\tfederal_spending\n",
      "4.0\t1.0\tmilitary_spending\tgovernment_spending\n",
      "4.5\t1.0\tassault_weapons\tfirearms\n",
      "5.0\t1.0\tassault_weapons\trifles\n",
      "4.0\t2.0\tcredit_card_companies\tcreditors\n",
      "5.0\t3.0\tmilitary_budget\tdefense_budget\n",
      "5.0\t3.0\tthe_recovery_act\tthe_stimulus_bill\n",
      "5.0\t4.0\tthe_recovery_act\tstimulus_package\n",
      "3.0\t2.0\ttrickledown\tcut_taxes\n",
      "5.0\t3.0\ttax_expenditures\tspending_programs\n",
      "4.0\t2.0\twaterboarding\tinterrogation\n",
      "5.0\t3.0\tassault_weapons_ban\tgun_control\n",
      "5.0\t1.0\tantichoice\tprolife\n",
      "4.0\t2.0\tprivate_insurance_companies\tmedicare_advantage_program\n",
      "5.0\t1.0\tnuclear_option\tconstitutional_option\n",
      "5.0\t2.0\tcorporate_profits\tearnings\n",
      "5.0\t1.0\tdeath_tax\testate_tax\n",
      "5.0\t2.0\tunborn\tfetus\n",
      "5.0\t2.0\tpartialbirth_abortion\tlateterm\n",
      "5.0\t1.0\tpartialbirth_abortion\tdx\n",
      "5.0\t1.0\tillegals\tundocumented_immigrants\n",
      "5.0\t1.0\tgovernmentrun\tpublic_option\n",
      "4.0\t1.0\tmedical_liability\tmedical_malpractice\n",
      "5.0\t1.0\tgovernment_takeover\tnational_health_insurance\n",
      "5.0\t1.0\tstimulus_bill\trecovery_and_reinvestment\n",
      "4.0\t3.0\tprogrowth\tcreate_jobs\n",
      "5.0\t1.0\tproabortion\tprochoice\n",
      "4.0\t1.0\tproabortion\tfamily_planning\n",
      "5.0\t1.0\tgovernmentrun_health_care\tsinglepayer\n",
      "4.0\t1.0\twelfare_state\tnational_health_insurance\n",
      "5.0\t1.0\tobamacare\thealth_care_reform\n",
      "5.0\t1.0\tsocialized_medicine\tsinglepayer\n",
      "5.0\t1.0\tsocialized_medicine\tuniversal_health_care\n",
      "5.0\t1.0\tpolitical_speech\tcampaign_spending\n",
      "5.0\t1.0\tpolitical_speech\tindependent_expenditures\n",
      "4.0\t1.0\twashington_spending\tmilitary_spending\n",
      "5.0\t1.0\tmassive_immigration\timmigration\n",
      "5.0\t1.0\tmassive_immigration\tundocumented_workers\n",
      "5.0\t1.0\tmassive_immigration\tnewcomers\n",
      "5.0\t1.0\tforced_busing\tbusing\n",
      "5.0\t1.0\tforced_busing\tdesegregation\n",
      "4.0\t1.0\tgrowth_of_government\tincreases_in_defense\n"
     ]
    }
   ],
   "source": [
    "# preview\n",
    "for stuff in euphemism:\n",
    "    q, n, d, c = stuff\n",
    "    print(d, c, q, n, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 111,387, num_dimensions = 300\n",
      "Loading embeddings from ../../data/pretrained_word2vec/for_real.txt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pretrained = Embedding('../../data/pretrained_word2vec/for_real.txt', 'plain_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "similarity should increase for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.017\t0.016\t0.029\t0.263\n",
      "1d -1c/epoch4.pt\t0.005\t-0.000\t0.035\t0.171\n",
      "1d -1c/epoch6.pt\t-0.002\t-0.006\t0.036\t0.083\n",
      "1d -1c/epoch8.pt\t-0.005\t-0.007\t0.043\t0.134\n",
      "1d -1c/epoch10.pt\t-0.003\t-0.009\t0.034\t0.085\n",
      "1d -1c/epoch12.pt\t-0.001\t-0.011\t0.039\t-0.026\n",
      "1d -1c/epoch14.pt\t-0.003\t-0.004\t0.039\t0.084\n",
      "1d -1c/epoch16.pt\t-0.002\t-0.008\t0.036\t0.027\n",
      "1d -1c/epoch20.pt\t-0.009\t-0.009\t0.037\t-0.043\n",
      "1d -1c/epoch24.pt\t-0.003\t-0.006\t0.038\t-0.014\n",
      "1d -1c/epoch28.pt\t-0.013\t-0.015\t0.040\t0.002\n",
      "1d -1c/epoch30.pt\t-0.011\t-0.013\t0.041\t-0.058\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.030\t0.029\t0.032\t0.045\n",
      "1d -2c/epoch4.pt\t0.010\t0.011\t0.038\t0.112\n",
      "1d -2c/epoch6.pt\t0.008\t0.001\t0.044\t0.122\n",
      "1d -2c/epoch8.pt\t0.010\t0.001\t0.048\t0.078\n",
      "1d -2c/epoch10.pt\t0.005\t-0.005\t0.050\t0.129\n",
      "1d -2c/epoch12.pt\t0.004\t-0.007\t0.051\t0.144\n",
      "1d -2c/epoch14.pt\t0.001\t-0.011\t0.055\t0.095\n",
      "1d -2c/epoch16.pt\t-0.001\t-0.011\t0.049\t0.135\n",
      "1d -2c/epoch20.pt\t-0.004\t-0.007\t0.052\t-0.015\n",
      "1d -2c/epoch24.pt\t0.003\t-0.010\t0.049\t0.100\n",
      "1d -2c/epoch28.pt\t0.002\t-0.010\t0.049\t0.101\n",
      "1d -2c/epoch30.pt\t0.007\t-0.006\t0.046\t0.037\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.044\t0.051\t0.042\t0.160\n",
      "1d -4c/epoch4.pt\t0.029\t0.028\t0.044\t0.142\n",
      "1d -4c/epoch6.pt\t0.035\t0.036\t0.033\t0.174\n",
      "1d -4c/epoch8.pt\t0.026\t0.027\t0.037\t0.004\n",
      "1d -4c/epoch10.pt\t0.022\t0.019\t0.046\t0.215\n",
      "1d -4c/epoch12.pt\t0.033\t0.020\t0.049\t0.141\n",
      "1d -4c/epoch14.pt\t0.024\t0.024\t0.058\t0.231\n",
      "1d -4c/epoch16.pt\t0.026\t0.023\t0.048\t0.121\n",
      "1d -4c/epoch20.pt\t0.005\t0.018\t0.052\t0.120\n",
      "1d -4c/epoch24.pt\t0.015\t0.017\t0.051\t0.162\n",
      "1d -4c/epoch28.pt\t0.020\t0.016\t0.058\t0.166\n",
      "1d -4c/epoch30.pt\t0.019\t0.018\t0.058\t0.195\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.078\t0.076\t0.045\t0.068\n",
      "1d -8c/epoch4.pt\t0.055\t0.058\t0.042\t-0.202\n",
      "1d -8c/epoch6.pt\t0.057\t0.056\t0.031\t-0.118\n",
      "1d -8c/epoch8.pt\t0.046\t0.041\t0.032\t0.002\n",
      "1d -8c/epoch10.pt\t0.040\t0.038\t0.035\t0.143\n",
      "1d -8c/epoch12.pt\t0.051\t0.051\t0.050\t0.169\n",
      "1d -8c/epoch14.pt\t0.045\t0.047\t0.043\t0.038\n",
      "1d -8c/epoch16.pt\t0.062\t0.056\t0.039\t-0.047\n",
      "1d -8c/epoch20.pt\t0.043\t0.056\t0.050\t-0.151\n",
      "1d -8c/epoch24.pt\t0.041\t0.041\t0.054\t-0.113\n",
      "1d -8c/epoch28.pt\t0.032\t0.031\t0.055\t-0.310\n",
      "1d -8c/epoch30.pt\t0.025\t0.026\t0.064\t-0.330\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.090\t0.092\t0.062\t-0.230\n",
      "1d -10c/epoch4.pt\t0.077\t0.089\t0.072\t-0.258\n",
      "1d -10c/epoch6.pt\t0.089\t0.098\t0.077\t-0.247\n",
      "1d -10c/epoch8.pt\t0.102\t0.094\t0.097\t-0.114\n",
      "1d -10c/epoch10.pt\t0.086\t0.070\t0.118\t-0.105\n",
      "1d -10c/epoch12.pt\t0.081\t0.069\t0.125\t-0.154\n",
      "1d -10c/epoch14.pt\t0.088\t0.077\t0.122\t-0.180\n",
      "1d -10c/epoch16.pt\t0.094\t0.073\t0.121\t-0.236\n",
      "1d -10c/epoch20.pt\t0.083\t0.070\t0.119\t-0.191\n",
      "1d -10c/epoch24.pt\t0.085\t0.077\t0.121\t-0.124\n",
      "1d -10c/epoch28.pt\t0.083\t0.083\t0.117\t-0.080\n",
      "1d -10c/epoch30.pt\t0.078\t0.073\t0.126\t-0.059\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/' \n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.011\t0.013\t0.019\t0.185\n",
      "1d -1c/epoch4.pt\t0.002\t0.009\t0.019\t0.163\n",
      "1d -1c/epoch6.pt\t0.008\t0.010\t0.017\t0.025\n",
      "1d -1c/epoch8.pt\t0.008\t0.008\t0.023\t0.237\n",
      "1d -1c/epoch10.pt\t0.004\t0.009\t0.024\t0.018\n",
      "1d -1c/epoch12.pt\t0.008\t0.011\t0.025\t-0.081\n",
      "1d -1c/epoch14.pt\t0.019\t0.018\t0.024\t0.123\n",
      "1d -1c/epoch16.pt\t0.010\t0.015\t0.027\t-0.041\n",
      "1d -1c/epoch20.pt\t0.009\t0.015\t0.029\t-0.097\n",
      "1d -1c/epoch24.pt\t0.012\t0.018\t0.033\t-0.064\n",
      "1d -1c/epoch28.pt\t0.009\t0.009\t0.031\t0.007\n",
      "1d -1c/epoch30.pt\t0.008\t0.010\t0.031\t-0.087\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.020\t0.026\t0.022\t-0.051\n",
      "1d -2c/epoch4.pt\t0.021\t0.019\t0.017\t0.075\n",
      "1d -2c/epoch6.pt\t0.014\t0.016\t0.022\t0.129\n",
      "1d -2c/epoch8.pt\t0.013\t0.016\t0.028\t0.104\n",
      "1d -2c/epoch10.pt\t0.014\t0.013\t0.031\t0.125\n",
      "1d -2c/epoch12.pt\t0.011\t0.014\t0.030\t0.187\n",
      "1d -2c/epoch14.pt\t0.010\t0.011\t0.036\t0.169\n",
      "1d -2c/epoch16.pt\t0.010\t0.011\t0.029\t0.149\n",
      "1d -2c/epoch20.pt\t0.014\t0.017\t0.036\t-0.081\n",
      "1d -2c/epoch24.pt\t0.012\t0.014\t0.034\t0.122\n",
      "1d -2c/epoch28.pt\t0.011\t0.014\t0.036\t0.055\n",
      "1d -2c/epoch30.pt\t0.018\t0.018\t0.037\t0.005\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.036\t0.048\t0.038\t0.175\n",
      "1d -4c/epoch4.pt\t0.028\t0.036\t0.028\t0.115\n",
      "1d -4c/epoch6.pt\t0.036\t0.051\t0.043\t0.153\n",
      "1d -4c/epoch8.pt\t0.032\t0.042\t0.042\t-0.003\n",
      "1d -4c/epoch10.pt\t0.032\t0.037\t0.041\t0.271\n",
      "1d -4c/epoch12.pt\t0.040\t0.042\t0.046\t0.116\n",
      "1d -4c/epoch14.pt\t0.029\t0.047\t0.055\t0.245\n",
      "1d -4c/epoch16.pt\t0.029\t0.045\t0.053\t0.080\n",
      "1d -4c/epoch20.pt\t0.023\t0.042\t0.060\t0.066\n",
      "1d -4c/epoch24.pt\t0.025\t0.041\t0.058\t0.033\n",
      "1d -4c/epoch28.pt\t0.023\t0.040\t0.066\t0.111\n",
      "1d -4c/epoch30.pt\t0.022\t0.041\t0.071\t0.175\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.068\t0.073\t0.063\t-0.018\n",
      "1d -8c/epoch4.pt\t0.055\t0.067\t0.056\t-0.192\n",
      "1d -8c/epoch6.pt\t0.067\t0.071\t0.054\t-0.059\n",
      "1d -8c/epoch8.pt\t0.054\t0.057\t0.048\t-0.005\n",
      "1d -8c/epoch10.pt\t0.052\t0.056\t0.043\t0.083\n",
      "1d -8c/epoch12.pt\t0.063\t0.072\t0.053\t0.185\n",
      "1d -8c/epoch14.pt\t0.073\t0.069\t0.053\t0.096\n",
      "1d -8c/epoch16.pt\t0.076\t0.079\t0.057\t-0.079\n",
      "1d -8c/epoch20.pt\t0.074\t0.080\t0.065\t-0.126\n",
      "1d -8c/epoch24.pt\t0.049\t0.065\t0.066\t-0.141\n",
      "1d -8c/epoch28.pt\t0.040\t0.055\t0.074\t-0.222\n",
      "1d -8c/epoch30.pt\t0.032\t0.049\t0.086\t-0.181\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.076\t0.089\t0.081\t-0.178\n",
      "1d -10c/epoch4.pt\t0.085\t0.097\t0.089\t-0.240\n",
      "1d -10c/epoch6.pt\t0.103\t0.113\t0.100\t-0.230\n",
      "1d -10c/epoch8.pt\t0.103\t0.109\t0.115\t-0.118\n",
      "1d -10c/epoch10.pt\t0.094\t0.087\t0.137\t-0.116\n",
      "1d -10c/epoch12.pt\t0.097\t0.091\t0.146\t-0.151\n",
      "1d -10c/epoch14.pt\t0.096\t0.100\t0.143\t-0.167\n",
      "1d -10c/epoch16.pt\t0.090\t0.096\t0.145\t-0.204\n",
      "1d -10c/epoch20.pt\t0.087\t0.094\t0.142\t-0.153\n",
      "1d -10c/epoch24.pt\t0.089\t0.101\t0.143\t-0.144\n",
      "1d -10c/epoch28.pt\t0.099\t0.107\t0.136\t-0.057\n",
      "1d -10c/epoch30.pt\t0.089\t0.096\t0.145\t-0.061\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Denotation +d -c models \n",
    "Similarity should decrease for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t-0.003\t-0.009\t0.049\t0.079\n",
      "1d -1c/epoch4.pt\t0.005\t-0.007\t0.048\t-0.031\n",
      "1d -1c/epoch6.pt\t-0.005\t-0.015\t0.041\t-0.102\n",
      "1d -1c/epoch8.pt\t-0.005\t-0.014\t0.039\t-0.148\n",
      "1d -1c/epoch10.pt\t-0.005\t-0.017\t0.045\t-0.172\n",
      "1d -1c/epoch12.pt\t-0.010\t-0.012\t0.042\t-0.175\n",
      "1d -1c/epoch14.pt\t0.005\t0.006\t0.045\t-0.240\n",
      "1d -1c/epoch16.pt\t-0.012\t-0.009\t0.043\t-0.204\n",
      "1d -1c/epoch20.pt\t-0.003\t-0.013\t0.045\t-0.180\n",
      "1d -1c/epoch24.pt\t-0.007\t-0.011\t0.050\t-0.267\n",
      "1d -1c/epoch28.pt\t-0.009\t-0.012\t0.053\t-0.308\n",
      "1d -1c/epoch30.pt\t-0.007\t-0.011\t0.054\t-0.254\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.013\t0.006\t0.048\t0.149\n",
      "1d -2c/epoch4.pt\t0.007\t0.001\t0.046\t0.086\n",
      "1d -2c/epoch6.pt\t0.005\t-0.006\t0.044\t0.004\n",
      "1d -2c/epoch8.pt\t-0.010\t-0.013\t0.056\t-0.043\n",
      "1d -2c/epoch10.pt\t-0.007\t-0.013\t0.052\t-0.033\n",
      "1d -2c/epoch12.pt\t0.008\t-0.006\t0.052\t-0.117\n",
      "1d -2c/epoch14.pt\t-0.006\t-0.015\t0.051\t-0.069\n",
      "1d -2c/epoch16.pt\t-0.010\t-0.011\t0.052\t-0.089\n",
      "1d -2c/epoch20.pt\t0.005\t-0.005\t0.054\t-0.092\n",
      "1d -2c/epoch24.pt\t0.006\t-0.003\t0.057\t-0.139\n",
      "1d -2c/epoch28.pt\t0.003\t-0.005\t0.059\t-0.065\n",
      "1d -2c/epoch30.pt\t0.004\t0.001\t0.057\t-0.081\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.033\t0.018\t0.067\t0.031\n",
      "1d -4c/epoch4.pt\t0.014\t0.007\t0.066\t0.129\n",
      "1d -4c/epoch6.pt\t0.030\t0.017\t0.059\t0.012\n",
      "1d -4c/epoch8.pt\t0.018\t0.012\t0.059\t-0.043\n",
      "1d -4c/epoch10.pt\t0.021\t0.013\t0.058\t0.060\n",
      "1d -4c/epoch12.pt\t0.030\t0.020\t0.057\t-0.041\n",
      "1d -4c/epoch14.pt\t0.023\t0.022\t0.060\t-0.061\n",
      "1d -4c/epoch16.pt\t0.025\t0.016\t0.052\t-0.029\n",
      "1d -4c/epoch20.pt\t0.023\t0.019\t0.055\t0.133\n",
      "1d -4c/epoch24.pt\t0.025\t0.022\t0.059\t-0.001\n",
      "1d -4c/epoch28.pt\t0.029\t0.027\t0.061\t0.043\n",
      "1d -4c/epoch30.pt\t0.035\t0.031\t0.064\t0.004\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.069\t0.069\t0.067\t0.058\n",
      "1d -8c/epoch4.pt\t0.057\t0.049\t0.076\t0.032\n",
      "1d -8c/epoch6.pt\t0.016\t0.015\t0.079\t0.254\n",
      "1d -8c/epoch8.pt\t0.031\t0.013\t0.074\t0.141\n",
      "1d -8c/epoch10.pt\t0.018\t0.009\t0.066\t0.147\n",
      "1d -8c/epoch12.pt\t0.038\t0.035\t0.095\t0.127\n",
      "1d -8c/epoch14.pt\t0.028\t0.018\t0.079\t0.181\n",
      "1d -8c/epoch16.pt\t0.033\t0.035\t0.085\t0.146\n",
      "1d -8c/epoch20.pt\t0.064\t0.043\t0.124\t0.133\n",
      "1d -8c/epoch24.pt\t0.050\t0.036\t0.097\t0.171\n",
      "1d -8c/epoch28.pt\t0.037\t0.021\t0.088\t0.242\n",
      "1d -8c/epoch30.pt\t0.032\t0.016\t0.092\t0.211\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.094\t0.086\t0.147\t0.028\n",
      "1d -10c/epoch4.pt\t0.092\t0.076\t0.161\t0.025\n",
      "1d -10c/epoch6.pt\t0.086\t0.071\t0.148\t0.076\n",
      "1d -10c/epoch8.pt\t0.097\t0.079\t0.157\t0.034\n",
      "1d -10c/epoch10.pt\t0.087\t0.078\t0.161\t-0.010\n",
      "1d -10c/epoch12.pt\t0.111\t0.095\t0.169\t-0.019\n",
      "1d -10c/epoch14.pt\t0.113\t0.114\t0.171\t-0.053\n",
      "1d -10c/epoch16.pt\t0.129\t0.118\t0.166\t-0.013\n",
      "1d -10c/epoch20.pt\t0.152\t0.140\t0.163\t-0.022\n",
      "1d -10c/epoch24.pt\t0.150\t0.136\t0.172\t0.015\n",
      "1d -10c/epoch28.pt\t0.139\t0.142\t0.195\t0.010\n",
      "1d -10c/epoch30.pt\t0.129\t0.132\t0.200\t0.016\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "1d -1c/epoch2.pt\t0.014\t0.014\t0.025\t-0.025\n",
      "1d -1c/epoch4.pt\t0.017\t0.017\t0.030\t0.083\n",
      "1d -1c/epoch6.pt\t0.010\t0.008\t0.024\t0.056\n",
      "1d -1c/epoch8.pt\t0.008\t0.009\t0.031\t-0.113\n",
      "1d -1c/epoch10.pt\t0.001\t0.004\t0.037\t-0.211\n",
      "1d -1c/epoch12.pt\t0.014\t0.012\t0.038\t-0.129\n",
      "1d -1c/epoch14.pt\t0.036\t0.033\t0.046\t-0.143\n",
      "1d -1c/epoch16.pt\t0.022\t0.016\t0.043\t-0.146\n",
      "1d -1c/epoch20.pt\t0.015\t0.015\t0.043\t-0.059\n",
      "1d -1c/epoch24.pt\t0.016\t0.020\t0.046\t-0.188\n",
      "1d -1c/epoch28.pt\t0.013\t0.019\t0.043\t-0.257\n",
      "1d -1c/epoch30.pt\t0.022\t0.018\t0.044\t-0.229\n",
      "\t\t\t\t\n",
      "1d -2c/epoch2.pt\t0.025\t0.029\t0.036\t0.141\n",
      "1d -2c/epoch4.pt\t0.025\t0.026\t0.045\t0.130\n",
      "1d -2c/epoch6.pt\t0.020\t0.018\t0.041\t0.146\n",
      "1d -2c/epoch8.pt\t0.006\t0.011\t0.048\t0.003\n",
      "1d -2c/epoch10.pt\t0.004\t0.008\t0.046\t-0.022\n",
      "1d -2c/epoch12.pt\t0.014\t0.018\t0.048\t-0.039\n",
      "1d -2c/epoch14.pt\t0.013\t0.013\t0.044\t0.067\n",
      "1d -2c/epoch16.pt\t0.014\t0.014\t0.054\t-0.007\n",
      "1d -2c/epoch20.pt\t0.021\t0.023\t0.060\t-0.014\n",
      "1d -2c/epoch24.pt\t0.027\t0.029\t0.063\t-0.041\n",
      "1d -2c/epoch28.pt\t0.038\t0.026\t0.064\t-0.006\n",
      "1d -2c/epoch30.pt\t0.033\t0.030\t0.063\t0.061\n",
      "\t\t\t\t\n",
      "1d -4c/epoch2.pt\t0.032\t0.040\t0.057\t0.090\n",
      "1d -4c/epoch4.pt\t0.032\t0.031\t0.052\t0.185\n",
      "1d -4c/epoch6.pt\t0.040\t0.040\t0.058\t0.164\n",
      "1d -4c/epoch8.pt\t0.042\t0.035\t0.066\t0.003\n",
      "1d -4c/epoch10.pt\t0.037\t0.034\t0.068\t0.089\n",
      "1d -4c/epoch12.pt\t0.041\t0.045\t0.063\t-0.017\n",
      "1d -4c/epoch14.pt\t0.048\t0.050\t0.062\t-0.003\n",
      "1d -4c/epoch16.pt\t0.039\t0.041\t0.065\t0.057\n",
      "1d -4c/epoch20.pt\t0.051\t0.047\t0.075\t0.143\n",
      "1d -4c/epoch24.pt\t0.040\t0.054\t0.079\t0.082\n",
      "1d -4c/epoch28.pt\t0.076\t0.058\t0.083\t0.059\n",
      "1d -4c/epoch30.pt\t0.069\t0.060\t0.089\t0.079\n",
      "\t\t\t\t\n",
      "1d -8c/epoch2.pt\t0.096\t0.092\t0.077\t-0.019\n",
      "1d -8c/epoch4.pt\t0.073\t0.073\t0.092\t0.121\n",
      "1d -8c/epoch6.pt\t0.041\t0.038\t0.089\t0.348\n",
      "1d -8c/epoch8.pt\t0.040\t0.037\t0.085\t0.248\n",
      "1d -8c/epoch10.pt\t0.023\t0.030\t0.082\t0.282\n",
      "1d -8c/epoch12.pt\t0.064\t0.060\t0.112\t0.167\n",
      "1d -8c/epoch14.pt\t0.051\t0.045\t0.102\t0.197\n",
      "1d -8c/epoch16.pt\t0.042\t0.060\t0.120\t0.213\n",
      "1d -8c/epoch20.pt\t0.082\t0.071\t0.152\t0.206\n",
      "1d -8c/epoch24.pt\t0.079\t0.067\t0.129\t0.197\n",
      "1d -8c/epoch28.pt\t0.053\t0.053\t0.115\t0.263\n",
      "1d -8c/epoch30.pt\t0.048\t0.045\t0.129\t0.234\n",
      "\t\t\t\t\n",
      "1d -10c/epoch2.pt\t0.115\t0.109\t0.152\t0.037\n",
      "1d -10c/epoch4.pt\t0.104\t0.100\t0.168\t0.056\n",
      "1d -10c/epoch6.pt\t0.122\t0.095\t0.160\t0.101\n",
      "1d -10c/epoch8.pt\t0.131\t0.103\t0.173\t0.121\n",
      "1d -10c/epoch10.pt\t0.112\t0.099\t0.174\t-0.023\n",
      "1d -10c/epoch12.pt\t0.133\t0.119\t0.185\t-0.021\n",
      "1d -10c/epoch14.pt\t0.155\t0.142\t0.188\t-0.035\n",
      "1d -10c/epoch16.pt\t0.162\t0.143\t0.189\t0.012\n",
      "1d -10c/epoch20.pt\t0.184\t0.168\t0.184\t0.003\n",
      "1d -10c/epoch24.pt\t0.152\t0.168\t0.181\t0.044\n",
      "1d -10c/epoch28.pt\t0.188\t0.174\t0.192\t0.035\n",
      "1d -10c/epoch30.pt\t0.173\t0.161\t0.198\t0.062\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 1d 0c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '1d 0c'\n",
    "models = ['1d -1c', '1d -2c', '1d -4c', '1d -8c', '1d -10c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.3f}\\t{mean:.3f}\\t{stddev:.3f}\\t{spearman_rho:.3f}')\n",
    "#         print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotaion -d +c models \n",
    "similarity should decrease for euphemism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.90%\t-5.47%\t15.20%\t6.02%\n",
      "-0.005d 1c/epoch4.pt\t-3.21%\t-8.39%\t12.53%\t8.49%\n",
      "-0.005d 1c/epoch6.pt\t-7.51%\t-9.36%\t12.49%\t26.07%\n",
      "-0.005d 1c/epoch8.pt\t-6.37%\t-11.70%\t13.74%\t14.84%\n",
      "-0.005d 1c/epoch10.pt\t-8.97%\t-7.93%\t8.32%\t27.21%\n",
      "-0.005d 1c/epoch12.pt\t-9.36%\t-10.00%\t8.83%\t27.00%\n",
      "-0.005d 1c/epoch14.pt\t-9.08%\t-9.84%\t8.01%\t24.87%\n",
      "-0.005d 1c/epoch16.pt\t-9.04%\t-10.71%\t8.59%\t23.56%\n",
      "-0.005d 1c/epoch20.pt\t-10.05%\t-11.76%\t8.47%\t7.68%\n",
      "-0.005d 1c/epoch24.pt\t-9.33%\t-12.09%\t8.60%\t19.42%\n",
      "-0.005d 1c/epoch28.pt\t-10.08%\t-12.75%\t9.10%\t32.94%\n",
      "-0.005d 1c/epoch30.pt\t-9.76%\t-11.93%\t8.53%\t42.65%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t23.64%\t26.00%\t10.35%\t2.83%\n",
      "-0.05d 1c/epoch4.pt\t24.48%\t26.87%\t10.91%\t-2.01%\n",
      "-0.05d 1c/epoch6.pt\t14.90%\t17.43%\t8.71%\t-0.78%\n",
      "-0.05d 1c/epoch8.pt\t13.45%\t15.22%\t8.49%\t-0.97%\n",
      "-0.05d 1c/epoch10.pt\t9.07%\t11.53%\t8.29%\t-0.67%\n",
      "-0.05d 1c/epoch12.pt\t7.96%\t9.71%\t8.34%\t-4.44%\n",
      "-0.05d 1c/epoch14.pt\t7.79%\t9.14%\t8.28%\t-2.22%\n",
      "-0.05d 1c/epoch16.pt\t16.02%\t18.70%\t9.04%\t-4.93%\n",
      "-0.05d 1c/epoch20.pt\t7.73%\t9.86%\t8.18%\t3.37%\n",
      "-0.05d 1c/epoch24.pt\t3.52%\t4.97%\t8.30%\t1.58%\n",
      "-0.05d 1c/epoch28.pt\t3.14%\t3.39%\t8.03%\t2.97%\n",
      "-0.05d 1c/epoch30.pt\t2.04%\t2.63%\t8.45%\t7.98%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-2.85%\t-7.42%\t14.97%\t6.15%\n",
      "-0.01d 1c/epoch4.pt\t-5.17%\t-9.57%\t11.64%\t4.43%\n",
      "-0.01d 1c/epoch6.pt\t-9.37%\t-11.25%\t11.65%\t29.32%\n",
      "-0.01d 1c/epoch8.pt\t-6.86%\t-11.99%\t11.63%\t14.91%\n",
      "-0.01d 1c/epoch10.pt\t-9.22%\t-10.43%\t8.60%\t16.08%\n",
      "-0.01d 1c/epoch12.pt\t-12.05%\t-11.96%\t8.09%\t25.57%\n",
      "-0.01d 1c/epoch14.pt\t-11.24%\t-11.89%\t7.46%\t31.21%\n",
      "-0.01d 1c/epoch16.pt\t-12.39%\t-13.62%\t8.39%\t23.44%\n",
      "-0.01d 1c/epoch20.pt\t-13.76%\t-14.77%\t9.58%\t7.16%\n",
      "-0.01d 1c/epoch24.pt\t-11.93%\t-13.95%\t8.23%\t24.03%\n",
      "-0.01d 1c/epoch28.pt\t-13.09%\t-14.16%\t8.97%\t29.69%\n",
      "-0.01d 1c/epoch30.pt\t-12.05%\t-13.20%\t8.74%\t39.82%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t28.03%\t30.56%\t12.13%\t-1.83%\n",
      "-0.1d 1c/epoch4.pt\t29.20%\t31.47%\t12.51%\t-2.13%\n",
      "-0.1d 1c/epoch6.pt\t29.46%\t31.70%\t12.59%\t-1.75%\n",
      "-0.1d 1c/epoch8.pt\t29.56%\t31.71%\t12.61%\t-2.13%\n",
      "-0.1d 1c/epoch10.pt\t29.55%\t31.68%\t12.61%\t-2.13%\n",
      "-0.1d 1c/epoch12.pt\t29.65%\t31.65%\t12.60%\t-2.13%\n",
      "-0.1d 1c/epoch14.pt\t29.58%\t31.53%\t12.59%\t-2.13%\n",
      "-0.1d 1c/epoch16.pt\t29.42%\t31.39%\t12.59%\t-2.13%\n",
      "-0.1d 1c/epoch20.pt\t28.80%\t30.92%\t12.49%\t-2.32%\n",
      "-0.1d 1c/epoch24.pt\t27.46%\t29.98%\t12.34%\t-2.58%\n",
      "-0.1d 1c/epoch28.pt\t26.61%\t28.96%\t12.12%\t-2.76%\n",
      "-0.1d 1c/epoch30.pt\t26.34%\t28.51%\t12.08%\t-2.23%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t29.49%\t31.51%\t12.39%\t-0.66%\n",
      "-0.2d 1c/epoch4.pt\t30.28%\t32.22%\t12.61%\t-1.69%\n",
      "-0.2d 1c/epoch6.pt\t30.47%\t32.42%\t12.67%\t-1.95%\n",
      "-0.2d 1c/epoch8.pt\t30.53%\t32.51%\t12.71%\t-1.95%\n",
      "-0.2d 1c/epoch10.pt\t30.58%\t32.56%\t12.73%\t-1.43%\n",
      "-0.2d 1c/epoch12.pt\t30.60%\t32.60%\t12.75%\t-1.51%\n",
      "-0.2d 1c/epoch14.pt\t30.57%\t32.61%\t12.75%\t-1.51%\n",
      "-0.2d 1c/epoch16.pt\t30.56%\t32.63%\t12.76%\t-1.51%\n",
      "-0.2d 1c/epoch20.pt\t30.53%\t32.65%\t12.75%\t-1.13%\n",
      "-0.2d 1c/epoch24.pt\t30.58%\t32.67%\t12.75%\t-1.43%\n",
      "-0.2d 1c/epoch28.pt\t30.67%\t32.68%\t12.75%\t-0.79%\n",
      "-0.2d 1c/epoch30.pt\t30.72%\t32.71%\t12.76%\t-0.79%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t30.10%\t31.83%\t12.54%\t-2.21%\n",
      "-0.4d 1c/epoch4.pt\t30.54%\t32.44%\t12.70%\t-1.77%\n",
      "-0.4d 1c/epoch6.pt\t30.65%\t32.59%\t12.74%\t-1.95%\n",
      "-0.4d 1c/epoch8.pt\t30.66%\t32.66%\t12.75%\t-1.51%\n",
      "-0.4d 1c/epoch10.pt\t30.73%\t32.72%\t12.78%\t-1.05%\n",
      "-0.4d 1c/epoch12.pt\t30.79%\t32.74%\t12.79%\t-1.05%\n",
      "-0.4d 1c/epoch14.pt\t30.82%\t32.77%\t12.80%\t-1.05%\n",
      "-0.4d 1c/epoch16.pt\t30.86%\t32.80%\t12.81%\t-0.79%\n",
      "-0.4d 1c/epoch20.pt\t30.90%\t32.82%\t12.83%\t-0.79%\n",
      "-0.4d 1c/epoch24.pt\t30.93%\t32.84%\t12.83%\t-1.05%\n",
      "-0.4d 1c/epoch28.pt\t30.95%\t32.85%\t12.84%\t-1.05%\n",
      "-0.4d 1c/epoch30.pt\t30.95%\t32.86%\t12.84%\t-1.05%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t30.34%\t32.05%\t12.61%\t-1.37%\n",
      "-0.8d 1c/epoch4.pt\t30.70%\t32.56%\t12.75%\t-1.69%\n",
      "-0.8d 1c/epoch6.pt\t30.80%\t32.69%\t12.79%\t-1.95%\n",
      "-0.8d 1c/epoch8.pt\t30.82%\t32.74%\t12.80%\t-1.13%\n",
      "-0.8d 1c/epoch10.pt\t30.85%\t32.76%\t12.80%\t-1.05%\n",
      "-0.8d 1c/epoch12.pt\t30.88%\t32.78%\t12.81%\t-0.79%\n",
      "-0.8d 1c/epoch14.pt\t30.88%\t32.79%\t12.82%\t-0.79%\n",
      "-0.8d 1c/epoch16.pt\t30.89%\t32.77%\t12.83%\t-1.23%\n",
      "-0.8d 1c/epoch20.pt\t30.92%\t32.79%\t12.82%\t-1.05%\n",
      "-0.8d 1c/epoch24.pt\t30.92%\t32.82%\t12.83%\t-1.05%\n",
      "-0.8d 1c/epoch28.pt\t30.93%\t32.83%\t12.83%\t-1.05%\n",
      "-0.8d 1c/epoch30.pt\t30.93%\t32.84%\t12.83%\t-1.05%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.61%\t-2.20%\t2.33%\t-0.35%\n",
      "-0.005d 1c/epoch4.pt\t-0.98%\t-1.35%\t3.55%\t25.43%\n",
      "-0.005d 1c/epoch6.pt\t-2.65%\t-3.17%\t4.21%\t21.51%\n",
      "-0.005d 1c/epoch8.pt\t-4.45%\t-5.31%\t4.95%\t-2.51%\n",
      "-0.005d 1c/epoch10.pt\t-2.90%\t-3.46%\t3.35%\t32.10%\n",
      "-0.005d 1c/epoch12.pt\t-4.65%\t-4.68%\t3.15%\t11.78%\n",
      "-0.005d 1c/epoch14.pt\t-3.06%\t-3.83%\t3.85%\t6.44%\n",
      "-0.005d 1c/epoch16.pt\t-4.76%\t-4.80%\t4.49%\t21.20%\n",
      "-0.005d 1c/epoch20.pt\t-3.52%\t-3.32%\t3.81%\t15.99%\n",
      "-0.005d 1c/epoch24.pt\t-4.05%\t-3.59%\t3.71%\t14.31%\n",
      "-0.005d 1c/epoch28.pt\t-4.94%\t-4.58%\t4.69%\t2.45%\n",
      "-0.005d 1c/epoch30.pt\t-5.20%\t-4.66%\t4.86%\t10.05%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t24.39%\t29.27%\t19.40%\t-3.41%\n",
      "-0.05d 1c/epoch4.pt\t31.64%\t33.90%\t19.02%\t2.73%\n",
      "-0.05d 1c/epoch6.pt\t21.33%\t23.62%\t15.42%\t-14.28%\n",
      "-0.05d 1c/epoch8.pt\t16.72%\t21.61%\t15.48%\t-9.05%\n",
      "-0.05d 1c/epoch10.pt\t12.57%\t16.00%\t11.33%\t-12.83%\n",
      "-0.05d 1c/epoch12.pt\t14.81%\t15.03%\t11.25%\t-21.13%\n",
      "-0.05d 1c/epoch14.pt\t12.27%\t15.14%\t10.67%\t-17.65%\n",
      "-0.05d 1c/epoch16.pt\t23.59%\t24.61%\t12.65%\t-10.12%\n",
      "-0.05d 1c/epoch20.pt\t15.09%\t18.31%\t13.54%\t1.12%\n",
      "-0.05d 1c/epoch24.pt\t12.46%\t13.47%\t11.89%\t-3.27%\n",
      "-0.05d 1c/epoch28.pt\t9.16%\t11.56%\t12.88%\t-9.58%\n",
      "-0.05d 1c/epoch30.pt\t8.08%\t9.90%\t11.77%\t-17.06%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-4.33%\t-4.15%\t3.11%\t3.05%\n",
      "-0.01d 1c/epoch4.pt\t-2.10%\t-2.54%\t5.67%\t15.84%\n",
      "-0.01d 1c/epoch6.pt\t-5.41%\t-5.05%\t4.85%\t21.15%\n",
      "-0.01d 1c/epoch8.pt\t-5.17%\t-5.59%\t5.33%\t-4.99%\n",
      "-0.01d 1c/epoch10.pt\t-5.99%\t-5.96%\t3.59%\t-6.34%\n",
      "-0.01d 1c/epoch12.pt\t-5.96%\t-6.64%\t4.15%\t0.88%\n",
      "-0.01d 1c/epoch14.pt\t-5.21%\t-5.89%\t4.70%\t3.93%\n",
      "-0.01d 1c/epoch16.pt\t-6.62%\t-7.71%\t5.13%\t18.79%\n",
      "-0.01d 1c/epoch20.pt\t-5.63%\t-6.33%\t4.81%\t14.88%\n",
      "-0.01d 1c/epoch24.pt\t-5.46%\t-5.46%\t4.77%\t17.11%\n",
      "-0.01d 1c/epoch28.pt\t-5.04%\t-5.99%\t6.64%\t13.95%\n",
      "-0.01d 1c/epoch30.pt\t-5.87%\t-5.93%\t4.80%\t9.25%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t26.80%\t33.83%\t21.43%\t-3.62%\n",
      "-0.1d 1c/epoch4.pt\t35.11%\t38.50%\t20.68%\t0.95%\n",
      "-0.1d 1c/epoch6.pt\t33.29%\t37.89%\t19.72%\t-14.80%\n",
      "-0.1d 1c/epoch8.pt\t36.02%\t38.10%\t20.30%\t-10.19%\n",
      "-0.1d 1c/epoch10.pt\t35.01%\t36.15%\t16.53%\t-8.78%\n",
      "-0.1d 1c/epoch12.pt\t34.56%\t36.97%\t17.02%\t-11.27%\n",
      "-0.1d 1c/epoch14.pt\t38.04%\t37.54%\t15.83%\t-13.74%\n",
      "-0.1d 1c/epoch16.pt\t34.83%\t37.30%\t16.23%\t-7.34%\n",
      "-0.1d 1c/epoch20.pt\t32.63%\t39.36%\t18.91%\t-1.95%\n",
      "-0.1d 1c/epoch24.pt\t36.55%\t38.48%\t17.16%\t-6.57%\n",
      "-0.1d 1c/epoch28.pt\t33.50%\t37.13%\t18.23%\t-10.58%\n",
      "-0.1d 1c/epoch30.pt\t31.02%\t35.78%\t17.22%\t-17.54%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t27.52%\t34.78%\t21.64%\t-3.51%\n",
      "-0.2d 1c/epoch4.pt\t35.71%\t39.25%\t20.77%\t1.85%\n",
      "-0.2d 1c/epoch6.pt\t33.92%\t38.61%\t19.77%\t-14.29%\n",
      "-0.2d 1c/epoch8.pt\t36.74%\t38.91%\t20.38%\t-10.71%\n",
      "-0.2d 1c/epoch10.pt\t35.65%\t37.03%\t16.66%\t-7.42%\n",
      "-0.2d 1c/epoch12.pt\t35.65%\t37.92%\t17.20%\t-10.63%\n",
      "-0.2d 1c/epoch14.pt\t38.87%\t38.62%\t16.01%\t-15.04%\n",
      "-0.2d 1c/epoch16.pt\t35.84%\t38.54%\t16.41%\t-6.71%\n",
      "-0.2d 1c/epoch20.pt\t34.98%\t41.10%\t19.12%\t-2.01%\n",
      "-0.2d 1c/epoch24.pt\t38.59%\t41.17%\t17.48%\t-6.44%\n",
      "-0.2d 1c/epoch28.pt\t36.70%\t40.85%\t18.58%\t-9.88%\n",
      "-0.2d 1c/epoch30.pt\t36.38%\t39.98%\t17.82%\t-15.25%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t27.70%\t35.09%\t21.79%\t-4.72%\n",
      "-0.4d 1c/epoch4.pt\t36.02%\t39.47%\t20.85%\t1.01%\n",
      "-0.4d 1c/epoch6.pt\t34.10%\t38.79%\t19.82%\t-14.03%\n",
      "-0.4d 1c/epoch8.pt\t36.92%\t39.05%\t20.41%\t-10.97%\n",
      "-0.4d 1c/epoch10.pt\t35.78%\t37.19%\t16.70%\t-7.42%\n",
      "-0.4d 1c/epoch12.pt\t35.81%\t38.06%\t17.24%\t-10.25%\n",
      "-0.4d 1c/epoch14.pt\t38.98%\t38.77%\t16.05%\t-15.69%\n",
      "-0.4d 1c/epoch16.pt\t36.01%\t38.71%\t16.46%\t-6.33%\n",
      "-0.4d 1c/epoch20.pt\t35.04%\t41.27%\t19.20%\t-2.27%\n",
      "-0.4d 1c/epoch24.pt\t38.79%\t41.34%\t17.57%\t-5.80%\n",
      "-0.4d 1c/epoch28.pt\t36.80%\t41.02%\t18.65%\t-9.62%\n",
      "-0.4d 1c/epoch30.pt\t36.55%\t40.13%\t17.90%\t-15.12%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t27.81%\t35.32%\t21.85%\t-4.46%\n",
      "-0.8d 1c/epoch4.pt\t36.09%\t39.59%\t20.91%\t1.39%\n",
      "-0.8d 1c/epoch6.pt\t34.14%\t38.88%\t19.86%\t-14.03%\n",
      "-0.8d 1c/epoch8.pt\t36.97%\t39.14%\t20.45%\t-10.71%\n",
      "-0.8d 1c/epoch10.pt\t35.86%\t37.23%\t16.72%\t-7.42%\n",
      "-0.8d 1c/epoch12.pt\t35.85%\t38.10%\t17.26%\t-10.25%\n",
      "-0.8d 1c/epoch14.pt\t39.06%\t38.80%\t16.07%\t-15.30%\n",
      "-0.8d 1c/epoch16.pt\t36.03%\t38.68%\t16.49%\t-5.95%\n",
      "-0.8d 1c/epoch20.pt\t34.98%\t41.24%\t19.19%\t-2.27%\n",
      "-0.8d 1c/epoch24.pt\t38.80%\t41.32%\t17.57%\t-5.80%\n",
      "-0.8d 1c/epoch28.pt\t36.80%\t41.00%\t18.65%\t-9.62%\n",
      "-0.8d 1c/epoch30.pt\t36.54%\t40.11%\t17.89%\t-15.12%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, euphemism, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Connotation -d +c models \n",
    "similarity should increase for party platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t11.64%\t15.08%\t17.91%\t-13.65%\n",
      "-0.005d 1c/epoch4.pt\t5.24%\t7.20%\t15.53%\t-0.80%\n",
      "-0.005d 1c/epoch6.pt\t4.57%\t4.06%\t14.10%\t-7.87%\n",
      "-0.005d 1c/epoch8.pt\t1.94%\t0.76%\t12.14%\t9.47%\n",
      "-0.005d 1c/epoch10.pt\t2.34%\t3.39%\t11.96%\t-17.45%\n",
      "-0.005d 1c/epoch12.pt\t-0.46%\t-0.72%\t13.68%\t-4.07%\n",
      "-0.005d 1c/epoch14.pt\t1.33%\t-0.01%\t9.17%\t-17.68%\n",
      "-0.005d 1c/epoch16.pt\t-1.05%\t-1.29%\t10.33%\t-13.27%\n",
      "-0.005d 1c/epoch20.pt\t-2.92%\t-2.61%\t10.97%\t-8.02%\n",
      "-0.005d 1c/epoch24.pt\t-2.00%\t-1.64%\t10.62%\t-13.50%\n",
      "-0.005d 1c/epoch28.pt\t-2.52%\t-2.63%\t10.51%\t-18.06%\n",
      "-0.005d 1c/epoch30.pt\t-4.18%\t-3.29%\t11.58%\t-20.19%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t64.66%\t55.65%\t22.69%\t-66.20%\n",
      "-0.05d 1c/epoch4.pt\t69.03%\t58.55%\t24.35%\t-66.20%\n",
      "-0.05d 1c/epoch6.pt\t46.91%\t42.12%\t18.99%\t-64.45%\n",
      "-0.05d 1c/epoch8.pt\t42.24%\t38.27%\t17.66%\t-63.76%\n",
      "-0.05d 1c/epoch10.pt\t34.21%\t32.34%\t16.92%\t-59.12%\n",
      "-0.05d 1c/epoch12.pt\t32.49%\t30.39%\t16.20%\t-56.92%\n",
      "-0.05d 1c/epoch14.pt\t31.16%\t29.82%\t16.22%\t-56.16%\n",
      "-0.05d 1c/epoch16.pt\t49.05%\t43.46%\t18.97%\t-64.29%\n",
      "-0.05d 1c/epoch20.pt\t33.34%\t31.08%\t16.76%\t-60.11%\n",
      "-0.05d 1c/epoch24.pt\t27.10%\t25.15%\t16.62%\t-54.10%\n",
      "-0.05d 1c/epoch28.pt\t26.57%\t23.66%\t16.03%\t-52.20%\n",
      "-0.05d 1c/epoch30.pt\t25.23%\t22.49%\t16.14%\t-51.21%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t11.90%\t13.10%\t18.00%\t-17.30%\n",
      "-0.01d 1c/epoch4.pt\t3.22%\t5.58%\t14.54%\t-3.16%\n",
      "-0.01d 1c/epoch6.pt\t1.73%\t2.02%\t12.78%\t-13.88%\n",
      "-0.01d 1c/epoch8.pt\t-0.56%\t-0.76%\t10.87%\t-1.63%\n",
      "-0.01d 1c/epoch10.pt\t-0.38%\t2.31%\t11.65%\t-29.09%\n",
      "-0.01d 1c/epoch12.pt\t-2.49%\t-3.03%\t11.54%\t-12.59%\n",
      "-0.01d 1c/epoch14.pt\t-1.92%\t-1.55%\t7.69%\t-20.42%\n",
      "-0.01d 1c/epoch16.pt\t-1.60%\t-1.27%\t8.89%\t-21.63%\n",
      "-0.01d 1c/epoch20.pt\t-2.41%\t-2.14%\t10.66%\t-11.52%\n",
      "-0.01d 1c/epoch24.pt\t-3.52%\t-2.57%\t10.44%\t-22.24%\n",
      "-0.01d 1c/epoch28.pt\t-4.31%\t-2.74%\t11.22%\t-29.47%\n",
      "-0.01d 1c/epoch30.pt\t-4.10%\t-3.30%\t11.65%\t-34.03%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t78.74%\t65.57%\t27.20%\t-66.73%\n",
      "-0.1d 1c/epoch4.pt\t81.99%\t68.14%\t28.40%\t-67.18%\n",
      "-0.1d 1c/epoch6.pt\t82.48%\t68.63%\t28.58%\t-67.26%\n",
      "-0.1d 1c/epoch8.pt\t82.43%\t68.70%\t28.58%\t-67.26%\n",
      "-0.1d 1c/epoch10.pt\t82.36%\t68.66%\t28.56%\t-67.26%\n",
      "-0.1d 1c/epoch12.pt\t82.49%\t68.64%\t28.54%\t-66.80%\n",
      "-0.1d 1c/epoch14.pt\t82.37%\t68.49%\t28.46%\t-66.80%\n",
      "-0.1d 1c/epoch16.pt\t82.13%\t68.27%\t28.37%\t-66.80%\n",
      "-0.1d 1c/epoch20.pt\t81.49%\t67.55%\t28.09%\t-66.80%\n",
      "-0.1d 1c/epoch24.pt\t80.00%\t66.12%\t27.58%\t-66.80%\n",
      "-0.1d 1c/epoch28.pt\t78.44%\t64.65%\t27.05%\t-66.27%\n",
      "-0.1d 1c/epoch30.pt\t77.48%\t64.00%\t26.83%\t-66.27%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t78.58%\t66.61%\t27.43%\t-66.73%\n",
      "-0.2d 1c/epoch4.pt\t82.69%\t69.11%\t28.69%\t-67.18%\n",
      "-0.2d 1c/epoch6.pt\t83.58%\t69.72%\t29.02%\t-67.18%\n",
      "-0.2d 1c/epoch8.pt\t83.91%\t69.96%\t29.13%\t-67.18%\n",
      "-0.2d 1c/epoch10.pt\t83.99%\t70.06%\t29.18%\t-67.18%\n",
      "-0.2d 1c/epoch12.pt\t84.12%\t70.15%\t29.23%\t-67.18%\n",
      "-0.2d 1c/epoch14.pt\t84.17%\t70.19%\t29.25%\t-67.18%\n",
      "-0.2d 1c/epoch16.pt\t84.21%\t70.24%\t29.27%\t-67.18%\n",
      "-0.2d 1c/epoch20.pt\t84.24%\t70.29%\t29.30%\t-67.18%\n",
      "-0.2d 1c/epoch24.pt\t84.31%\t70.33%\t29.31%\t-67.18%\n",
      "-0.2d 1c/epoch28.pt\t84.23%\t70.31%\t29.29%\t-67.18%\n",
      "-0.2d 1c/epoch30.pt\t84.29%\t70.35%\t29.31%\t-67.18%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t81.35%\t67.88%\t28.04%\t-66.73%\n",
      "-0.4d 1c/epoch4.pt\t83.55%\t69.65%\t28.96%\t-67.18%\n",
      "-0.4d 1c/epoch6.pt\t84.04%\t70.05%\t29.16%\t-67.18%\n",
      "-0.4d 1c/epoch8.pt\t84.23%\t70.22%\t29.24%\t-67.18%\n",
      "-0.4d 1c/epoch10.pt\t84.37%\t70.32%\t29.29%\t-67.18%\n",
      "-0.4d 1c/epoch12.pt\t84.36%\t70.33%\t29.28%\t-67.18%\n",
      "-0.4d 1c/epoch14.pt\t84.40%\t70.39%\t29.31%\t-67.18%\n",
      "-0.4d 1c/epoch16.pt\t84.46%\t70.45%\t29.33%\t-67.18%\n",
      "-0.4d 1c/epoch20.pt\t84.57%\t70.50%\t29.35%\t-67.18%\n",
      "-0.4d 1c/epoch24.pt\t84.63%\t70.54%\t29.37%\t-67.18%\n",
      "-0.4d 1c/epoch28.pt\t84.67%\t70.57%\t29.38%\t-67.18%\n",
      "-0.4d 1c/epoch30.pt\t84.68%\t70.58%\t29.39%\t-67.18%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t82.40%\t68.42%\t28.35%\t-66.73%\n",
      "-0.8d 1c/epoch4.pt\t83.93%\t69.88%\t29.06%\t-67.18%\n",
      "-0.8d 1c/epoch6.pt\t84.28%\t70.22%\t29.23%\t-67.18%\n",
      "-0.8d 1c/epoch8.pt\t84.40%\t70.36%\t29.30%\t-67.18%\n",
      "-0.8d 1c/epoch10.pt\t84.44%\t70.39%\t29.31%\t-67.18%\n",
      "-0.8d 1c/epoch12.pt\t84.44%\t70.41%\t29.31%\t-67.18%\n",
      "-0.8d 1c/epoch14.pt\t84.50%\t70.43%\t29.31%\t-67.18%\n",
      "-0.8d 1c/epoch16.pt\t84.55%\t70.40%\t29.29%\t-67.18%\n",
      "-0.8d 1c/epoch20.pt\t84.62%\t70.47%\t29.32%\t-67.18%\n",
      "-0.8d 1c/epoch24.pt\t84.66%\t70.52%\t29.35%\t-67.18%\n",
      "-0.8d 1c/epoch28.pt\t84.68%\t70.54%\t29.36%\t-67.18%\n",
      "-0.8d 1c/epoch30.pt\t84.69%\t70.55%\t29.37%\t-67.18%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against frozen pretrained word2vec\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "reference_embed = pretrained\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        embed = Embedding(base_dir + model_path)\n",
    "\n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tMedian Delta\tMean Delta\tStd. Dev.\tSpearman Rho\n",
      "-0.005d 1c/epoch2.pt\t-1.76%\t-1.53%\t3.77%\t8.63%\n",
      "-0.005d 1c/epoch4.pt\t-1.79%\t-1.68%\t3.85%\t-24.90%\n",
      "-0.005d 1c/epoch6.pt\t-2.06%\t-1.88%\t4.47%\t-4.45%\n",
      "-0.005d 1c/epoch8.pt\t-1.96%\t-2.03%\t4.50%\t-13.19%\n",
      "-0.005d 1c/epoch10.pt\t-1.55%\t-2.01%\t3.77%\t-23.46%\n",
      "-0.005d 1c/epoch12.pt\t-2.62%\t-1.54%\t3.96%\t-10.00%\n",
      "-0.005d 1c/epoch14.pt\t-1.36%\t-1.43%\t3.53%\t-18.97%\n",
      "-0.005d 1c/epoch16.pt\t-2.75%\t-2.38%\t5.04%\t-12.74%\n",
      "-0.005d 1c/epoch20.pt\t-1.31%\t-2.28%\t5.18%\t-19.58%\n",
      "-0.005d 1c/epoch24.pt\t-4.39%\t-3.94%\t6.63%\t-12.36%\n",
      "-0.005d 1c/epoch28.pt\t-3.31%\t-4.64%\t8.21%\t-20.42%\n",
      "-0.005d 1c/epoch30.pt\t-3.57%\t-3.46%\t7.76%\t-25.21%\n",
      "\t\t\t\t\n",
      "-0.05d 1c/epoch2.pt\t35.43%\t39.03%\t26.03%\t-59.73%\n",
      "-0.05d 1c/epoch4.pt\t55.39%\t49.67%\t27.28%\t-64.98%\n",
      "-0.05d 1c/epoch6.pt\t34.38%\t36.19%\t22.82%\t-63.38%\n",
      "-0.05d 1c/epoch8.pt\t38.41%\t35.48%\t21.15%\t-60.95%\n",
      "-0.05d 1c/epoch10.pt\t25.61%\t26.94%\t18.79%\t-49.92%\n",
      "-0.05d 1c/epoch12.pt\t25.15%\t29.57%\t19.46%\t-49.62%\n",
      "-0.05d 1c/epoch14.pt\t28.26%\t28.40%\t17.58%\t-51.52%\n",
      "-0.05d 1c/epoch16.pt\t44.11%\t42.37%\t20.66%\t-61.86%\n",
      "-0.05d 1c/epoch20.pt\t32.43%\t31.42%\t17.25%\t-58.51%\n",
      "-0.05d 1c/epoch24.pt\t19.84%\t22.85%\t16.13%\t-54.03%\n",
      "-0.05d 1c/epoch28.pt\t20.01%\t21.64%\t17.12%\t-47.56%\n",
      "-0.05d 1c/epoch30.pt\t23.44%\t22.32%\t17.83%\t-50.68%\n",
      "\t\t\t\t\n",
      "-0.01d 1c/epoch2.pt\t-3.41%\t-3.51%\t5.00%\t0.19%\n",
      "-0.01d 1c/epoch4.pt\t-4.31%\t-3.30%\t6.18%\t-8.71%\n",
      "-0.01d 1c/epoch6.pt\t-5.17%\t-3.91%\t6.30%\t-16.84%\n",
      "-0.01d 1c/epoch8.pt\t-3.71%\t-3.55%\t6.00%\t-24.07%\n",
      "-0.01d 1c/epoch10.pt\t-4.06%\t-3.10%\t4.80%\t-34.94%\n",
      "-0.01d 1c/epoch12.pt\t-5.32%\t-3.85%\t5.89%\t-18.82%\n",
      "-0.01d 1c/epoch14.pt\t-3.14%\t-2.97%\t5.14%\t-30.15%\n",
      "-0.01d 1c/epoch16.pt\t-3.78%\t-2.36%\t6.40%\t-16.84%\n",
      "-0.01d 1c/epoch20.pt\t-2.73%\t-1.80%\t5.64%\t-20.72%\n",
      "-0.01d 1c/epoch24.pt\t-4.45%\t-4.86%\t7.00%\t-24.90%\n",
      "-0.01d 1c/epoch28.pt\t-4.27%\t-4.75%\t10.76%\t-37.30%\n",
      "-0.01d 1c/epoch30.pt\t-4.84%\t-3.47%\t10.42%\t-34.71%\n",
      "\t\t\t\t\n",
      "-0.1d 1c/epoch2.pt\t48.10%\t48.95%\t29.09%\t-62.77%\n",
      "-0.1d 1c/epoch4.pt\t66.65%\t59.26%\t30.44%\t-66.42%\n",
      "-0.1d 1c/epoch6.pt\t68.52%\t62.70%\t30.99%\t-67.11%\n",
      "-0.1d 1c/epoch8.pt\t73.88%\t65.91%\t31.21%\t-65.89%\n",
      "-0.1d 1c/epoch10.pt\t69.08%\t63.26%\t28.87%\t-65.66%\n",
      "-0.1d 1c/epoch12.pt\t72.68%\t67.82%\t30.16%\t-65.59%\n",
      "-0.1d 1c/epoch14.pt\t78.70%\t67.07%\t29.13%\t-65.05%\n",
      "-0.1d 1c/epoch16.pt\t76.20%\t67.18%\t28.57%\t-66.35%\n",
      "-0.1d 1c/epoch20.pt\t78.73%\t67.89%\t28.32%\t-66.20%\n",
      "-0.1d 1c/epoch24.pt\t72.48%\t63.82%\t26.95%\t-67.11%\n",
      "-0.1d 1c/epoch28.pt\t71.62%\t62.64%\t27.11%\t-65.43%\n",
      "-0.1d 1c/epoch30.pt\t73.12%\t63.83%\t28.07%\t-65.66%\n",
      "\t\t\t\t\n",
      "-0.2d 1c/epoch2.pt\t48.77%\t50.00%\t29.33%\t-62.77%\n",
      "-0.2d 1c/epoch4.pt\t67.78%\t60.23%\t30.69%\t-66.42%\n",
      "-0.2d 1c/epoch6.pt\t69.92%\t63.79%\t31.36%\t-66.65%\n",
      "-0.2d 1c/epoch8.pt\t75.16%\t67.17%\t31.77%\t-65.89%\n",
      "-0.2d 1c/epoch10.pt\t71.15%\t64.65%\t29.45%\t-65.66%\n",
      "-0.2d 1c/epoch12.pt\t74.70%\t69.33%\t30.76%\t-65.59%\n",
      "-0.2d 1c/epoch14.pt\t80.50%\t68.76%\t29.79%\t-65.05%\n",
      "-0.2d 1c/epoch16.pt\t79.06%\t69.15%\t29.30%\t-66.35%\n",
      "-0.2d 1c/epoch20.pt\t81.39%\t70.63%\t29.40%\t-66.20%\n",
      "-0.2d 1c/epoch24.pt\t77.93%\t68.04%\t28.49%\t-66.65%\n",
      "-0.2d 1c/epoch28.pt\t78.35%\t68.30%\t29.15%\t-65.89%\n",
      "-0.2d 1c/epoch30.pt\t78.49%\t70.18%\t30.29%\t-64.75%\n",
      "\t\t\t\t\n",
      "-0.4d 1c/epoch2.pt\t50.19%\t51.27%\t29.61%\t-63.23%\n",
      "-0.4d 1c/epoch4.pt\t68.01%\t60.77%\t30.87%\t-66.42%\n",
      "-0.4d 1c/epoch6.pt\t70.35%\t64.11%\t31.46%\t-66.65%\n",
      "-0.4d 1c/epoch8.pt\t75.34%\t67.43%\t31.88%\t-65.89%\n",
      "-0.4d 1c/epoch10.pt\t71.84%\t64.91%\t29.53%\t-65.66%\n",
      "-0.4d 1c/epoch12.pt\t74.95%\t69.51%\t30.81%\t-65.59%\n",
      "-0.4d 1c/epoch14.pt\t80.67%\t68.96%\t29.85%\t-65.05%\n",
      "-0.4d 1c/epoch16.pt\t79.36%\t69.36%\t29.36%\t-66.35%\n",
      "-0.4d 1c/epoch20.pt\t81.68%\t70.83%\t29.46%\t-66.20%\n",
      "-0.4d 1c/epoch24.pt\t78.28%\t68.24%\t28.55%\t-66.65%\n",
      "-0.4d 1c/epoch28.pt\t78.75%\t68.56%\t29.24%\t-65.89%\n",
      "-0.4d 1c/epoch30.pt\t78.79%\t70.41%\t30.37%\t-64.75%\n",
      "\t\t\t\t\n",
      "-0.8d 1c/epoch2.pt\t50.61%\t51.81%\t29.88%\t-63.23%\n",
      "-0.8d 1c/epoch4.pt\t68.38%\t61.00%\t30.95%\t-66.42%\n",
      "-0.8d 1c/epoch6.pt\t70.63%\t64.29%\t31.52%\t-67.11%\n",
      "-0.8d 1c/epoch8.pt\t75.54%\t67.57%\t31.93%\t-65.89%\n",
      "-0.8d 1c/epoch10.pt\t71.73%\t64.98%\t29.56%\t-65.66%\n",
      "-0.8d 1c/epoch12.pt\t75.11%\t69.59%\t30.85%\t-65.59%\n",
      "-0.8d 1c/epoch14.pt\t80.74%\t69.01%\t29.87%\t-65.05%\n",
      "-0.8d 1c/epoch16.pt\t79.50%\t69.32%\t29.33%\t-66.35%\n",
      "-0.8d 1c/epoch20.pt\t81.54%\t70.80%\t29.44%\t-66.20%\n",
      "-0.8d 1c/epoch24.pt\t78.26%\t68.22%\t28.53%\t-66.65%\n",
      "-0.8d 1c/epoch28.pt\t78.50%\t68.53%\t29.22%\t-65.89%\n",
      "-0.8d 1c/epoch30.pt\t78.76%\t70.38%\t30.35%\t-64.75%\n",
      "\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against 0d 1c ceteris paribus trained models\n",
    "base_dir = '../../results/for_real_NS/'\n",
    "reference_model = '0d 1c'\n",
    "models = ['-0.005d 1c', '-0.05d 1c', '-0.01d 1c', '-0.1d 1c', '-0.2d 1c', '-0.4d 1c', '-0.8d 1c']\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16, 20, 24, 28, 30]\n",
    "\n",
    "print('Model\\tMedian Delta\\tMean Delta\\tStd. Dev.\\tSpearman Rho')\n",
    "for model in models:\n",
    "    for epoch in epochs:\n",
    "        model_path = f'{model}/epoch{epoch}.pt'\n",
    "        reference_model_path = f'{reference_model}/epoch{epoch}.pt'\n",
    "        \n",
    "        embed = Embedding(base_dir + model_path)\n",
    "        reference_embed = Embedding(base_dir + reference_model_path)\n",
    "        \n",
    "        spearman_rho, median, mean, stddev = correlate_sim_deltas(\n",
    "            embed, reference_embed, party_platform, verbose=False)\n",
    "        \n",
    "        print(f'{model_path}\\t{median:.2%}\\t{mean:.2%}\\t{stddev:.2%}\\t{spearman_rho:.2%}')\n",
    "    print('\\t\\t\\t\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
